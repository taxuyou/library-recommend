{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "visitor_예측_lstm2 월요일 휴일표함.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taxuyou/library-recommend-and-timeseries-predict/blob/master/visitor_%EC%98%88%EC%B8%A1_lstm2_%EC%9B%94%EC%9A%94%EC%9D%BC_%ED%9C%B4%EC%9D%BC%ED%91%9C%ED%95%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_WUk368Oxtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2hZnGv6Oxts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardization\n",
        "def data_standardization(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.mean()) / x_np.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9DlduZOxtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
        "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
        "# Min-Max scaling\n",
        "def min_max_scaling(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
        " \n",
        "# 정규화된 값을 원래의 값으로 되돌린다\n",
        "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
        "def reverse_min_max_scaling(org_x, x):\n",
        "    org_x_np = np.asarray(org_x)\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TbAY-pwzpcq",
        "colab": {}
      },
      "source": [
        "# 하이퍼파라미터\n",
        "input_data_column_cnt = 5  # 입력데이터의 컬럼 개수(Variable 개수)\n",
        "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
        " \n",
        "seq_length = 7           # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
        "rnn_cell_hidden_dim = 12   # 각 셀의 (hidden)출력 크기\n",
        "forget_bias = 1          # 망각편향(기본값 1.0)\n",
        "num_stacked_layers = 4     # stacked LSTM layers 개수\n",
        "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
        " \n",
        "epoch_num = 2000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
        "learning_rate = 0.001       # 학습률"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU7YchG0Oxt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터를 로딩한다.\n",
        "from datetime import datetime\n",
        "raw_dataframe = pd.read_csv('test.csv', \n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G6pH7m6Lucl",
        "colab_type": "code",
        "outputId": "8a4f39ab-efd9-42f4-8040-4df836640f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "raw_dataframe.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  days  holiday  workingday  visitors\n",
              "0  2017-01-01     7        1           0      2221\n",
              "1  2017-01-02     1        0           1      2447\n",
              "2  2017-01-03     2        0           1      2963\n",
              "3  2017-01-04     3        0           1      2653\n",
              "4  2017-01-05     4        0           1      2627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYr_K2OoLKGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe['date'] = pd.to_datetime(raw_dataframe['date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zShkIqy-L0my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe.set_index('date', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7rsd-V8NnVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c5fff8c-2891-4561-9a54-44a4aba455f8"
      },
      "source": [
        "raw_dataframe[['days','holiday','workingday','visitors']].resample('D').mean()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2963.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-06</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2646.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-07</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-08</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-09</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-10</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3121.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-11</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2563.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-12</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2374.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-13</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2141.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-14</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3012.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-15</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3710.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-17</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2687.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-18</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2392.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-19</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2444.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-20</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1578.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-21</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2809.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-22</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3095.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-23</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-24</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2947.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-25</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2394.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-26</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2234.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-27</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-06-30</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3697.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1692.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-02</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2055.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-03</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1943.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-04</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1863.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-05</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1721.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-06</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-07</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3572.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-08</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-09</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2285.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-10</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-11</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1865.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-12</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1924.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-13</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3205.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-14</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4036.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1053.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-16</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-17</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2099.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1991.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-19</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-20</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-21</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4123.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-23</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-24</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-25</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2873.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-27</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3647.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-28</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3909.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-29</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2564.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            days  holiday  workingday  visitors\n",
              "date                                           \n",
              "2017-01-01   7.0      1.0         0.0    2221.0\n",
              "2017-01-02   1.0      0.0         1.0    2447.0\n",
              "2017-01-03   2.0      0.0         1.0    2963.0\n",
              "2017-01-04   3.0      0.0         1.0    2653.0\n",
              "2017-01-05   4.0      0.0         1.0    2627.0\n",
              "2017-01-06   5.0      0.0         1.0    2646.0\n",
              "2017-01-07   6.0      1.0         0.0    3346.0\n",
              "2017-01-08   7.0      1.0         0.0    4291.0\n",
              "2017-01-09   NaN      NaN         NaN       NaN\n",
              "2017-01-10   2.0      0.0         1.0    3121.0\n",
              "2017-01-11   3.0      0.0         1.0    2563.0\n",
              "2017-01-12   4.0      0.0         1.0    2374.0\n",
              "2017-01-13   5.0      0.0         1.0    2141.0\n",
              "2017-01-14   6.0      1.0         0.0    3012.0\n",
              "2017-01-15   7.0      1.0         0.0    3710.0\n",
              "2017-01-16   1.0      0.0         1.0    1960.0\n",
              "2017-01-17   2.0      0.0         1.0    2687.0\n",
              "2017-01-18   3.0      0.0         1.0    2392.0\n",
              "2017-01-19   4.0      0.0         1.0    2444.0\n",
              "2017-01-20   5.0      0.0         1.0    1578.0\n",
              "2017-01-21   6.0      1.0         0.0    2809.0\n",
              "2017-01-22   7.0      1.0         0.0    3095.0\n",
              "2017-01-23   NaN      NaN         NaN       NaN\n",
              "2017-01-24   2.0      0.0         1.0    2947.0\n",
              "2017-01-25   3.0      0.0         1.0    2394.0\n",
              "2017-01-26   4.0      0.0         1.0    2234.0\n",
              "2017-01-27   NaN      NaN         NaN       NaN\n",
              "2017-01-28   NaN      NaN         NaN       NaN\n",
              "2017-01-29   NaN      NaN         NaN       NaN\n",
              "2017-01-30   NaN      NaN         NaN       NaN\n",
              "...          ...      ...         ...       ...\n",
              "2019-06-30   7.0      1.0         0.0    3697.0\n",
              "2019-07-01   1.0      0.0         1.0    1692.0\n",
              "2019-07-02   2.0      0.0         1.0    2055.0\n",
              "2019-07-03   3.0      0.0         1.0    1943.0\n",
              "2019-07-04   4.0      0.0         1.0    1863.0\n",
              "2019-07-05   5.0      0.0         1.0    1721.0\n",
              "2019-07-06   6.0      1.0         0.0    2735.0\n",
              "2019-07-07   7.0      1.0         0.0    3572.0\n",
              "2019-07-08   NaN      NaN         NaN       NaN\n",
              "2019-07-09   2.0      0.0         1.0    2285.0\n",
              "2019-07-10   3.0      0.0         1.0    1800.0\n",
              "2019-07-11   4.0      0.0         1.0    1865.0\n",
              "2019-07-12   5.0      0.0         1.0    1924.0\n",
              "2019-07-13   6.0      1.0         0.0    3205.0\n",
              "2019-07-14   7.0      1.0         0.0    4036.0\n",
              "2019-07-15   1.0      0.0         1.0    1053.0\n",
              "2019-07-16   2.0      0.0         1.0    2144.0\n",
              "2019-07-17   3.0      0.0         1.0    2099.0\n",
              "2019-07-18   4.0      0.0         1.0    1991.0\n",
              "2019-07-19   5.0      0.0         1.0    2100.0\n",
              "2019-07-20   6.0      1.0         0.0    2812.0\n",
              "2019-07-21   7.0      1.0         0.0    4123.0\n",
              "2019-07-22   NaN      NaN         NaN       NaN\n",
              "2019-07-23   2.0      0.0         1.0    3700.0\n",
              "2019-07-24   3.0      0.0         1.0    3152.0\n",
              "2019-07-25   4.0      0.0         1.0    2457.0\n",
              "2019-07-26   5.0      0.0         1.0    2873.0\n",
              "2019-07-27   6.0      1.0         0.0    3647.0\n",
              "2019-07-28   7.0      1.0         0.0    3909.0\n",
              "2019-07-29   1.0      0.0         1.0    2564.0\n",
              "\n",
              "[940 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ9bReIeP1Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe = raw_dataframe[['days','holiday','workingday','visitors']].resample('D').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AK7-Np7bXLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "59f5399f-8d1e-4b15-d190-676590400f0b"
      },
      "source": [
        "raw_dataframe.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2963.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-06</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2646.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-07</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-08</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-09</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-10</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3121.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            days  holiday  workingday  visitors\n",
              "date                                           \n",
              "2017-01-01   7.0      1.0         0.0    2221.0\n",
              "2017-01-02   1.0      0.0         1.0    2447.0\n",
              "2017-01-03   2.0      0.0         1.0    2963.0\n",
              "2017-01-04   3.0      0.0         1.0    2653.0\n",
              "2017-01-05   4.0      0.0         1.0    2627.0\n",
              "2017-01-06   5.0      0.0         1.0    2646.0\n",
              "2017-01-07   6.0      1.0         0.0    3346.0\n",
              "2017-01-08   7.0      1.0         0.0    4291.0\n",
              "2017-01-09   NaN      NaN         NaN       NaN\n",
              "2017-01-10   2.0      0.0         1.0    3121.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Strbh1UYbjYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe = raw_dataframe.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htIaRH_1cMkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe['date'] = raw_dataframe['date'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65zMykWlblYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "b00f10ce-97e4-4245-fc97-35f9ed3eeb35"
      },
      "source": [
        "##   date를 받아와서 휴일, 일하는 날 구하기 \n",
        "import datetime\n",
        "def getDayName(a,b,c):\n",
        "   \n",
        "  return ['1','2','3','4','5','6','7'][datetime.date(int(a),int(b),int(c)).weekday()]\n",
        "\n",
        "# 리스트로 저장 -> DataFrame으로 변환순으로 가면되여\n",
        "# 빈리스트 선언\n",
        "list1 = []\n",
        "for i in raw_dataframe['date']:\n",
        "    a = i[0:4]\n",
        "    b = i[5:7]\n",
        "    c = i[8:10]\n",
        "    # print(getDayName(a,b,c))\n",
        "    # 리스트에 추가\n",
        "    list1.append(getDayName(a,b,c))\n",
        "\n",
        "# 리스트 -> DataFrame으로 전환    \n",
        "raw_dataframe['days'] = list1\n",
        "raw_dataframe.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2963.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2646.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017-01-07</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017-01-08</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017-01-09</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017-01-10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3121.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date days  holiday  workingday  visitors\n",
              "0  2017-01-01    7      1.0         0.0    2221.0\n",
              "1  2017-01-02    1      0.0         1.0    2447.0\n",
              "2  2017-01-03    2      0.0         1.0    2963.0\n",
              "3  2017-01-04    3      0.0         1.0    2653.0\n",
              "4  2017-01-05    4      0.0         1.0    2627.0\n",
              "5  2017-01-06    5      0.0         1.0    2646.0\n",
              "6  2017-01-07    6      1.0         0.0    3346.0\n",
              "7  2017-01-08    7      1.0         0.0    4291.0\n",
              "8  2017-01-09    1      NaN         NaN       NaN\n",
              "9  2017-01-10    2      0.0         1.0    3121.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjA3ZA70cVFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "94cf840c-6e7c-46d8-c8a4-473ffbd977d5"
      },
      "source": [
        "## date 칼럼으로 요일 칼럼 holiday 만들어줌\n",
        "list2 = []\n",
        "for i in raw_dataframe['days']:\n",
        "  if i == '7':\n",
        "    list2.append(1)\n",
        "  elif i == '6':\n",
        "    list2.append(1)\n",
        "  else:\n",
        "    list2.append(0)\n",
        "raw_dataframe[\"holiday\"] = list2\n",
        "raw_dataframe.head(10) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2963.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2646.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017-01-07</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017-01-08</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017-01-09</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017-01-10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3121.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date days  holiday  workingday  visitors\n",
              "0  2017-01-01    7        1         0.0    2221.0\n",
              "1  2017-01-02    1        0         1.0    2447.0\n",
              "2  2017-01-03    2        0         1.0    2963.0\n",
              "3  2017-01-04    3        0         1.0    2653.0\n",
              "4  2017-01-05    4        0         1.0    2627.0\n",
              "5  2017-01-06    5        0         1.0    2646.0\n",
              "6  2017-01-07    6        1         0.0    3346.0\n",
              "7  2017-01-08    7        1         0.0    4291.0\n",
              "8  2017-01-09    1        0         NaN       NaN\n",
              "9  2017-01-10    2        0         1.0    3121.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7941KQcoiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "a67a2038-fcee-4144-b79e-b703ccde84e7"
      },
      "source": [
        "## 일하는 날 칼럼 만들어줌\n",
        "list3 = []\n",
        "for i in raw_dataframe['holiday']:\n",
        "  if i == 0:\n",
        "    list3.append(1)\n",
        "  else:\n",
        "    list3.append(0)\n",
        "\n",
        "raw_dataframe['workingday'] = list3\n",
        "raw_dataframe.head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2447.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2963.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2646.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017-01-07</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017-01-08</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017-01-09</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017-01-10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3121.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date days  holiday  workingday  visitors\n",
              "0  2017-01-01    7        1           0    2221.0\n",
              "1  2017-01-02    1        0           1    2447.0\n",
              "2  2017-01-03    2        0           1    2963.0\n",
              "3  2017-01-04    3        0           1    2653.0\n",
              "4  2017-01-05    4        0           1    2627.0\n",
              "5  2017-01-06    5        0           1    2646.0\n",
              "6  2017-01-07    6        1           0    3346.0\n",
              "7  2017-01-08    7        1           0    4291.0\n",
              "8  2017-01-09    1        0           1       NaN\n",
              "9  2017-01-10    2        0           1    3121.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVc99yBVgswL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "46a9900f-4e31-4e2f-cb73-25872f6afb4b"
      },
      "source": [
        "list4 = []\n",
        "for i in raw_dataframe['visitors']:\n",
        "  if i % 1==0:\n",
        "    list4.append(0)\n",
        "  else:\n",
        "    list4.append(1)\n",
        "\n",
        "raw_dataframe['closed'] = list4\n",
        "raw_dataframe.tail(30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>visitors</th>\n",
              "      <th>closed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>2019-06-30</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3697.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>2019-07-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1692.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>2019-07-02</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2055.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>2019-07-03</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1943.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>2019-07-04</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1721.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>2019-07-06</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>2019-07-07</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3572.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>2019-07-08</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>2019-07-09</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2285.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>2019-07-11</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1865.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>2019-07-12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1924.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>2019-07-13</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3205.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>2019-07-14</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4036.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>2019-07-15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1053.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>2019-07-16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>2019-07-17</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2099.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>2019-07-18</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>2019-07-19</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>2019-07-20</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2812.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>2019-07-21</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4123.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>2019-07-23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3700.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>2019-07-24</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3152.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>2019-07-25</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2457.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>2019-07-26</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2873.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>2019-07-27</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3647.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>2019-07-28</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3909.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>2019-07-29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2564.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           date days  holiday  workingday  visitors  closed\n",
              "910  2019-06-30    7        1           0    3697.0       0\n",
              "911  2019-07-01    1        0           1    1692.0       0\n",
              "912  2019-07-02    2        0           1    2055.0       0\n",
              "913  2019-07-03    3        0           1    1943.0       0\n",
              "914  2019-07-04    4        0           1    1863.0       0\n",
              "915  2019-07-05    5        0           1    1721.0       0\n",
              "916  2019-07-06    6        1           0    2735.0       0\n",
              "917  2019-07-07    7        1           0    3572.0       0\n",
              "918  2019-07-08    1        0           1       NaN       1\n",
              "919  2019-07-09    2        0           1    2285.0       0\n",
              "920  2019-07-10    3        0           1    1800.0       0\n",
              "921  2019-07-11    4        0           1    1865.0       0\n",
              "922  2019-07-12    5        0           1    1924.0       0\n",
              "923  2019-07-13    6        1           0    3205.0       0\n",
              "924  2019-07-14    7        1           0    4036.0       0\n",
              "925  2019-07-15    1        0           1    1053.0       0\n",
              "926  2019-07-16    2        0           1    2144.0       0\n",
              "927  2019-07-17    3        0           1    2099.0       0\n",
              "928  2019-07-18    4        0           1    1991.0       0\n",
              "929  2019-07-19    5        0           1    2100.0       0\n",
              "930  2019-07-20    6        1           0    2812.0       0\n",
              "931  2019-07-21    7        1           0    4123.0       0\n",
              "932  2019-07-22    1        0           1       NaN       1\n",
              "933  2019-07-23    2        0           1    3700.0       0\n",
              "934  2019-07-24    3        0           1    3152.0       0\n",
              "935  2019-07-25    4        0           1    2457.0       0\n",
              "936  2019-07-26    5        0           1    2873.0       0\n",
              "937  2019-07-27    6        1           0    3647.0       0\n",
              "938  2019-07-28    7        1           0    3909.0       0\n",
              "939  2019-07-29    1        0           1    2564.0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOOCyeNpWT3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe['visitors'] = raw_dataframe['visitors'].fillna(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j-_yuIkWBCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4587f26-7f88-4f86-964a-fdef3fd80d4a"
      },
      "source": [
        "raw_dataframe['visitors'].mean()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2188.0170212765956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyFv_clRdZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe = raw_dataframe[['days','holiday','workingday','closed','visitors']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phQxWFdqV6bi",
        "colab_type": "code",
        "outputId": "32dde08e-1769-4db9-aee7-72fe17e329e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "raw_dataframe.tail()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>closed</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2873.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3647.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3909.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2564.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    days  holiday  workingday  closed  visitors\n",
              "935    4        0           1       0    2457.0\n",
              "936    5        0           1       0    2873.0\n",
              "937    6        1           0       0    3647.0\n",
              "938    7        1           0       0    3909.0\n",
              "939    1        0           1       0    2564.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1K-uGrJWw6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe.to_csv('test2.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcRIU6SygcI",
        "colab_type": "code",
        "outputId": "c4e766d3-0acc-4e76-a127-9ef392e2f73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_info = raw_dataframe.values[0:].astype(np.float) #  문자열을 부동소수점형으로 변환한다\n",
        "print(\"data_info.shape: \", data_info.shape)\n",
        "print(\"data_info[0]: \", data_info[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_info.shape:  (940, 5)\n",
            "data_info[0]:  [7.000e+00 1.000e+00 0.000e+00 0.000e+00 2.221e+03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCFxy3Y8sgYN",
        "colab_type": "code",
        "outputId": "7e956839-ffbd-4b68-cd00-e87271698627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "data_info"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 2.221e+03],\n",
              "       [1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.447e+03],\n",
              "       [2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.963e+03],\n",
              "       ...,\n",
              "       [6.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 3.647e+03],\n",
              "       [7.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 3.909e+03],\n",
              "       [1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.564e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd3c95sOxuA",
        "colab_type": "code",
        "outputId": "cd603153-262d-4b9e-a2cd-78248364732f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# 데이터들을 정규화한다\n",
        "# ['days','holiday','workingday','closed', 'visitors']에서 'workingday'까지 취함\n",
        "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
        "day = data_info[:,:4]\n",
        "norm_day = min_max_scaling(day) # 가격형태 데이터 정규화 처리\n",
        "print(\"day.shape: \", day.shape)\n",
        "print(\"day[0]: \", day[0:3])\n",
        "print(\"norm_day[0]: \", norm_day[0])\n",
        "print(\"=\"*100) # 화면상 구분용"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day.shape:  (940, 4)\n",
            "day[0]:  [[7. 1. 0. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [2. 0. 1. 0.]]\n",
            "norm_day[0]:  [0.99999999 0.14285714 0.         0.        ]\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInLXQzHOxuF",
        "colab_type": "code",
        "outputId": "532f050c-9704-4115-af55-01c494465ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "# 방문자 데이터를 정규화한다\n",
        "# ['days','holiday','workingday','visitors']에서 마지막 'visitors'만 취함\n",
        "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
        "visitor = data_info[:,-1:]\n",
        "norm_visitor = min_max_scaling(visitor) # 거래량형태 데이터 정규화 처리\n",
        "print(\"visitor.shape: \", visitor.shape)\n",
        "print(\"vitisor[0]: \", visitor[0])\n",
        "print(\"norm_visitor[0]: \", norm_visitor[0])\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
        "x = np.concatenate((norm_day, norm_visitor), axis=1) # axis=1, 세로로 합친다\n",
        "print(\"x.shape: \", x.shape)\n",
        "print(\"x[0]: \", x[0])    # x의 첫 값\n",
        "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "y = x[:, [4]] # 타켓은 방문자다\n",
        "print(\"y[0]: \",y[0])     # y의 첫 값\n",
        "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
        " \n",
        " \n",
        "dataX = [] # 입력으로 사용될 Sequence Data\n",
        "dataY = [] # 출력(타켓)으로 사용\n",
        "\n",
        "\n",
        "for i in range(0, len(y) - seq_length):\n",
        "    _x = x[i : i+seq_length]\n",
        "    _y = y[i + seq_length] # 다음 나타날 방문자수(정답)\n",
        "    if i is 0:\n",
        "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
        "    dataX.append(_x) # dataX 리스트에 추가\n",
        "    dataY.append(_y) # dataY 리스트에 추가"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "visitor.shape:  (940, 1)\n",
            "vitisor[0]:  [2221.]\n",
            "norm_visitor[0]:  [0.30549057]\n",
            "====================================================================================================\n",
            "x.shape:  (940, 5)\n",
            "x[0]:  [0.99999999 0.14285714 0.         0.         0.30549057]\n",
            "x[-1]:  [0.14285714 0.         0.14285714 0.         0.35269024]\n",
            "====================================================================================================\n",
            "y[0]:  [0.30549057]\n",
            "y[-1]:  [0.35269024]\n",
            "[[0.99999999 0.14285714 0.         0.         0.30549057]\n",
            " [0.14285714 0.         0.14285714 0.         0.33659006]\n",
            " [0.28571428 0.         0.14285714 0.         0.40759598]\n",
            " [0.42857142 0.         0.14285714 0.         0.36493739]\n",
            " [0.57142856 0.         0.14285714 0.         0.36135957]\n",
            " [0.7142857  0.         0.14285714 0.         0.36397413]\n",
            " [0.85714284 0.14285714 0.         0.         0.46029999]] -> [0.59033989]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXFGhBzOxuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습용/테스트용 데이터 생성\n",
        "# 전체 70%를 학습용 데이터로 사용\n",
        "train_size = int(len(dataY) * 0.993)\n",
        "\n",
        "# 나머지(30%)를 테스트용 데이터로 사용\n",
        "test_size = len(dataY) - train_size\n",
        " \n",
        "# 데이터를 잘라 학습용 데이터 생성\n",
        "trainX = np.array(dataX[0:train_size])\n",
        "trainY = np.array(dataY[0:train_size])\n",
        " \n",
        "# 데이터를 잘라 테스트용 데이터 생성\n",
        "testX = np.array(dataX[train_size:len(dataX)])\n",
        "testY = np.array(dataY[train_size:len(dataY)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8xOz2SJT5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f78e488-c5e0-4a0a-8b83-9965cc8bb905"
      },
      "source": [
        "test_size"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVC5TGyOxuM",
        "colab_type": "code",
        "outputId": "c6ca6afd-d3f3-4d5e-f4c1-8ac583502e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 텐서플로우 플레이스홀더 생성\n",
        "# 입력 X, 출력 Y를 생성한다\n",
        "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
        "print(\"X: \", X)\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"Y: \", Y)\n",
        " \n",
        "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
        "targets = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"targets: \", targets)\n",
        " \n",
        "predictions = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"predictions: \", predictions)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  Tensor(\"Placeholder:0\", shape=(?, 7, 5), dtype=float32)\n",
            "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
            "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
            "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsh5_GgAOxuQ",
        "colab_type": "code",
        "outputId": "6ef3773c-461a-40a9-8586-54c32ce90f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# 모델(LSTM 네트워크) 생성\n",
        "def lstm_cell():\n",
        "    # LSTM셀을 생성\n",
        "    # num_units: 각 Cell 출력 크기\n",
        "    # forget_bias:  to the biases of the forget gate \n",
        "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
        "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
        "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
        "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
        "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    if keep_prob < 1.0:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "    return cell\n",
        " \n",
        "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
        "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
        "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-30-668a829a3f10>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-30-668a829a3f10>:16: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QGqL_YOxuW",
        "colab_type": "code",
        "outputId": "0edc7c4e-ea62-4ce9-dfea-5f74d40a4322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
        "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "print(\"hypothesis: \", hypothesis)\n",
        " \n",
        "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
        "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
        "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
        " \n",
        " \n",
        "# 손실함수로 평균제곱오차를 사용한다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "# 최적화함수로 AdamOptimizer를 사용한다\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
        " \n",
        "train = optimizer.minimize(loss)\n",
        " \n",
        "# RMSE(Root Mean Square Error)\n",
        "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
        "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
        "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
        " \n",
        " \n",
        "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
        "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
        "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
        " \n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-a2b6404f5de1>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6e823a7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6e823a7a20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6e823a7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f6e823a7a20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e824480b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e824480b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e824480b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e824480b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a76a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a76a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a76a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a76a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a7c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a7c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a7c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e823a7c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e8236a630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e8236a630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e8236a630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f6e8236a630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 12), dtype=float32)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6e7308a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6e7308a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6e7308a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6e7308a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kx6tvlt03lvu",
        "outputId": "fb8eea3f-06b9-4c3d-85b0-cda9b74ea364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 학습한다\n",
        "# start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
        "print('학습을 시작합니다...')\n",
        "for epoch in range(epoch_num):\n",
        "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
        "    if ((epoch+1) % 2 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
        "        # 학습용데이터로 rmse오차를 구한다\n",
        "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
        "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
        "        train_error_summary.append(train_error)\n",
        " \n",
        "        # 테스트용데이터로 rmse오차를 구한다\n",
        "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
        "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
        "        test_error_summary.append(test_error)\n",
        "        \n",
        "        # 현재 오류를 출력한다\n",
        "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
        "        \n",
        "# end_time = datetime.datetime.now() # 종료시간을 기록한 다\n",
        "# elapsed_time = end_time - start_time # 경과시간을 구한다\n",
        "# print('elapsed_time:',elapsed_time)\n",
        "# print('elapsed_time per epoch:',elapsed_time/epoch_num)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습을 시작합니다...\n",
            "epoch: 2, train_error(A): 0.3281172513961792, test_error(B): 0.4320870041847229, B-A: 0.1039697527885437\n",
            "epoch: 4, train_error(A): 0.3148568570613861, test_error(B): 0.41706782579421997, B-A: 0.10221096873283386\n",
            "epoch: 6, train_error(A): 0.3016475439071655, test_error(B): 0.40190309286117554, B-A: 0.10025554895401001\n",
            "epoch: 8, train_error(A): 0.28838300704956055, test_error(B): 0.38643571734428406, B-A: 0.09805271029472351\n",
            "epoch: 10, train_error(A): 0.2749445140361786, test_error(B): 0.3704695701599121, B-A: 0.09552505612373352\n",
            "epoch: 12, train_error(A): 0.26130613684654236, test_error(B): 0.3538898825645447, B-A: 0.09258374571800232\n",
            "epoch: 14, train_error(A): 0.24750950932502747, test_error(B): 0.33662915229797363, B-A: 0.08911964297294617\n",
            "epoch: 16, train_error(A): 0.23365698754787445, test_error(B): 0.31865161657333374, B-A: 0.08499462902545929\n",
            "epoch: 18, train_error(A): 0.2199188470840454, test_error(B): 0.29995107650756836, B-A: 0.08003222942352295\n",
            "epoch: 20, train_error(A): 0.2065475881099701, test_error(B): 0.28055667877197266, B-A: 0.07400909066200256\n",
            "epoch: 22, train_error(A): 0.19389469921588898, test_error(B): 0.26054561138153076, B-A: 0.06665091216564178\n",
            "epoch: 24, train_error(A): 0.18241959810256958, test_error(B): 0.24006405472755432, B-A: 0.05764445662498474\n",
            "epoch: 26, train_error(A): 0.17267316579818726, test_error(B): 0.2193576991558075, B-A: 0.04668453335762024\n",
            "epoch: 28, train_error(A): 0.16522634029388428, test_error(B): 0.19881246984004974, B-A: 0.033586129546165466\n",
            "epoch: 30, train_error(A): 0.160518079996109, test_error(B): 0.17900350689888, B-A: 0.018485426902770996\n",
            "epoch: 32, train_error(A): 0.15863361954689026, test_error(B): 0.16073480248451233, B-A: 0.0021011829376220703\n",
            "epoch: 34, train_error(A): 0.15910601615905762, test_error(B): 0.14501604437828064, B-A: -0.014089971780776978\n",
            "epoch: 36, train_error(A): 0.16091209650039673, test_error(B): 0.1328822523355484, B-A: -0.028029844164848328\n",
            "epoch: 38, train_error(A): 0.1628054976463318, test_error(B): 0.12501610815525055, B-A: -0.03778938949108124\n",
            "epoch: 40, train_error(A): 0.16386181116104126, test_error(B): 0.12143897265195847, B-A: -0.042422838509082794\n",
            "epoch: 42, train_error(A): 0.1637963503599167, test_error(B): 0.12160540372133255, B-A: -0.04219094663858414\n",
            "epoch: 44, train_error(A): 0.16285650432109833, test_error(B): 0.12470322847366333, B-A: -0.038153275847435\n",
            "epoch: 46, train_error(A): 0.1615171879529953, test_error(B): 0.12984861433506012, B-A: -0.03166857361793518\n",
            "epoch: 48, train_error(A): 0.16022080183029175, test_error(B): 0.1361767053604126, B-A: -0.02404409646987915\n",
            "epoch: 50, train_error(A): 0.1592434197664261, test_error(B): 0.1429084688425064, B-A: -0.016334950923919678\n",
            "epoch: 52, train_error(A): 0.15867459774017334, test_error(B): 0.14940643310546875, B-A: -0.00926816463470459\n",
            "epoch: 54, train_error(A): 0.1584649384021759, test_error(B): 0.15520304441452026, B-A: -0.0032618939876556396\n",
            "epoch: 56, train_error(A): 0.15849539637565613, test_error(B): 0.1599985957145691, B-A: 0.0015031993389129639\n",
            "epoch: 58, train_error(A): 0.15863610804080963, test_error(B): 0.16363920271396637, B-A: 0.005003094673156738\n",
            "epoch: 60, train_error(A): 0.15878254175186157, test_error(B): 0.1660868376493454, B-A: 0.007304295897483826\n",
            "epoch: 62, train_error(A): 0.1588701605796814, test_error(B): 0.16739040613174438, B-A: 0.008520245552062988\n",
            "epoch: 64, train_error(A): 0.1588740050792694, test_error(B): 0.16766119003295898, B-A: 0.008787184953689575\n",
            "epoch: 66, train_error(A): 0.15880021452903748, test_error(B): 0.1670539230108261, B-A: 0.008253708481788635\n",
            "epoch: 68, train_error(A): 0.15867407619953156, test_error(B): 0.1657518893480301, B-A: 0.007077813148498535\n",
            "epoch: 70, train_error(A): 0.15852801501750946, test_error(B): 0.16395437717437744, B-A: 0.005426362156867981\n",
            "epoch: 72, train_error(A): 0.15839152038097382, test_error(B): 0.16186559200286865, B-A: 0.0034740716218948364\n",
            "epoch: 74, train_error(A): 0.1582842767238617, test_error(B): 0.1596834659576416, B-A: 0.0013991892337799072\n",
            "epoch: 76, train_error(A): 0.158213272690773, test_error(B): 0.15758833289146423, B-A: -0.0006249397993087769\n",
            "epoch: 78, train_error(A): 0.15817390382289886, test_error(B): 0.15573221445083618, B-A: -0.002441689372062683\n",
            "epoch: 80, train_error(A): 0.15815390646457672, test_error(B): 0.15422947704792023, B-A: -0.003924429416656494\n",
            "epoch: 82, train_error(A): 0.1581389307975769, test_error(B): 0.15315067768096924, B-A: -0.004988253116607666\n",
            "epoch: 84, train_error(A): 0.15811729431152344, test_error(B): 0.15252040326595306, B-A: -0.0055968910455703735\n",
            "epoch: 86, train_error(A): 0.15808279812335968, test_error(B): 0.15231990814208984, B-A: -0.005762889981269836\n",
            "epoch: 88, train_error(A): 0.15803511440753937, test_error(B): 0.15249375998973846, B-A: -0.005541354417800903\n",
            "epoch: 90, train_error(A): 0.15797795355319977, test_error(B): 0.15296003222465515, B-A: -0.005017921328544617\n",
            "epoch: 92, train_error(A): 0.15791653096675873, test_error(B): 0.15362173318862915, B-A: -0.004294797778129578\n",
            "epoch: 94, train_error(A): 0.15785515308380127, test_error(B): 0.1543785184621811, B-A: -0.0034766346216201782\n",
            "epoch: 96, train_error(A): 0.15779592096805573, test_error(B): 0.1551368236541748, B-A: -0.0026590973138809204\n",
            "epoch: 98, train_error(A): 0.1577385663986206, test_error(B): 0.15581777691841125, B-A: -0.0019207894802093506\n",
            "epoch: 100, train_error(A): 0.15768110752105713, test_error(B): 0.1563624143600464, B-A: -0.0013186931610107422\n",
            "epoch: 102, train_error(A): 0.15762093663215637, test_error(B): 0.15673410892486572, B-A: -0.0008868277072906494\n",
            "epoch: 104, train_error(A): 0.15755583345890045, test_error(B): 0.15691857039928436, B-A: -0.0006372630596160889\n",
            "epoch: 106, train_error(A): 0.15748433768749237, test_error(B): 0.15692193806171417, B-A: -0.0005623996257781982\n",
            "epoch: 108, train_error(A): 0.15740595757961273, test_error(B): 0.15676714479923248, B-A: -0.000638812780380249\n",
            "epoch: 110, train_error(A): 0.1573207527399063, test_error(B): 0.1564895063638687, B-A: -0.0008312463760375977\n",
            "epoch: 112, train_error(A): 0.15722893178462982, test_error(B): 0.15613146126270294, B-A: -0.0010974705219268799\n",
            "epoch: 114, train_error(A): 0.15713045001029968, test_error(B): 0.15573766827583313, B-A: -0.0013927817344665527\n",
            "epoch: 116, train_error(A): 0.15702465176582336, test_error(B): 0.15534991025924683, B-A: -0.001674741506576538\n",
            "epoch: 118, train_error(A): 0.15691037476062775, test_error(B): 0.15500329434871674, B-A: -0.0019070804119110107\n",
            "epoch: 120, train_error(A): 0.1567860096693039, test_error(B): 0.15472300350666046, B-A: -0.0020630061626434326\n",
            "epoch: 122, train_error(A): 0.15664972364902496, test_error(B): 0.1545228511095047, B-A: -0.0021268725395202637\n",
            "epoch: 124, train_error(A): 0.15649950504302979, test_error(B): 0.15440501272678375, B-A: -0.0020944923162460327\n",
            "epoch: 126, train_error(A): 0.1563333123922348, test_error(B): 0.1543610841035843, B-A: -0.0019722282886505127\n",
            "epoch: 128, train_error(A): 0.1561487764120102, test_error(B): 0.1543744057416916, B-A: -0.0017743706703186035\n",
            "epoch: 130, train_error(A): 0.1559431552886963, test_error(B): 0.1544230431318283, B-A: -0.001520112156867981\n",
            "epoch: 132, train_error(A): 0.15571299195289612, test_error(B): 0.15448330342769623, B-A: -0.0012296885251998901\n",
            "epoch: 134, train_error(A): 0.1554538607597351, test_error(B): 0.15453305840492249, B-A: -0.0009208023548126221\n",
            "epoch: 136, train_error(A): 0.15516024827957153, test_error(B): 0.1545548141002655, B-A: -0.0006054341793060303\n",
            "epoch: 138, train_error(A): 0.15482518076896667, test_error(B): 0.1545381247997284, B-A: -0.00028705596923828125\n",
            "epoch: 140, train_error(A): 0.1544399857521057, test_error(B): 0.15448124706745148, B-A: 4.126131534576416e-05\n",
            "epoch: 142, train_error(A): 0.15399381518363953, test_error(B): 0.15439186990261078, B-A: 0.00039805471897125244\n",
            "epoch: 144, train_error(A): 0.1534731090068817, test_error(B): 0.15428712964057922, B-A: 0.0008140206336975098\n",
            "epoch: 146, train_error(A): 0.1528608798980713, test_error(B): 0.15419235825538635, B-A: 0.0013314783573150635\n",
            "epoch: 148, train_error(A): 0.15213608741760254, test_error(B): 0.15413887798786163, B-A: 0.0020027905702590942\n",
            "epoch: 150, train_error(A): 0.15127286314964294, test_error(B): 0.15416203439235687, B-A: 0.0028891712427139282\n",
            "epoch: 152, train_error(A): 0.15024015307426453, test_error(B): 0.15429933369159698, B-A: 0.0040591806173324585\n",
            "epoch: 154, train_error(A): 0.14900267124176025, test_error(B): 0.15458698570728302, B-A: 0.005584314465522766\n",
            "epoch: 156, train_error(A): 0.14752362668514252, test_error(B): 0.15505485236644745, B-A: 0.007531225681304932\n",
            "epoch: 158, train_error(A): 0.14577235281467438, test_error(B): 0.15571723878383636, B-A: 0.009944885969161987\n",
            "epoch: 160, train_error(A): 0.14374315738677979, test_error(B): 0.1565425544977188, B-A: 0.012799397110939026\n",
            "epoch: 162, train_error(A): 0.14148081839084625, test_error(B): 0.15737268328666687, B-A: 0.015891864895820618\n",
            "epoch: 164, train_error(A): 0.13908345997333527, test_error(B): 0.15785273909568787, B-A: 0.0187692791223526\n",
            "epoch: 166, train_error(A): 0.13669240474700928, test_error(B): 0.15764202177524567, B-A: 0.02094961702823639\n",
            "epoch: 168, train_error(A): 0.13452012836933136, test_error(B): 0.15695495903491974, B-A: 0.02243483066558838\n",
            "epoch: 170, train_error(A): 0.13279512524604797, test_error(B): 0.15685388445854187, B-A: 0.024058759212493896\n",
            "epoch: 172, train_error(A): 0.1316116899251938, test_error(B): 0.15852467715740204, B-A: 0.026912987232208252\n",
            "epoch: 174, train_error(A): 0.13089966773986816, test_error(B): 0.1617870181798935, B-A: 0.03088735044002533\n",
            "epoch: 176, train_error(A): 0.1304382085800171, test_error(B): 0.16477127373218536, B-A: 0.034333065152168274\n",
            "epoch: 178, train_error(A): 0.12991033494472504, test_error(B): 0.16572387516498566, B-A: 0.03581354022026062\n",
            "epoch: 180, train_error(A): 0.12913119792938232, test_error(B): 0.16471484303474426, B-A: 0.03558364510536194\n",
            "epoch: 182, train_error(A): 0.12811897695064545, test_error(B): 0.16305413842201233, B-A: 0.03493516147136688\n",
            "epoch: 184, train_error(A): 0.12701626121997833, test_error(B): 0.16167768836021423, B-A: 0.0346614271402359\n",
            "epoch: 186, train_error(A): 0.12599556148052216, test_error(B): 0.16046437621116638, B-A: 0.034468814730644226\n",
            "epoch: 188, train_error(A): 0.12514521181583405, test_error(B): 0.15891826152801514, B-A: 0.03377304971218109\n",
            "epoch: 190, train_error(A): 0.12445517629384995, test_error(B): 0.15706214308738708, B-A: 0.03260696679353714\n",
            "epoch: 192, train_error(A): 0.12386295199394226, test_error(B): 0.15550388395786285, B-A: 0.03164093196392059\n",
            "epoch: 194, train_error(A): 0.12328808009624481, test_error(B): 0.1547224074602127, B-A: 0.031434327363967896\n",
            "epoch: 196, train_error(A): 0.12267765402793884, test_error(B): 0.15451443195343018, B-A: 0.03183677792549133\n",
            "epoch: 198, train_error(A): 0.12201789021492004, test_error(B): 0.154265359044075, B-A: 0.03224746882915497\n",
            "epoch: 200, train_error(A): 0.12132402509450912, test_error(B): 0.15367895364761353, B-A: 0.0323549285531044\n",
            "epoch: 202, train_error(A): 0.1206289529800415, test_error(B): 0.1530906707048416, B-A: 0.03246171772480011\n",
            "epoch: 204, train_error(A): 0.11995821446180344, test_error(B): 0.15292194485664368, B-A: 0.03296373039484024\n",
            "epoch: 206, train_error(A): 0.11931993067264557, test_error(B): 0.1529829353094101, B-A: 0.033663004636764526\n",
            "epoch: 208, train_error(A): 0.11870162189006805, test_error(B): 0.1526990681886673, B-A: 0.03399744629859924\n",
            "epoch: 210, train_error(A): 0.11808179318904877, test_error(B): 0.15200228989124298, B-A: 0.033920496702194214\n",
            "epoch: 212, train_error(A): 0.11744549125432968, test_error(B): 0.1513676941394806, B-A: 0.03392220288515091\n",
            "epoch: 214, train_error(A): 0.11679074913263321, test_error(B): 0.1508905589580536, B-A: 0.03409980982542038\n",
            "epoch: 216, train_error(A): 0.11612729728221893, test_error(B): 0.15015311539173126, B-A: 0.03402581810951233\n",
            "epoch: 218, train_error(A): 0.11546696722507477, test_error(B): 0.14916521310806274, B-A: 0.033698245882987976\n",
            "epoch: 220, train_error(A): 0.11481631547212601, test_error(B): 0.14842376112937927, B-A: 0.033607445657253265\n",
            "epoch: 222, train_error(A): 0.11417392641305923, test_error(B): 0.14791128039360046, B-A: 0.03373735398054123\n",
            "epoch: 224, train_error(A): 0.11353420466184616, test_error(B): 0.14724330604076385, B-A: 0.033709101378917694\n",
            "epoch: 226, train_error(A): 0.11289383471012115, test_error(B): 0.1466429978609085, B-A: 0.033749163150787354\n",
            "epoch: 228, train_error(A): 0.1122545525431633, test_error(B): 0.1463722437620163, B-A: 0.034117691218853\n",
            "epoch: 230, train_error(A): 0.11162250488996506, test_error(B): 0.14606770873069763, B-A: 0.034445203840732574\n",
            "epoch: 232, train_error(A): 0.11100543290376663, test_error(B): 0.14575621485710144, B-A: 0.03475078195333481\n",
            "epoch: 234, train_error(A): 0.11040916293859482, test_error(B): 0.14571599662303925, B-A: 0.03530683368444443\n",
            "epoch: 236, train_error(A): 0.10983733832836151, test_error(B): 0.14558248221874237, B-A: 0.03574514389038086\n",
            "epoch: 238, train_error(A): 0.10929357260465622, test_error(B): 0.14544542133808136, B-A: 0.03615184873342514\n",
            "epoch: 240, train_error(A): 0.10878079384565353, test_error(B): 0.1454828828573227, B-A: 0.03670208901166916\n",
            "epoch: 242, train_error(A): 0.10830050706863403, test_error(B): 0.145401269197464, B-A: 0.037100762128829956\n",
            "epoch: 244, train_error(A): 0.10785234719514847, test_error(B): 0.14551271498203278, B-A: 0.03766036778688431\n",
            "epoch: 246, train_error(A): 0.10743364691734314, test_error(B): 0.14563898742198944, B-A: 0.0382053405046463\n",
            "epoch: 248, train_error(A): 0.10703989863395691, test_error(B): 0.14587290585041046, B-A: 0.03883300721645355\n",
            "epoch: 250, train_error(A): 0.10666549950838089, test_error(B): 0.14621832966804504, B-A: 0.039552830159664154\n",
            "epoch: 252, train_error(A): 0.10630647838115692, test_error(B): 0.14656612277030945, B-A: 0.04025964438915253\n",
            "epoch: 254, train_error(A): 0.10595866292715073, test_error(B): 0.1469980925321579, B-A: 0.04103942960500717\n",
            "epoch: 256, train_error(A): 0.10561659932136536, test_error(B): 0.1473543643951416, B-A: 0.041737765073776245\n",
            "epoch: 258, train_error(A): 0.10527489334344864, test_error(B): 0.14769108593463898, B-A: 0.04241619259119034\n",
            "epoch: 260, train_error(A): 0.1049291118979454, test_error(B): 0.14791011810302734, B-A: 0.04298100620508194\n",
            "epoch: 262, train_error(A): 0.10457620769739151, test_error(B): 0.14805619418621063, B-A: 0.04347998648881912\n",
            "epoch: 264, train_error(A): 0.10421381890773773, test_error(B): 0.14813072979450226, B-A: 0.043916910886764526\n",
            "epoch: 266, train_error(A): 0.10383982211351395, test_error(B): 0.14813868701457977, B-A: 0.044298864901065826\n",
            "epoch: 268, train_error(A): 0.10345232486724854, test_error(B): 0.14815489947795868, B-A: 0.044702574610710144\n",
            "epoch: 270, train_error(A): 0.10305015742778778, test_error(B): 0.1481015980243683, B-A: 0.045051440596580505\n",
            "epoch: 272, train_error(A): 0.10263282805681229, test_error(B): 0.14804932475090027, B-A: 0.04541649669408798\n",
            "epoch: 274, train_error(A): 0.1021997481584549, test_error(B): 0.14792771637439728, B-A: 0.04572796821594238\n",
            "epoch: 276, train_error(A): 0.10175025463104248, test_error(B): 0.14774301648139954, B-A: 0.045992761850357056\n",
            "epoch: 278, train_error(A): 0.10128381103277206, test_error(B): 0.14754462242126465, B-A: 0.046260811388492584\n",
            "epoch: 280, train_error(A): 0.10079976171255112, test_error(B): 0.1473178267478943, B-A: 0.04651806503534317\n",
            "epoch: 282, train_error(A): 0.1002974882721901, test_error(B): 0.14712192118167877, B-A: 0.04682443290948868\n",
            "epoch: 284, train_error(A): 0.09977644681930542, test_error(B): 0.1469813585281372, B-A: 0.04720491170883179\n",
            "epoch: 286, train_error(A): 0.09923700243234634, test_error(B): 0.1468716710805893, B-A: 0.04763466864824295\n",
            "epoch: 288, train_error(A): 0.0986800268292427, test_error(B): 0.14675596356391907, B-A: 0.04807593673467636\n",
            "epoch: 290, train_error(A): 0.09810656309127808, test_error(B): 0.14661523699760437, B-A: 0.048508673906326294\n",
            "epoch: 292, train_error(A): 0.09751835465431213, test_error(B): 0.14644783735275269, B-A: 0.04892948269844055\n",
            "epoch: 294, train_error(A): 0.09691846370697021, test_error(B): 0.14625903964042664, B-A: 0.04934057593345642\n",
            "epoch: 296, train_error(A): 0.09631215780973434, test_error(B): 0.14606721699237823, B-A: 0.04975505918264389\n",
            "epoch: 298, train_error(A): 0.09570746123790741, test_error(B): 0.14586366713047028, B-A: 0.050156205892562866\n",
            "epoch: 300, train_error(A): 0.09511470049619675, test_error(B): 0.1455908566713333, B-A: 0.050476156175136566\n",
            "epoch: 302, train_error(A): 0.09454647451639175, test_error(B): 0.14503580331802368, B-A: 0.05048932880163193\n",
            "epoch: 304, train_error(A): 0.09406093508005142, test_error(B): 0.14273083209991455, B-A: 0.04866989701986313\n",
            "epoch: 306, train_error(A): 0.09449918568134308, test_error(B): 0.13444441556930542, B-A: 0.03994522988796234\n",
            "epoch: 308, train_error(A): 0.0931939035654068, test_error(B): 0.14507049322128296, B-A: 0.05187658965587616\n",
            "epoch: 310, train_error(A): 0.09323451668024063, test_error(B): 0.15081235766410828, B-A: 0.057577840983867645\n",
            "epoch: 312, train_error(A): 0.09323740005493164, test_error(B): 0.13615794479846954, B-A: 0.0429205447435379\n",
            "epoch: 314, train_error(A): 0.09293925017118454, test_error(B): 0.15185920894145966, B-A: 0.058919958770275116\n",
            "epoch: 316, train_error(A): 0.09254442155361176, test_error(B): 0.13828295469284058, B-A: 0.04573853313922882\n",
            "epoch: 318, train_error(A): 0.09218256175518036, test_error(B): 0.14730805158615112, B-A: 0.055125489830970764\n",
            "epoch: 320, train_error(A): 0.09192045032978058, test_error(B): 0.14316245913505554, B-A: 0.05124200880527496\n",
            "epoch: 322, train_error(A): 0.09175899624824524, test_error(B): 0.14261099696159363, B-A: 0.05085200071334839\n",
            "epoch: 324, train_error(A): 0.09164280444383621, test_error(B): 0.14669117331504822, B-A: 0.055048368871212006\n",
            "epoch: 326, train_error(A): 0.0915127545595169, test_error(B): 0.14016230404376984, B-A: 0.04864954948425293\n",
            "epoch: 328, train_error(A): 0.09134554862976074, test_error(B): 0.1476018726825714, B-A: 0.05625632405281067\n",
            "epoch: 330, train_error(A): 0.09114565700292587, test_error(B): 0.1404419094324112, B-A: 0.04929625242948532\n",
            "epoch: 332, train_error(A): 0.0909288227558136, test_error(B): 0.14625515043735504, B-A: 0.05532632768154144\n",
            "epoch: 334, train_error(A): 0.09072314947843552, test_error(B): 0.1424323469400406, B-A: 0.05170919746160507\n",
            "epoch: 336, train_error(A): 0.09054436534643173, test_error(B): 0.1438138782978058, B-A: 0.053269512951374054\n",
            "epoch: 338, train_error(A): 0.09038989990949631, test_error(B): 0.14445744454860687, B-A: 0.054067544639110565\n",
            "epoch: 340, train_error(A): 0.09024550020694733, test_error(B): 0.14185090363025665, B-A: 0.051605403423309326\n",
            "epoch: 342, train_error(A): 0.09009531140327454, test_error(B): 0.14513884484767914, B-A: 0.0550435334444046\n",
            "epoch: 344, train_error(A): 0.08993198722600937, test_error(B): 0.14141391217708588, B-A: 0.05148192495107651\n",
            "epoch: 346, train_error(A): 0.08976033329963684, test_error(B): 0.14395110309123993, B-A: 0.05419076979160309\n",
            "epoch: 348, train_error(A): 0.08959300071001053, test_error(B): 0.14232003688812256, B-A: 0.05272703617811203\n",
            "epoch: 350, train_error(A): 0.08943714201450348, test_error(B): 0.14183209836483002, B-A: 0.05239495635032654\n",
            "epoch: 352, train_error(A): 0.08928730338811874, test_error(B): 0.14307613670825958, B-A: 0.05378883332014084\n",
            "epoch: 354, train_error(A): 0.08913301676511765, test_error(B): 0.14068737626075745, B-A: 0.0515543594956398\n",
            "epoch: 356, train_error(A): 0.0889730378985405, test_error(B): 0.14214207231998444, B-A: 0.05316903442144394\n",
            "epoch: 358, train_error(A): 0.0888170674443245, test_error(B): 0.14120440185070038, B-A: 0.052387334406375885\n",
            "epoch: 360, train_error(A): 0.08866940438747406, test_error(B): 0.14031395316123962, B-A: 0.051644548773765564\n",
            "epoch: 362, train_error(A): 0.08852200210094452, test_error(B): 0.1414015144109726, B-A: 0.052879512310028076\n",
            "epoch: 364, train_error(A): 0.08837103843688965, test_error(B): 0.13999731838703156, B-A: 0.05162627995014191\n",
            "epoch: 366, train_error(A): 0.08822403848171234, test_error(B): 0.13996094465255737, B-A: 0.05173690617084503\n",
            "epoch: 368, train_error(A): 0.08808200061321259, test_error(B): 0.14046324789524078, B-A: 0.0523812472820282\n",
            "epoch: 370, train_error(A): 0.08793845772743225, test_error(B): 0.13928556442260742, B-A: 0.05134710669517517\n",
            "epoch: 372, train_error(A): 0.08779692649841309, test_error(B): 0.13935725390911102, B-A: 0.05156032741069794\n",
            "epoch: 374, train_error(A): 0.08766014128923416, test_error(B): 0.1396419107913971, B-A: 0.05198176950216293\n",
            "epoch: 376, train_error(A): 0.08752328902482986, test_error(B): 0.13872064650058746, B-A: 0.0511973574757576\n",
            "epoch: 378, train_error(A): 0.08738938719034195, test_error(B): 0.13855868577957153, B-A: 0.051169298589229584\n",
            "epoch: 380, train_error(A): 0.08725882321596146, test_error(B): 0.13881143927574158, B-A: 0.05155261605978012\n",
            "epoch: 382, train_error(A): 0.0871291533112526, test_error(B): 0.13818079233169556, B-A: 0.05105163902044296\n",
            "epoch: 384, train_error(A): 0.08700340241193771, test_error(B): 0.13769391179084778, B-A: 0.050690509378910065\n",
            "epoch: 386, train_error(A): 0.08687929809093475, test_error(B): 0.1378238946199417, B-A: 0.05094459652900696\n",
            "epoch: 388, train_error(A): 0.0867583230137825, test_error(B): 0.1375925987958908, B-A: 0.05083427578210831\n",
            "epoch: 390, train_error(A): 0.08663992583751678, test_error(B): 0.1369846612215042, B-A: 0.05034473538398743\n",
            "epoch: 392, train_error(A): 0.08652433007955551, test_error(B): 0.13673798739910126, B-A: 0.050213657319545746\n",
            "epoch: 394, train_error(A): 0.08641168475151062, test_error(B): 0.13673923909664154, B-A: 0.05032755434513092\n",
            "epoch: 396, train_error(A): 0.08630196005105972, test_error(B): 0.1364634782075882, B-A: 0.05016151815652847\n",
            "epoch: 398, train_error(A): 0.08619528263807297, test_error(B): 0.13599081337451935, B-A: 0.04979553073644638\n",
            "epoch: 400, train_error(A): 0.08609187602996826, test_error(B): 0.13570187985897064, B-A: 0.04961000382900238\n",
            "epoch: 402, train_error(A): 0.0859915018081665, test_error(B): 0.1356077790260315, B-A: 0.04961627721786499\n",
            "epoch: 404, train_error(A): 0.08589456975460052, test_error(B): 0.13544881343841553, B-A: 0.049554243683815\n",
            "epoch: 406, train_error(A): 0.08580068498849869, test_error(B): 0.13512222468852997, B-A: 0.04932153970003128\n",
            "epoch: 408, train_error(A): 0.08571022003889084, test_error(B): 0.1347581446170807, B-A: 0.04904792457818985\n",
            "epoch: 410, train_error(A): 0.08562307059764862, test_error(B): 0.13448989391326904, B-A: 0.04886682331562042\n",
            "epoch: 412, train_error(A): 0.08553913235664368, test_error(B): 0.13431721925735474, B-A: 0.04877808690071106\n",
            "epoch: 414, train_error(A): 0.08545858412981033, test_error(B): 0.13415560126304626, B-A: 0.04869701713323593\n",
            "epoch: 416, train_error(A): 0.08538131415843964, test_error(B): 0.13394160568714142, B-A: 0.04856029152870178\n",
            "epoch: 418, train_error(A): 0.08530724793672562, test_error(B): 0.13367193937301636, B-A: 0.04836469143629074\n",
            "epoch: 420, train_error(A): 0.08523636311292648, test_error(B): 0.13338275253772736, B-A: 0.04814638942480087\n",
            "epoch: 422, train_error(A): 0.08516862243413925, test_error(B): 0.133109912276268, B-A: 0.047941289842128754\n",
            "epoch: 424, train_error(A): 0.08510391414165497, test_error(B): 0.13286392390727997, B-A: 0.047760009765625\n",
            "epoch: 426, train_error(A): 0.08504214137792587, test_error(B): 0.13263657689094543, B-A: 0.04759443551301956\n",
            "epoch: 428, train_error(A): 0.08498318493366241, test_error(B): 0.13242042064666748, B-A: 0.047437235713005066\n",
            "epoch: 430, train_error(A): 0.08492696285247803, test_error(B): 0.13221171498298645, B-A: 0.04728475213050842\n",
            "epoch: 432, train_error(A): 0.08487331122159958, test_error(B): 0.1320037841796875, B-A: 0.04713047295808792\n",
            "epoch: 434, train_error(A): 0.0848221406340599, test_error(B): 0.131786048412323, B-A: 0.04696390777826309\n",
            "epoch: 436, train_error(A): 0.08477337658405304, test_error(B): 0.13154654204845428, B-A: 0.046773165464401245\n",
            "epoch: 438, train_error(A): 0.08472704142332077, test_error(B): 0.13126225769519806, B-A: 0.04653521627187729\n",
            "epoch: 440, train_error(A): 0.08468363434076309, test_error(B): 0.1308729648590088, B-A: 0.0461893305182457\n",
            "epoch: 442, train_error(A): 0.08464598655700684, test_error(B): 0.13023030757904053, B-A: 0.04558432102203369\n",
            "epoch: 444, train_error(A): 0.0846293643116951, test_error(B): 0.12898001074790955, B-A: 0.04435064643621445\n",
            "epoch: 446, train_error(A): 0.08471035212278366, test_error(B): 0.12638802826404572, B-A: 0.041677676141262054\n",
            "epoch: 448, train_error(A): 0.08506210893392563, test_error(B): 0.12231362611055374, B-A: 0.03725151717662811\n",
            "epoch: 450, train_error(A): 0.08490105718374252, test_error(B): 0.12325489521026611, B-A: 0.03835383802652359\n",
            "epoch: 452, train_error(A): 0.08453782647848129, test_error(B): 0.13353696465492249, B-A: 0.04899913817644119\n",
            "epoch: 454, train_error(A): 0.08472603559494019, test_error(B): 0.13648928701877594, B-A: 0.051763251423835754\n",
            "epoch: 456, train_error(A): 0.08447317034006119, test_error(B): 0.12725332379341125, B-A: 0.04278015345335007\n",
            "epoch: 458, train_error(A): 0.08452428132295609, test_error(B): 0.12577594816684723, B-A: 0.041251666843891144\n",
            "epoch: 460, train_error(A): 0.08445634692907333, test_error(B): 0.13352827727794647, B-A: 0.04907193034887314\n",
            "epoch: 462, train_error(A): 0.0843752846121788, test_error(B): 0.1320546418428421, B-A: 0.0476793572306633\n",
            "epoch: 464, train_error(A): 0.08441861718893051, test_error(B): 0.12600970268249512, B-A: 0.041591085493564606\n",
            "epoch: 466, train_error(A): 0.08429461717605591, test_error(B): 0.1292732059955597, B-A: 0.044978588819503784\n",
            "epoch: 468, train_error(A): 0.0843493863940239, test_error(B): 0.13275815546512604, B-A: 0.04840876907110214\n",
            "epoch: 470, train_error(A): 0.08425965905189514, test_error(B): 0.12845757603645325, B-A: 0.044197916984558105\n",
            "epoch: 472, train_error(A): 0.0842704027891159, test_error(B): 0.12710446119308472, B-A: 0.04283405840396881\n",
            "epoch: 474, train_error(A): 0.08423388749361038, test_error(B): 0.1308896541595459, B-A: 0.046655766665935516\n",
            "epoch: 476, train_error(A): 0.08420783281326294, test_error(B): 0.1304648518562317, B-A: 0.04625701904296875\n",
            "epoch: 478, train_error(A): 0.08420088142156601, test_error(B): 0.12737587094306946, B-A: 0.04317498952150345\n",
            "epoch: 480, train_error(A): 0.08416271954774857, test_error(B): 0.1285310536623001, B-A: 0.044368334114551544\n",
            "epoch: 482, train_error(A): 0.08416277170181274, test_error(B): 0.13056324422359467, B-A: 0.04640047252178192\n",
            "epoch: 484, train_error(A): 0.08412770926952362, test_error(B): 0.12894974648952484, B-A: 0.04482203722000122\n",
            "epoch: 486, train_error(A): 0.08412455767393112, test_error(B): 0.12757498025894165, B-A: 0.04345042258501053\n",
            "epoch: 488, train_error(A): 0.08409687131643295, test_error(B): 0.12903577089309692, B-A: 0.04493889957666397\n",
            "epoch: 490, train_error(A): 0.08408953249454498, test_error(B): 0.12977845966815948, B-A: 0.0456889271736145\n",
            "epoch: 492, train_error(A): 0.08406766504049301, test_error(B): 0.12837474048137665, B-A: 0.044307075440883636\n",
            "epoch: 494, train_error(A): 0.08405780792236328, test_error(B): 0.1278129667043686, B-A: 0.04375515878200531\n",
            "epoch: 496, train_error(A): 0.08403955399990082, test_error(B): 0.12886840105056763, B-A: 0.04482884705066681\n",
            "epoch: 498, train_error(A): 0.08402885496616364, test_error(B): 0.1291847825050354, B-A: 0.045155927538871765\n",
            "epoch: 500, train_error(A): 0.08401264995336533, test_error(B): 0.12823611497879028, B-A: 0.04422346502542496\n",
            "epoch: 502, train_error(A): 0.08400195091962814, test_error(B): 0.12783785164356232, B-A: 0.043835900723934174\n",
            "epoch: 504, train_error(A): 0.08398707211017609, test_error(B): 0.1284712553024292, B-A: 0.04448418319225311\n",
            "epoch: 506, train_error(A): 0.08397660404443741, test_error(B): 0.12880001962184906, B-A: 0.04482341557741165\n",
            "epoch: 508, train_error(A): 0.08396288007497787, test_error(B): 0.12828005850315094, B-A: 0.044317178428173065\n",
            "epoch: 510, train_error(A): 0.08395247906446457, test_error(B): 0.1278289258480072, B-A: 0.04387644678354263\n",
            "epoch: 512, train_error(A): 0.0839400514960289, test_error(B): 0.12805287539958954, B-A: 0.04411282390356064\n",
            "epoch: 514, train_error(A): 0.08392942696809769, test_error(B): 0.12842589616775513, B-A: 0.04449646919965744\n",
            "epoch: 516, train_error(A): 0.08391837030649185, test_error(B): 0.12833134829998016, B-A: 0.04441297799348831\n",
            "epoch: 518, train_error(A): 0.08390749990940094, test_error(B): 0.12794163823127747, B-A: 0.044034138321876526\n",
            "epoch: 520, train_error(A): 0.08389747887849808, test_error(B): 0.12778188288211823, B-A: 0.04388440400362015\n",
            "epoch: 522, train_error(A): 0.08388686180114746, test_error(B): 0.12795883417129517, B-A: 0.044071972370147705\n",
            "epoch: 524, train_error(A): 0.08387717604637146, test_error(B): 0.1281411498785019, B-A: 0.04426397383213043\n",
            "epoch: 526, train_error(A): 0.08386735618114471, test_error(B): 0.12807227671146393, B-A: 0.044204920530319214\n",
            "epoch: 528, train_error(A): 0.08385766297578812, test_error(B): 0.12784355878829956, B-A: 0.043985895812511444\n",
            "epoch: 530, train_error(A): 0.0838484913110733, test_error(B): 0.12769722938537598, B-A: 0.04384873807430267\n",
            "epoch: 532, train_error(A): 0.08383920788764954, test_error(B): 0.12773074209690094, B-A: 0.043891534209251404\n",
            "epoch: 534, train_error(A): 0.08383017033338547, test_error(B): 0.12784211337566376, B-A: 0.04401194304227829\n",
            "epoch: 536, train_error(A): 0.08382144570350647, test_error(B): 0.12788543105125427, B-A: 0.0440639853477478\n",
            "epoch: 538, train_error(A): 0.08381272852420807, test_error(B): 0.12781500816345215, B-A: 0.04400227963924408\n",
            "epoch: 540, train_error(A): 0.0838041752576828, test_error(B): 0.12769155204296112, B-A: 0.04388737678527832\n",
            "epoch: 542, train_error(A): 0.08379588276147842, test_error(B): 0.12759867310523987, B-A: 0.043802790343761444\n",
            "epoch: 544, train_error(A): 0.08378766477108002, test_error(B): 0.12757337093353271, B-A: 0.0437857061624527\n",
            "epoch: 546, train_error(A): 0.08377955108880997, test_error(B): 0.12759816646575928, B-A: 0.04381861537694931\n",
            "epoch: 548, train_error(A): 0.08377160876989365, test_error(B): 0.12763303518295288, B-A: 0.043861426413059235\n",
            "epoch: 550, train_error(A): 0.08376382291316986, test_error(B): 0.12764617800712585, B-A: 0.043882355093955994\n",
            "epoch: 552, train_error(A): 0.08375613391399384, test_error(B): 0.1276272088289261, B-A: 0.04387107491493225\n",
            "epoch: 554, train_error(A): 0.08374854922294617, test_error(B): 0.12758399546146393, B-A: 0.04383544623851776\n",
            "epoch: 556, train_error(A): 0.08374107629060745, test_error(B): 0.12753194570541382, B-A: 0.043790869414806366\n",
            "epoch: 558, train_error(A): 0.08373373001813889, test_error(B): 0.12748302519321442, B-A: 0.04374929517507553\n",
            "epoch: 560, train_error(A): 0.08372649550437927, test_error(B): 0.1274421066045761, B-A: 0.04371561110019684\n",
            "epoch: 562, train_error(A): 0.08371936529874802, test_error(B): 0.127408966422081, B-A: 0.04368960112333298\n",
            "epoch: 564, train_error(A): 0.08371232450008392, test_error(B): 0.1273808479309082, B-A: 0.04366852343082428\n",
            "epoch: 566, train_error(A): 0.08370538055896759, test_error(B): 0.12735389173030853, B-A: 0.04364851117134094\n",
            "epoch: 568, train_error(A): 0.08369854092597961, test_error(B): 0.12732313573360443, B-A: 0.04362459480762482\n",
            "epoch: 570, train_error(A): 0.0836917981505394, test_error(B): 0.12728270888328552, B-A: 0.043590910732746124\n",
            "epoch: 572, train_error(A): 0.08368518203496933, test_error(B): 0.1272241473197937, B-A: 0.04353896528482437\n",
            "epoch: 574, train_error(A): 0.08367878943681717, test_error(B): 0.12713152170181274, B-A: 0.043452732264995575\n",
            "epoch: 576, train_error(A): 0.083672896027565, test_error(B): 0.12697315216064453, B-A: 0.04330025613307953\n",
            "epoch: 578, train_error(A): 0.08366856724023819, test_error(B): 0.12668439745903015, B-A: 0.04301583021879196\n",
            "epoch: 580, train_error(A): 0.08366985619068146, test_error(B): 0.12613052129745483, B-A: 0.042460665106773376\n",
            "epoch: 582, train_error(A): 0.08369287103414536, test_error(B): 0.12503598630428314, B-A: 0.04134311527013779\n",
            "epoch: 584, train_error(A): 0.08379706740379333, test_error(B): 0.12292952090501785, B-A: 0.03913245350122452\n",
            "epoch: 586, train_error(A): 0.08409920334815979, test_error(B): 0.11972133070230484, B-A: 0.03562212735414505\n",
            "epoch: 588, train_error(A): 0.08421524614095688, test_error(B): 0.11881010234355927, B-A: 0.034594856202602386\n",
            "epoch: 590, train_error(A): 0.08365069329738617, test_error(B): 0.12568868696689606, B-A: 0.04203799366950989\n",
            "epoch: 592, train_error(A): 0.08390670269727707, test_error(B): 0.13326701521873474, B-A: 0.04936031252145767\n",
            "epoch: 594, train_error(A): 0.08371967822313309, test_error(B): 0.13080479204654694, B-A: 0.04708511382341385\n",
            "epoch: 596, train_error(A): 0.08373579382896423, test_error(B): 0.12337037175893784, B-A: 0.0396345779299736\n",
            "epoch: 598, train_error(A): 0.08370457589626312, test_error(B): 0.12379936873912811, B-A: 0.04009479284286499\n",
            "epoch: 600, train_error(A): 0.08366814255714417, test_error(B): 0.13003221154212952, B-A: 0.04636406898498535\n",
            "epoch: 602, train_error(A): 0.08367115259170532, test_error(B): 0.13017475605010986, B-A: 0.04650360345840454\n",
            "epoch: 604, train_error(A): 0.08363114297389984, test_error(B): 0.12500989437103271, B-A: 0.041378751397132874\n",
            "epoch: 606, train_error(A): 0.0836406797170639, test_error(B): 0.1246081292629242, B-A: 0.04096744954586029\n",
            "epoch: 608, train_error(A): 0.08360601961612701, test_error(B): 0.1287459433078766, B-A: 0.04513992369174957\n",
            "epoch: 610, train_error(A): 0.08361715078353882, test_error(B): 0.12924885749816895, B-A: 0.04563170671463013\n",
            "epoch: 612, train_error(A): 0.08358640223741531, test_error(B): 0.12588118016719818, B-A: 0.04229477792978287\n",
            "epoch: 614, train_error(A): 0.0835978239774704, test_error(B): 0.12522076070308685, B-A: 0.041622936725616455\n",
            "epoch: 616, train_error(A): 0.0835704430937767, test_error(B): 0.1278706043958664, B-A: 0.04430016130208969\n",
            "epoch: 618, train_error(A): 0.08358139544725418, test_error(B): 0.1286868304014206, B-A: 0.04510543495416641\n",
            "epoch: 620, train_error(A): 0.08355729281902313, test_error(B): 0.12663564085960388, B-A: 0.04307834804058075\n",
            "epoch: 622, train_error(A): 0.0835663303732872, test_error(B): 0.12568973004817963, B-A: 0.042123399674892426\n",
            "epoch: 624, train_error(A): 0.08354636281728745, test_error(B): 0.1271752119064331, B-A: 0.04362884908914566\n",
            "epoch: 626, train_error(A): 0.08355219662189484, test_error(B): 0.12822021543979645, B-A: 0.04466801881790161\n",
            "epoch: 628, train_error(A): 0.08353708684444427, test_error(B): 0.12723511457443237, B-A: 0.0436980277299881\n",
            "epoch: 630, train_error(A): 0.08353850990533829, test_error(B): 0.126144140958786, B-A: 0.04260563105344772\n",
            "epoch: 632, train_error(A): 0.0835288017988205, test_error(B): 0.126611590385437, B-A: 0.043082788586616516\n",
            "epoch: 634, train_error(A): 0.08352555334568024, test_error(B): 0.1276138871908188, B-A: 0.04408833384513855\n",
            "epoch: 636, train_error(A): 0.08352057635784149, test_error(B): 0.12756560742855072, B-A: 0.04404503107070923\n",
            "epoch: 638, train_error(A): 0.08351393043994904, test_error(B): 0.12673094868659973, B-A: 0.043217018246650696\n",
            "epoch: 640, train_error(A): 0.08351141214370728, test_error(B): 0.1264098584651947, B-A: 0.04289844632148743\n",
            "epoch: 642, train_error(A): 0.08350416272878647, test_error(B): 0.12691667675971985, B-A: 0.04341251403093338\n",
            "epoch: 644, train_error(A): 0.08350107818841934, test_error(B): 0.12741228938102722, B-A: 0.04391121119260788\n",
            "epoch: 646, train_error(A): 0.0834956243634224, test_error(B): 0.12726210057735443, B-A: 0.04376647621393204\n",
            "epoch: 648, train_error(A): 0.08349061757326126, test_error(B): 0.12677574157714844, B-A: 0.043285124003887177\n",
            "epoch: 650, train_error(A): 0.08348681032657623, test_error(B): 0.12659332156181335, B-A: 0.04310651123523712\n",
            "epoch: 652, train_error(A): 0.08348128944635391, test_error(B): 0.12685416638851166, B-A: 0.043372876942157745\n",
            "epoch: 654, train_error(A): 0.08347710222005844, test_error(B): 0.12716902792453766, B-A: 0.04369192570447922\n",
            "epoch: 656, train_error(A): 0.08347263932228088, test_error(B): 0.12717986106872559, B-A: 0.0437072217464447\n",
            "epoch: 658, train_error(A): 0.08346763253211975, test_error(B): 0.12693040072917938, B-A: 0.04346276819705963\n",
            "epoch: 660, train_error(A): 0.08346343785524368, test_error(B): 0.126715749502182, B-A: 0.043252311646938324\n",
            "epoch: 662, train_error(A): 0.08345889300107956, test_error(B): 0.1267252117395401, B-A: 0.04326631873846054\n",
            "epoch: 664, train_error(A): 0.08345416188240051, test_error(B): 0.1268940567970276, B-A: 0.043439894914627075\n",
            "epoch: 666, train_error(A): 0.08344985544681549, test_error(B): 0.12703324854373932, B-A: 0.04358339309692383\n",
            "epoch: 668, train_error(A): 0.08344540745019913, test_error(B): 0.12702812254428864, B-A: 0.04358271509408951\n",
            "epoch: 670, train_error(A): 0.08344081044197083, test_error(B): 0.12691020965576172, B-A: 0.043469399213790894\n",
            "epoch: 672, train_error(A): 0.08343640714883804, test_error(B): 0.12678682804107666, B-A: 0.04335042089223862\n",
            "epoch: 674, train_error(A): 0.08343205600976944, test_error(B): 0.12673908472061157, B-A: 0.04330702871084213\n",
            "epoch: 676, train_error(A): 0.08342757076025009, test_error(B): 0.1267756074666977, B-A: 0.0433480367064476\n",
            "epoch: 678, train_error(A): 0.08342312276363373, test_error(B): 0.1268509030342102, B-A: 0.04342778027057648\n",
            "epoch: 680, train_error(A): 0.08341877162456512, test_error(B): 0.1269099861383438, B-A: 0.043491214513778687\n",
            "epoch: 682, train_error(A): 0.08341440558433533, test_error(B): 0.12692247331142426, B-A: 0.04350806772708893\n",
            "epoch: 684, train_error(A): 0.08341000974178314, test_error(B): 0.1268913447856903, B-A: 0.043481335043907166\n",
            "epoch: 686, train_error(A): 0.08340561389923096, test_error(B): 0.1268390715122223, B-A: 0.04343345761299133\n",
            "epoch: 688, train_error(A): 0.08340125530958176, test_error(B): 0.1267889142036438, B-A: 0.04338765889406204\n",
            "epoch: 690, train_error(A): 0.08339691907167435, test_error(B): 0.12675444781780243, B-A: 0.04335752874612808\n",
            "epoch: 692, train_error(A): 0.08339259028434753, test_error(B): 0.12673833966255188, B-A: 0.043345749378204346\n",
            "epoch: 694, train_error(A): 0.08338825404644012, test_error(B): 0.12673702836036682, B-A: 0.0433487743139267\n",
            "epoch: 696, train_error(A): 0.08338392525911331, test_error(B): 0.1267441213130951, B-A: 0.04336019605398178\n",
            "epoch: 698, train_error(A): 0.0833795964717865, test_error(B): 0.12675334513187408, B-A: 0.043373748660087585\n",
            "epoch: 700, train_error(A): 0.08337528258562088, test_error(B): 0.12676109373569489, B-A: 0.043385811150074005\n",
            "epoch: 702, train_error(A): 0.08337097615003586, test_error(B): 0.12676630914211273, B-A: 0.043395332992076874\n",
            "epoch: 704, train_error(A): 0.08336668461561203, test_error(B): 0.12676961719989777, B-A: 0.043402932584285736\n",
            "epoch: 706, train_error(A): 0.0833624079823494, test_error(B): 0.1267719715833664, B-A: 0.043409563601017\n",
            "epoch: 708, train_error(A): 0.08335813134908676, test_error(B): 0.12677517533302307, B-A: 0.04341704398393631\n",
            "epoch: 710, train_error(A): 0.08335386216640472, test_error(B): 0.12678220868110657, B-A: 0.04342834651470184\n",
            "epoch: 712, train_error(A): 0.08334961533546448, test_error(B): 0.12679749727249146, B-A: 0.04344788193702698\n",
            "epoch: 714, train_error(A): 0.08334540575742722, test_error(B): 0.12682828307151794, B-A: 0.04348287731409073\n",
            "epoch: 716, train_error(A): 0.08334130048751831, test_error(B): 0.1268891990184784, B-A: 0.04354789853096008\n",
            "epoch: 718, train_error(A): 0.08333751559257507, test_error(B): 0.12700894474983215, B-A: 0.04367142915725708\n",
            "epoch: 720, train_error(A): 0.08333490043878555, test_error(B): 0.1272466778755188, B-A: 0.043911777436733246\n",
            "epoch: 722, train_error(A): 0.0833367183804512, test_error(B): 0.12772662937641144, B-A: 0.044389910995960236\n",
            "epoch: 724, train_error(A): 0.08335637301206589, test_error(B): 0.12871120870113373, B-A: 0.04535483568906784\n",
            "epoch: 726, train_error(A): 0.08344766497612, test_error(B): 0.13071641325950623, B-A: 0.04726874828338623\n",
            "epoch: 728, train_error(A): 0.08376991003751755, test_error(B): 0.13432860374450684, B-A: 0.05055869370698929\n",
            "epoch: 730, train_error(A): 0.08421460539102554, test_error(B): 0.13754336535930634, B-A: 0.05332875996828079\n",
            "epoch: 732, train_error(A): 0.08354927599430084, test_error(B): 0.13229520618915558, B-A: 0.048745930194854736\n",
            "epoch: 734, train_error(A): 0.08351629227399826, test_error(B): 0.12160510569810867, B-A: 0.03808881342411041\n",
            "epoch: 736, train_error(A): 0.08361205458641052, test_error(B): 0.12049302458763123, B-A: 0.0368809700012207\n",
            "epoch: 738, train_error(A): 0.08336144685745239, test_error(B): 0.12948711216449738, B-A: 0.04612566530704498\n",
            "epoch: 740, train_error(A): 0.08351936936378479, test_error(B): 0.13204126060009003, B-A: 0.04852189123630524\n",
            "epoch: 742, train_error(A): 0.0833277478814125, test_error(B): 0.12457859516143799, B-A: 0.04125084728002548\n",
            "epoch: 744, train_error(A): 0.08343058824539185, test_error(B): 0.12241006642580032, B-A: 0.03897947818040848\n",
            "epoch: 746, train_error(A): 0.08331302553415298, test_error(B): 0.12845808267593384, B-A: 0.04514505714178085\n",
            "epoch: 748, train_error(A): 0.08337083458900452, test_error(B): 0.12994913756847382, B-A: 0.0465783029794693\n",
            "epoch: 750, train_error(A): 0.08330205082893372, test_error(B): 0.12484648078680038, B-A: 0.04154442995786667\n",
            "epoch: 752, train_error(A): 0.08332949876785278, test_error(B): 0.12391727417707443, B-A: 0.04058777540922165\n",
            "epoch: 754, train_error(A): 0.08329064399003983, test_error(B): 0.1280621588230133, B-A: 0.04477151483297348\n",
            "epoch: 756, train_error(A): 0.08330215513706207, test_error(B): 0.12861020863056183, B-A: 0.045308053493499756\n",
            "epoch: 758, train_error(A): 0.08327903598546982, test_error(B): 0.1252182126045227, B-A: 0.04193917661905289\n",
            "epoch: 760, train_error(A): 0.08328262716531754, test_error(B): 0.12491097301244736, B-A: 0.04162834584712982\n",
            "epoch: 762, train_error(A): 0.08326784521341324, test_error(B): 0.127671018242836, B-A: 0.04440317302942276\n",
            "epoch: 764, train_error(A): 0.08326846361160278, test_error(B): 0.1278998851776123, B-A: 0.04463142156600952\n",
            "epoch: 766, train_error(A): 0.08325739204883575, test_error(B): 0.1256733536720276, B-A: 0.042415961623191833\n",
            "epoch: 768, train_error(A): 0.0832572877407074, test_error(B): 0.12545077502727509, B-A: 0.04219348728656769\n",
            "epoch: 770, train_error(A): 0.08324771374464035, test_error(B): 0.12722913920879364, B-A: 0.04398142546415329\n",
            "epoch: 772, train_error(A): 0.08324787020683289, test_error(B): 0.12750238180160522, B-A: 0.04425451159477234\n",
            "epoch: 774, train_error(A): 0.08323876559734344, test_error(B): 0.12607204914093018, B-A: 0.04283328354358673\n",
            "epoch: 776, train_error(A): 0.08323925733566284, test_error(B): 0.12567734718322754, B-A: 0.0424380898475647\n",
            "epoch: 778, train_error(A): 0.08323059976100922, test_error(B): 0.12675373256206512, B-A: 0.04352313280105591\n",
            "epoch: 780, train_error(A): 0.08323099464178085, test_error(B): 0.127239391207695, B-A: 0.044008396565914154\n",
            "epoch: 782, train_error(A): 0.08322318643331528, test_error(B): 0.12645652890205383, B-A: 0.043233342468738556\n",
            "epoch: 784, train_error(A): 0.08322273939847946, test_error(B): 0.1258789598941803, B-A: 0.042656220495700836\n",
            "epoch: 786, train_error(A): 0.08321639895439148, test_error(B): 0.1263483613729477, B-A: 0.04313196241855621\n",
            "epoch: 788, train_error(A): 0.08321449160575867, test_error(B): 0.12694209814071655, B-A: 0.043727606534957886\n",
            "epoch: 790, train_error(A): 0.08320990204811096, test_error(B): 0.12674731016159058, B-A: 0.043537408113479614\n",
            "epoch: 792, train_error(A): 0.08320649713277817, test_error(B): 0.12619467079639435, B-A: 0.04298817366361618\n",
            "epoch: 794, train_error(A): 0.08320330083370209, test_error(B): 0.12613117694854736, B-A: 0.042927876114845276\n",
            "epoch: 796, train_error(A): 0.08319904655218124, test_error(B): 0.1265375167131424, B-A: 0.04333847016096115\n",
            "epoch: 798, train_error(A): 0.08319631963968277, test_error(B): 0.1267561912536621, B-A: 0.04355987161397934\n",
            "epoch: 800, train_error(A): 0.08319216966629028, test_error(B): 0.12652131915092468, B-A: 0.0433291494846344\n",
            "epoch: 802, train_error(A): 0.08318904042243958, test_error(B): 0.1262163668870926, B-A: 0.043027326464653015\n",
            "epoch: 804, train_error(A): 0.08318553864955902, test_error(B): 0.12622927129268646, B-A: 0.04304373264312744\n",
            "epoch: 806, train_error(A): 0.08318185061216354, test_error(B): 0.1264694631099701, B-A: 0.04328761249780655\n",
            "epoch: 808, train_error(A): 0.08317868411540985, test_error(B): 0.12659336626529694, B-A: 0.043414682149887085\n",
            "epoch: 810, train_error(A): 0.08317501097917557, test_error(B): 0.12647172808647156, B-A: 0.04329671710729599\n",
            "epoch: 812, train_error(A): 0.08317162096500397, test_error(B): 0.12628400325775146, B-A: 0.0431123822927475\n",
            "epoch: 814, train_error(A): 0.08316826075315475, test_error(B): 0.1262405663728714, B-A: 0.043072305619716644\n",
            "epoch: 816, train_error(A): 0.08316468447446823, test_error(B): 0.12634900212287903, B-A: 0.0431843176484108\n",
            "epoch: 818, train_error(A): 0.08316131681203842, test_error(B): 0.126460000872612, B-A: 0.04329868406057358\n",
            "epoch: 820, train_error(A): 0.08315788954496384, test_error(B): 0.12645821273326874, B-A: 0.0433003231883049\n",
            "epoch: 822, train_error(A): 0.08315438777208328, test_error(B): 0.1263638585805893, B-A: 0.04320947080850601\n",
            "epoch: 824, train_error(A): 0.08315099775791168, test_error(B): 0.12627564370632172, B-A: 0.043124645948410034\n",
            "epoch: 826, train_error(A): 0.0831475704908371, test_error(B): 0.1262623518705368, B-A: 0.04311478137969971\n",
            "epoch: 828, train_error(A): 0.08314409852027893, test_error(B): 0.12631331384181976, B-A: 0.04316921532154083\n",
            "epoch: 830, train_error(A): 0.08314067125320435, test_error(B): 0.12636946141719818, B-A: 0.043228790163993835\n",
            "epoch: 832, train_error(A): 0.08313725143671036, test_error(B): 0.1263820230960846, B-A: 0.04324477165937424\n",
            "epoch: 834, train_error(A): 0.08313379436731339, test_error(B): 0.12634649872779846, B-A: 0.04321270436048508\n",
            "epoch: 836, train_error(A): 0.08313034474849701, test_error(B): 0.12629352509975433, B-A: 0.043163180351257324\n",
            "epoch: 838, train_error(A): 0.08312691748142242, test_error(B): 0.12625718116760254, B-A: 0.043130263686180115\n",
            "epoch: 840, train_error(A): 0.08312346786260605, test_error(B): 0.12625150382518768, B-A: 0.043128035962581635\n",
            "epoch: 842, train_error(A): 0.08312001079320908, test_error(B): 0.12626858055591583, B-A: 0.04314856976270676\n",
            "epoch: 844, train_error(A): 0.0831165537238121, test_error(B): 0.12629111111164093, B-A: 0.04317455738782883\n",
            "epoch: 846, train_error(A): 0.08311310410499573, test_error(B): 0.12630440294742584, B-A: 0.043191298842430115\n",
            "epoch: 848, train_error(A): 0.08310964703559875, test_error(B): 0.12630236148834229, B-A: 0.04319271445274353\n",
            "epoch: 850, train_error(A): 0.08310617506504059, test_error(B): 0.12628740072250366, B-A: 0.043181225657463074\n",
            "epoch: 852, train_error(A): 0.08310269564390182, test_error(B): 0.12626659870147705, B-A: 0.043163903057575226\n",
            "epoch: 854, train_error(A): 0.08309922367334366, test_error(B): 0.12624657154083252, B-A: 0.04314734786748886\n",
            "epoch: 856, train_error(A): 0.0830957368016243, test_error(B): 0.12623095512390137, B-A: 0.04313521832227707\n",
            "epoch: 858, train_error(A): 0.08309224247932434, test_error(B): 0.12622083723545074, B-A: 0.043128594756126404\n",
            "epoch: 860, train_error(A): 0.08308874815702438, test_error(B): 0.12621520459651947, B-A: 0.04312645643949509\n",
            "epoch: 862, train_error(A): 0.08308524638414383, test_error(B): 0.12621228396892548, B-A: 0.04312703758478165\n",
            "epoch: 864, train_error(A): 0.08308172971010208, test_error(B): 0.1262105405330658, B-A: 0.043128810822963715\n",
            "epoch: 866, train_error(A): 0.08307821303606033, test_error(B): 0.12620854377746582, B-A: 0.04313033074140549\n",
            "epoch: 868, train_error(A): 0.0830746740102768, test_error(B): 0.12620599567890167, B-A: 0.04313132166862488\n",
            "epoch: 870, train_error(A): 0.08307114243507385, test_error(B): 0.12620244920253754, B-A: 0.043131306767463684\n",
            "epoch: 872, train_error(A): 0.08306760340929031, test_error(B): 0.12619778513908386, B-A: 0.04313018172979355\n",
            "epoch: 874, train_error(A): 0.08306404948234558, test_error(B): 0.12619148194789886, B-A: 0.043127432465553284\n",
            "epoch: 876, train_error(A): 0.08306048810482025, test_error(B): 0.1261833757162094, B-A: 0.04312288761138916\n",
            "epoch: 878, train_error(A): 0.08305691927671432, test_error(B): 0.12617260217666626, B-A: 0.043115682899951935\n",
            "epoch: 880, train_error(A): 0.0830533429980278, test_error(B): 0.12615716457366943, B-A: 0.04310382157564163\n",
            "epoch: 882, train_error(A): 0.08304976671934128, test_error(B): 0.1261325478553772, B-A: 0.04308278113603592\n",
            "epoch: 884, train_error(A): 0.08304622769355774, test_error(B): 0.1260910928249359, B-A: 0.043044865131378174\n",
            "epoch: 886, train_error(A): 0.08304275572299957, test_error(B): 0.12601694464683533, B-A: 0.042974188923835754\n",
            "epoch: 888, train_error(A): 0.08303962647914886, test_error(B): 0.12587633728981018, B-A: 0.042836710810661316\n",
            "epoch: 890, train_error(A): 0.08303787559270859, test_error(B): 0.12559665739536285, B-A: 0.042558781802654266\n",
            "epoch: 892, train_error(A): 0.08304202556610107, test_error(B): 0.12501972913742065, B-A: 0.04197770357131958\n",
            "epoch: 894, train_error(A): 0.08307237178087234, test_error(B): 0.12380165606737137, B-A: 0.04072928428649902\n",
            "epoch: 896, train_error(A): 0.08321751654148102, test_error(B): 0.1212642714381218, B-A: 0.03804675489664078\n",
            "epoch: 898, train_error(A): 0.08374959975481033, test_error(B): 0.11673904955387115, B-A: 0.03298944979906082\n",
            "epoch: 900, train_error(A): 0.08435069024562836, test_error(B): 0.11354924738407135, B-A: 0.029198557138442993\n",
            "epoch: 902, train_error(A): 0.0831763744354248, test_error(B): 0.12184099107980728, B-A: 0.03866461664438248\n",
            "epoch: 904, train_error(A): 0.08356410264968872, test_error(B): 0.13455083966255188, B-A: 0.05098673701286316\n",
            "epoch: 906, train_error(A): 0.08321209251880646, test_error(B): 0.13114725053310394, B-A: 0.047935158014297485\n",
            "epoch: 908, train_error(A): 0.08334148675203323, test_error(B): 0.11984115839004517, B-A: 0.03649967163801193\n",
            "epoch: 910, train_error(A): 0.08309341967105865, test_error(B): 0.12297491729259491, B-A: 0.039881497621536255\n",
            "epoch: 912, train_error(A): 0.08327391743659973, test_error(B): 0.13196951150894165, B-A: 0.04869559407234192\n",
            "epoch: 914, train_error(A): 0.08301404118537903, test_error(B): 0.12732049822807312, B-A: 0.04430645704269409\n",
            "epoch: 916, train_error(A): 0.08319566398859024, test_error(B): 0.12109928578138351, B-A: 0.037903621792793274\n",
            "epoch: 918, train_error(A): 0.08299524337053299, test_error(B): 0.1263154149055481, B-A: 0.043320171535015106\n",
            "epoch: 920, train_error(A): 0.08312065899372101, test_error(B): 0.1300261914730072, B-A: 0.046905532479286194\n",
            "epoch: 922, train_error(A): 0.08300328999757767, test_error(B): 0.12461671233177185, B-A: 0.04161342233419418\n",
            "epoch: 924, train_error(A): 0.08305308222770691, test_error(B): 0.12308038026094437, B-A: 0.04002729803323746\n",
            "epoch: 926, train_error(A): 0.08301093429327011, test_error(B): 0.12785735726356506, B-A: 0.04484642297029495\n",
            "epoch: 928, train_error(A): 0.08300802856683731, test_error(B): 0.12787146866321564, B-A: 0.044863440096378326\n",
            "epoch: 930, train_error(A): 0.08300916850566864, test_error(B): 0.12401216477155685, B-A: 0.041002996265888214\n",
            "epoch: 932, train_error(A): 0.08298242092132568, test_error(B): 0.12501758337020874, B-A: 0.04203516244888306\n",
            "epoch: 934, train_error(A): 0.08299975842237473, test_error(B): 0.1279323697090149, B-A: 0.04493261128664017\n",
            "epoch: 936, train_error(A): 0.08296965807676315, test_error(B): 0.12641766667366028, B-A: 0.043448008596897125\n",
            "epoch: 938, train_error(A): 0.08298645913600922, test_error(B): 0.12442483007907867, B-A: 0.04143837094306946\n",
            "epoch: 940, train_error(A): 0.08296273648738861, test_error(B): 0.1260531097650528, B-A: 0.043090373277664185\n",
            "epoch: 942, train_error(A): 0.08297357708215714, test_error(B): 0.12733601033687592, B-A: 0.04436243325471878\n",
            "epoch: 944, train_error(A): 0.08295723795890808, test_error(B): 0.12576767802238464, B-A: 0.04281044006347656\n",
            "epoch: 946, train_error(A): 0.08296246826648712, test_error(B): 0.12494930624961853, B-A: 0.04198683798313141\n",
            "epoch: 948, train_error(A): 0.08295158296823502, test_error(B): 0.1262887418270111, B-A: 0.04333715885877609\n",
            "epoch: 950, train_error(A): 0.08295333385467529, test_error(B): 0.12680482864379883, B-A: 0.043851494789123535\n",
            "epoch: 952, train_error(A): 0.08294560015201569, test_error(B): 0.12567342817783356, B-A: 0.04272782802581787\n",
            "epoch: 954, train_error(A): 0.08294547349214554, test_error(B): 0.1253000646829605, B-A: 0.04235459119081497\n",
            "epoch: 956, train_error(A): 0.08293940871953964, test_error(B): 0.12620976567268372, B-A: 0.043270356953144073\n",
            "epoch: 958, train_error(A): 0.08293837308883667, test_error(B): 0.12651264667510986, B-A: 0.04357427358627319\n",
            "epoch: 960, train_error(A): 0.08293318748474121, test_error(B): 0.12577994167804718, B-A: 0.04284675419330597\n",
            "epoch: 962, train_error(A): 0.08293168991804123, test_error(B): 0.12548358738422394, B-A: 0.04255189746618271\n",
            "epoch: 964, train_error(A): 0.08292704820632935, test_error(B): 0.12603574991226196, B-A: 0.04310870170593262\n",
            "epoch: 966, train_error(A): 0.0829252228140831, test_error(B): 0.12632213532924652, B-A: 0.04339691251516342\n",
            "epoch: 968, train_error(A): 0.08292100578546524, test_error(B): 0.12590070068836212, B-A: 0.04297969490289688\n",
            "epoch: 970, train_error(A): 0.08291886746883392, test_error(B): 0.12558618187904358, B-A: 0.042667314410209656\n",
            "epoch: 972, train_error(A): 0.0829150527715683, test_error(B): 0.12584874033927917, B-A: 0.042933687567710876\n",
            "epoch: 974, train_error(A): 0.08291256427764893, test_error(B): 0.12614460289478302, B-A: 0.043232038617134094\n",
            "epoch: 976, train_error(A): 0.08290915191173553, test_error(B): 0.1259925365447998, B-A: 0.04308338463306427\n",
            "epoch: 978, train_error(A): 0.0829063281416893, test_error(B): 0.12569941580295563, B-A: 0.04279308766126633\n",
            "epoch: 980, train_error(A): 0.08290326595306396, test_error(B): 0.12571890652179718, B-A: 0.042815640568733215\n",
            "epoch: 982, train_error(A): 0.08290018141269684, test_error(B): 0.12594959139823914, B-A: 0.0430494099855423\n",
            "epoch: 984, train_error(A): 0.08289731293916702, test_error(B): 0.12600892782211304, B-A: 0.043111614882946014\n",
            "epoch: 986, train_error(A): 0.08289413899183273, test_error(B): 0.12583786249160767, B-A: 0.04294372349977493\n",
            "epoch: 988, train_error(A): 0.08289129287004471, test_error(B): 0.12570761144161224, B-A: 0.042816318571567535\n",
            "epoch: 990, train_error(A): 0.08288818597793579, test_error(B): 0.12577593326568604, B-A: 0.042887747287750244\n",
            "epoch: 992, train_error(A): 0.08288522809743881, test_error(B): 0.1259051114320755, B-A: 0.04301988333463669\n",
            "epoch: 994, train_error(A): 0.08288225531578064, test_error(B): 0.12590859830379486, B-A: 0.04302634298801422\n",
            "epoch: 996, train_error(A): 0.0828792005777359, test_error(B): 0.125798299908638, B-A: 0.0429190993309021\n",
            "epoch: 998, train_error(A): 0.08287625759840012, test_error(B): 0.12572279572486877, B-A: 0.04284653812646866\n",
            "epoch: 1000, train_error(A): 0.08287323266267776, test_error(B): 0.12575560808181763, B-A: 0.04288237541913986\n",
            "epoch: 1002, train_error(A): 0.0828702449798584, test_error(B): 0.12582793831825256, B-A: 0.042957693338394165\n",
            "epoch: 1004, train_error(A): 0.08286726474761963, test_error(B): 0.1258428394794464, B-A: 0.04297557473182678\n",
            "epoch: 1006, train_error(A): 0.08286424726247787, test_error(B): 0.1257885843515396, B-A: 0.04292433708906174\n",
            "epoch: 1008, train_error(A): 0.08286125957965851, test_error(B): 0.12572893500328064, B-A: 0.04286767542362213\n",
            "epoch: 1010, train_error(A): 0.08285827189683914, test_error(B): 0.12571778893470764, B-A: 0.0428595170378685\n",
            "epoch: 1012, train_error(A): 0.08285526186227798, test_error(B): 0.12574873864650726, B-A: 0.04289347678422928\n",
            "epoch: 1014, train_error(A): 0.08285227417945862, test_error(B): 0.12577733397483826, B-A: 0.04292505979537964\n",
            "epoch: 1016, train_error(A): 0.08284927904605865, test_error(B): 0.12577255070209503, B-A: 0.04292327165603638\n",
            "epoch: 1018, train_error(A): 0.0828462764620781, test_error(B): 0.1257396936416626, B-A: 0.0428934171795845\n",
            "epoch: 1020, train_error(A): 0.08284328132867813, test_error(B): 0.12570585310459137, B-A: 0.04286257177591324\n",
            "epoch: 1022, train_error(A): 0.08284028619527817, test_error(B): 0.12569241225719452, B-A: 0.04285212606191635\n",
            "epoch: 1024, train_error(A): 0.0828372910618782, test_error(B): 0.1256997138261795, B-A: 0.0428624227643013\n",
            "epoch: 1026, train_error(A): 0.08283428847789764, test_error(B): 0.12571249902248383, B-A: 0.04287821054458618\n",
            "epoch: 1028, train_error(A): 0.08283128589391708, test_error(B): 0.12571576237678528, B-A: 0.042884476482868195\n",
            "epoch: 1030, train_error(A): 0.08282828330993652, test_error(B): 0.12570486962795258, B-A: 0.04287658631801605\n",
            "epoch: 1032, train_error(A): 0.08282528072595596, test_error(B): 0.12568546831607819, B-A: 0.04286018759012222\n",
            "epoch: 1034, train_error(A): 0.0828222781419754, test_error(B): 0.12566633522510529, B-A: 0.04284405708312988\n",
            "epoch: 1036, train_error(A): 0.08281926810741425, test_error(B): 0.12565350532531738, B-A: 0.04283423721790314\n",
            "epoch: 1038, train_error(A): 0.08281626552343369, test_error(B): 0.12564827501773834, B-A: 0.04283200949430466\n",
            "epoch: 1040, train_error(A): 0.08281324803829193, test_error(B): 0.12564793229103088, B-A: 0.04283468425273895\n",
            "epoch: 1042, train_error(A): 0.08281024545431137, test_error(B): 0.12564796209335327, B-A: 0.0428377166390419\n",
            "epoch: 1044, train_error(A): 0.08280724287033081, test_error(B): 0.1256454586982727, B-A: 0.042838215827941895\n",
            "epoch: 1046, train_error(A): 0.08280422538518906, test_error(B): 0.12563978135585785, B-A: 0.04283555597066879\n",
            "epoch: 1048, train_error(A): 0.0828012153506279, test_error(B): 0.1256314367055893, B-A: 0.042830221354961395\n",
            "epoch: 1050, train_error(A): 0.08279819786548615, test_error(B): 0.12562131881713867, B-A: 0.04282312095165253\n",
            "epoch: 1052, train_error(A): 0.08279518783092499, test_error(B): 0.12561051547527313, B-A: 0.042815327644348145\n",
            "epoch: 1054, train_error(A): 0.08279217034578323, test_error(B): 0.12559984624385834, B-A: 0.042807675898075104\n",
            "epoch: 1056, train_error(A): 0.08278915286064148, test_error(B): 0.1255897432565689, B-A: 0.04280059039592743\n",
            "epoch: 1058, train_error(A): 0.08278613537549973, test_error(B): 0.12558013200759888, B-A: 0.04279399663209915\n",
            "epoch: 1060, train_error(A): 0.08278311789035797, test_error(B): 0.12557092308998108, B-A: 0.04278780519962311\n",
            "epoch: 1062, train_error(A): 0.08278009295463562, test_error(B): 0.12556186318397522, B-A: 0.0427817702293396\n",
            "epoch: 1064, train_error(A): 0.08277707546949387, test_error(B): 0.12555260956287384, B-A: 0.042775534093379974\n",
            "epoch: 1066, train_error(A): 0.08277405053377151, test_error(B): 0.125542551279068, B-A: 0.04276850074529648\n",
            "epoch: 1068, train_error(A): 0.08277103304862976, test_error(B): 0.12553085386753082, B-A: 0.04275982081890106\n",
            "epoch: 1070, train_error(A): 0.08276800811290741, test_error(B): 0.12551634013652802, B-A: 0.042748332023620605\n",
            "epoch: 1072, train_error(A): 0.08276498317718506, test_error(B): 0.12549681961536407, B-A: 0.042731836438179016\n",
            "epoch: 1074, train_error(A): 0.0827619805932045, test_error(B): 0.12546807527542114, B-A: 0.042706094682216644\n",
            "epoch: 1076, train_error(A): 0.08275900036096573, test_error(B): 0.12542232871055603, B-A: 0.0426633283495903\n",
            "epoch: 1078, train_error(A): 0.08275611698627472, test_error(B): 0.12534449994564056, B-A: 0.042588382959365845\n",
            "epoch: 1080, train_error(A): 0.08275357633829117, test_error(B): 0.12520429491996765, B-A: 0.04245071858167648\n",
            "epoch: 1082, train_error(A): 0.0827523022890091, test_error(B): 0.12493915855884552, B-A: 0.042186856269836426\n",
            "epoch: 1084, train_error(A): 0.08275595307350159, test_error(B): 0.1244182139635086, B-A: 0.04166226089000702\n",
            "epoch: 1086, train_error(A): 0.082779660820961, test_error(B): 0.12336616218090057, B-A: 0.040586501359939575\n",
            "epoch: 1088, train_error(A): 0.08288591355085373, test_error(B): 0.12123830616474152, B-A: 0.03835239261388779\n",
            "epoch: 1090, train_error(A): 0.08328624814748764, test_error(B): 0.11729578673839569, B-A: 0.03400953859090805\n",
            "epoch: 1092, train_error(A): 0.08410650491714478, test_error(B): 0.11268264800310135, B-A: 0.028576143085956573\n",
            "epoch: 1094, train_error(A): 0.0835518166422844, test_error(B): 0.11566054075956345, B-A: 0.03210872411727905\n",
            "epoch: 1096, train_error(A): 0.08284083008766174, test_error(B): 0.12922193109989166, B-A: 0.04638110101222992\n",
            "epoch: 1098, train_error(A): 0.08343610167503357, test_error(B): 0.13497784733772278, B-A: 0.05154174566268921\n",
            "epoch: 1100, train_error(A): 0.08274286240339279, test_error(B): 0.12439300864934921, B-A: 0.04165014624595642\n",
            "epoch: 1102, train_error(A): 0.08316671848297119, test_error(B): 0.11825435608625412, B-A: 0.03508763760328293\n",
            "epoch: 1104, train_error(A): 0.08273495733737946, test_error(B): 0.12655159831047058, B-A: 0.043816640973091125\n",
            "epoch: 1106, train_error(A): 0.08300793915987015, test_error(B): 0.131408229470253, B-A: 0.04840029031038284\n",
            "epoch: 1108, train_error(A): 0.08273646980524063, test_error(B): 0.12389178574085236, B-A: 0.041155315935611725\n",
            "epoch: 1110, train_error(A): 0.0828888863325119, test_error(B): 0.12077245116233826, B-A: 0.037883564829826355\n",
            "epoch: 1112, train_error(A): 0.08273842185735703, test_error(B): 0.12707680463790894, B-A: 0.04433838278055191\n",
            "epoch: 1114, train_error(A): 0.08281566947698593, test_error(B): 0.12888754904270172, B-A: 0.04607187956571579\n",
            "epoch: 1116, train_error(A): 0.08273673057556152, test_error(B): 0.12344248592853546, B-A: 0.04070575535297394\n",
            "epoch: 1118, train_error(A): 0.08276496827602386, test_error(B): 0.12265239655971527, B-A: 0.039887428283691406\n",
            "epoch: 1120, train_error(A): 0.0827307403087616, test_error(B): 0.12717169523239136, B-A: 0.04444095492362976\n",
            "epoch: 1122, train_error(A): 0.08273293823003769, test_error(B): 0.127321258187294, B-A: 0.04458831995725632\n",
            "epoch: 1124, train_error(A): 0.08272220939397812, test_error(B): 0.12365879863500595, B-A: 0.04093658924102783\n",
            "epoch: 1126, train_error(A): 0.08271267265081406, test_error(B): 0.12397931516170502, B-A: 0.04126664251089096\n",
            "epoch: 1128, train_error(A): 0.082712821662426, test_error(B): 0.12694410979747772, B-A: 0.04423128813505173\n",
            "epoch: 1130, train_error(A): 0.08269987255334854, test_error(B): 0.126409649848938, B-A: 0.04370977729558945\n",
            "epoch: 1132, train_error(A): 0.08270280063152313, test_error(B): 0.12404691427946091, B-A: 0.041344113647937775\n",
            "epoch: 1134, train_error(A): 0.08269104361534119, test_error(B): 0.12459220737218857, B-A: 0.04190116375684738\n",
            "epoch: 1136, train_error(A): 0.08269325643777847, test_error(B): 0.12646625936031342, B-A: 0.04377300292253494\n",
            "epoch: 1138, train_error(A): 0.08268420398235321, test_error(B): 0.1259787231683731, B-A: 0.0432945191860199\n",
            "epoch: 1140, train_error(A): 0.08268449455499649, test_error(B): 0.12444061785936356, B-A: 0.041756123304367065\n",
            "epoch: 1142, train_error(A): 0.08267834782600403, test_error(B): 0.12474611401557922, B-A: 0.042067766189575195\n",
            "epoch: 1144, train_error(A): 0.08267663419246674, test_error(B): 0.12599831819534302, B-A: 0.04332168400287628\n",
            "epoch: 1146, train_error(A): 0.08267280459403992, test_error(B): 0.1258661448955536, B-A: 0.04319334030151367\n",
            "epoch: 1148, train_error(A): 0.08266951143741608, test_error(B): 0.12483594566583633, B-A: 0.04216643422842026\n",
            "epoch: 1150, train_error(A): 0.082667276263237, test_error(B): 0.12478331476449966, B-A: 0.042116038501262665\n",
            "epoch: 1152, train_error(A): 0.08266303688287735, test_error(B): 0.12559561431407928, B-A: 0.042932577431201935\n",
            "epoch: 1154, train_error(A): 0.08266165107488632, test_error(B): 0.12578968703746796, B-A: 0.043128035962581635\n",
            "epoch: 1156, train_error(A): 0.08265714347362518, test_error(B): 0.12516745924949646, B-A: 0.04251031577587128\n",
            "epoch: 1158, train_error(A): 0.08265584707260132, test_error(B): 0.12484591454267502, B-A: 0.0421900674700737\n",
            "epoch: 1160, train_error(A): 0.08265167474746704, test_error(B): 0.12524154782295227, B-A: 0.04258987307548523\n",
            "epoch: 1162, train_error(A): 0.08264992386102676, test_error(B): 0.12560425698757172, B-A: 0.04295433312654495\n",
            "epoch: 1164, train_error(A): 0.0826464369893074, test_error(B): 0.12539219856262207, B-A: 0.04274576157331467\n",
            "epoch: 1166, train_error(A): 0.08264398574829102, test_error(B): 0.1250140219926834, B-A: 0.042370036244392395\n",
            "epoch: 1168, train_error(A): 0.08264121413230896, test_error(B): 0.12502485513687134, B-A: 0.04238364100456238\n",
            "epoch: 1170, train_error(A): 0.0826382115483284, test_error(B): 0.12532037496566772, B-A: 0.042682163417339325\n",
            "epoch: 1172, train_error(A): 0.0826358050107956, test_error(B): 0.12543533742427826, B-A: 0.042799532413482666\n",
            "epoch: 1174, train_error(A): 0.08263272047042847, test_error(B): 0.12524628639221191, B-A: 0.04261356592178345\n",
            "epoch: 1176, train_error(A): 0.08263017982244492, test_error(B): 0.12505023181438446, B-A: 0.042420051991939545\n",
            "epoch: 1178, train_error(A): 0.08262735605239868, test_error(B): 0.1250874549150467, B-A: 0.04246009886264801\n",
            "epoch: 1180, train_error(A): 0.08262453973293304, test_error(B): 0.12525852024555206, B-A: 0.04263398051261902\n",
            "epoch: 1182, train_error(A): 0.08262190967798233, test_error(B): 0.12532541155815125, B-A: 0.042703501880168915\n",
            "epoch: 1184, train_error(A): 0.08261902630329132, test_error(B): 0.12522394955158234, B-A: 0.042604923248291016\n",
            "epoch: 1186, train_error(A): 0.08261631429195404, test_error(B): 0.12509648501873016, B-A: 0.04248017072677612\n",
            "epoch: 1188, train_error(A): 0.08261357247829437, test_error(B): 0.12508268654346466, B-A: 0.04246911406517029\n",
            "epoch: 1190, train_error(A): 0.08261074125766754, test_error(B): 0.1251680701971054, B-A: 0.042557328939437866\n",
            "epoch: 1192, train_error(A): 0.08260801434516907, test_error(B): 0.12523697316646576, B-A: 0.04262895882129669\n",
            "epoch: 1194, train_error(A): 0.08260522782802582, test_error(B): 0.1252172291278839, B-A: 0.04261200129985809\n",
            "epoch: 1196, train_error(A): 0.08260241895914078, test_error(B): 0.12514129281044006, B-A: 0.042538873851299286\n",
            "epoch: 1198, train_error(A): 0.08259966224431992, test_error(B): 0.12508748471736908, B-A: 0.042487822473049164\n",
            "epoch: 1200, train_error(A): 0.08259686082601547, test_error(B): 0.12509433925151825, B-A: 0.04249747842550278\n",
            "epoch: 1202, train_error(A): 0.08259405195713043, test_error(B): 0.12513768672943115, B-A: 0.04254363477230072\n",
            "epoch: 1204, train_error(A): 0.08259125798940659, test_error(B): 0.12516963481903076, B-A: 0.042578376829624176\n",
            "epoch: 1206, train_error(A): 0.08258845657110214, test_error(B): 0.12516269087791443, B-A: 0.042574234306812286\n",
            "epoch: 1208, train_error(A): 0.08258563280105591, test_error(B): 0.12512624263763428, B-A: 0.04254060983657837\n",
            "epoch: 1210, train_error(A): 0.08258282393217087, test_error(B): 0.1250889152288437, B-A: 0.04250609129667282\n",
            "epoch: 1212, train_error(A): 0.08258000761270523, test_error(B): 0.12507307529449463, B-A: 0.0424930676817894\n",
            "epoch: 1214, train_error(A): 0.0825771763920784, test_error(B): 0.12508077919483185, B-A: 0.04250360280275345\n",
            "epoch: 1216, train_error(A): 0.08257434517145157, test_error(B): 0.12509779632091522, B-A: 0.042523451149463654\n",
            "epoch: 1218, train_error(A): 0.08257150650024414, test_error(B): 0.12510842084884644, B-A: 0.042536914348602295\n",
            "epoch: 1220, train_error(A): 0.08256867527961731, test_error(B): 0.12510523200035095, B-A: 0.04253655672073364\n",
            "epoch: 1222, train_error(A): 0.08256583660840988, test_error(B): 0.1250903457403183, B-A: 0.04252450913190842\n",
            "epoch: 1224, train_error(A): 0.08256298303604126, test_error(B): 0.12507082521915436, B-A: 0.0425078421831131\n",
            "epoch: 1226, train_error(A): 0.08256013691425323, test_error(B): 0.12505358457565308, B-A: 0.04249344766139984\n",
            "epoch: 1228, train_error(A): 0.08255728334188461, test_error(B): 0.1250429004430771, B-A: 0.042485617101192474\n",
            "epoch: 1230, train_error(A): 0.08255442976951599, test_error(B): 0.12503869831562042, B-A: 0.04248426854610443\n",
            "epoch: 1232, train_error(A): 0.08255156129598618, test_error(B): 0.1250385344028473, B-A: 0.042486973106861115\n",
            "epoch: 1234, train_error(A): 0.08254869282245636, test_error(B): 0.12503960728645325, B-A: 0.04249091446399689\n",
            "epoch: 1236, train_error(A): 0.08254582434892654, test_error(B): 0.12503975629806519, B-A: 0.04249393194913864\n",
            "epoch: 1238, train_error(A): 0.08254294842481613, test_error(B): 0.1250377744436264, B-A: 0.04249482601881027\n",
            "epoch: 1240, train_error(A): 0.08254007250070572, test_error(B): 0.12503422796726227, B-A: 0.04249415546655655\n",
            "epoch: 1242, train_error(A): 0.08253718167543411, test_error(B): 0.12502922117710114, B-A: 0.04249203950166702\n",
            "epoch: 1244, train_error(A): 0.0825342983007431, test_error(B): 0.12502360343933105, B-A: 0.04248930513858795\n",
            "epoch: 1246, train_error(A): 0.0825313925743103, test_error(B): 0.12501803040504456, B-A: 0.04248663783073425\n",
            "epoch: 1248, train_error(A): 0.0825284942984581, test_error(B): 0.12501266598701477, B-A: 0.04248417168855667\n",
            "epoch: 1250, train_error(A): 0.0825255885720253, test_error(B): 0.12500816583633423, B-A: 0.04248257726430893\n",
            "epoch: 1252, train_error(A): 0.0825226828455925, test_error(B): 0.12500526010990143, B-A: 0.04248257726430893\n",
            "epoch: 1254, train_error(A): 0.0825197696685791, test_error(B): 0.12500469386577606, B-A: 0.04248492419719696\n",
            "epoch: 1256, train_error(A): 0.08251684904098511, test_error(B): 0.125007763504982, B-A: 0.04249091446399689\n",
            "epoch: 1258, train_error(A): 0.08251393586397171, test_error(B): 0.1250172257423401, B-A: 0.04250328987836838\n",
            "epoch: 1260, train_error(A): 0.0825110375881195, test_error(B): 0.1250380128622055, B-A: 0.042526975274086\n",
            "epoch: 1262, train_error(A): 0.08250816911458969, test_error(B): 0.12507928907871246, B-A: 0.04257111996412277\n",
            "epoch: 1264, train_error(A): 0.08250545710325241, test_error(B): 0.1251589059829712, B-A: 0.04265344887971878\n",
            "epoch: 1266, train_error(A): 0.08250324428081512, test_error(B): 0.1253131479024887, B-A: 0.042809903621673584\n",
            "epoch: 1268, train_error(A): 0.08250284940004349, test_error(B): 0.1256161779165268, B-A: 0.04311332851648331\n",
            "epoch: 1270, train_error(A): 0.08250939846038818, test_error(B): 0.12622228264808655, B-A: 0.043712884187698364\n",
            "epoch: 1272, train_error(A): 0.08254365622997284, test_error(B): 0.1274571716785431, B-A: 0.04491351544857025\n",
            "epoch: 1274, train_error(A): 0.08268922567367554, test_error(B): 0.12997321784496307, B-A: 0.04728399217128754\n",
            "epoch: 1276, train_error(A): 0.08321725577116013, test_error(B): 0.13468234241008759, B-A: 0.05146508663892746\n",
            "epoch: 1278, train_error(A): 0.08421800285577774, test_error(B): 0.14014841616153717, B-A: 0.05593041330575943\n",
            "epoch: 1280, train_error(A): 0.08336520940065384, test_error(B): 0.1357918083667755, B-A: 0.052426598966121674\n",
            "epoch: 1282, train_error(A): 0.08267641812562943, test_error(B): 0.12016729265451431, B-A: 0.03749087452888489\n",
            "epoch: 1284, train_error(A): 0.08325221389532089, test_error(B): 0.11526495963335037, B-A: 0.03201274573802948\n",
            "epoch: 1286, train_error(A): 0.08252127468585968, test_error(B): 0.1271384358406067, B-A: 0.04461716115474701\n",
            "epoch: 1288, train_error(A): 0.0829881951212883, test_error(B): 0.13311511278152466, B-A: 0.05012691766023636\n",
            "epoch: 1290, train_error(A): 0.08251278102397919, test_error(B): 0.12286066263914108, B-A: 0.040347881615161896\n",
            "epoch: 1292, train_error(A): 0.082779161632061, test_error(B): 0.11869947612285614, B-A: 0.035920314490795135\n",
            "epoch: 1294, train_error(A): 0.08251496404409409, test_error(B): 0.12718498706817627, B-A: 0.044670023024082184\n",
            "epoch: 1296, train_error(A): 0.08265088498592377, test_error(B): 0.1296480894088745, B-A: 0.046997204422950745\n",
            "epoch: 1298, train_error(A): 0.08251779526472092, test_error(B): 0.12224289774894714, B-A: 0.03972510248422623\n",
            "epoch: 1300, train_error(A): 0.08256486803293228, test_error(B): 0.12118393182754517, B-A: 0.038619063794612885\n",
            "epoch: 1302, train_error(A): 0.08251242339611053, test_error(B): 0.12726040184497833, B-A: 0.0447479784488678\n",
            "epoch: 1304, train_error(A): 0.08251183480024338, test_error(B): 0.1273631602525711, B-A: 0.04485132545232773\n",
            "epoch: 1306, train_error(A): 0.08250177651643753, test_error(B): 0.1224362850189209, B-A: 0.03993450850248337\n",
            "epoch: 1308, train_error(A): 0.08247890323400497, test_error(B): 0.1230437308549881, B-A: 0.040564827620983124\n",
            "epoch: 1310, train_error(A): 0.08248919993638992, test_error(B): 0.12701416015625, B-A: 0.04452496021986008\n",
            "epoch: 1312, train_error(A): 0.08245984464883804, test_error(B): 0.1260349303483963, B-A: 0.04357508569955826\n",
            "epoch: 1314, train_error(A): 0.08247559517621994, test_error(B): 0.12298863381147385, B-A: 0.040513038635253906\n",
            "epoch: 1316, train_error(A): 0.08244871348142624, test_error(B): 0.12412382662296295, B-A: 0.04167511314153671\n",
            "epoch: 1318, train_error(A): 0.08246281743049622, test_error(B): 0.12648607790470123, B-A: 0.04402326047420502\n",
            "epoch: 1320, train_error(A): 0.08244115114212036, test_error(B): 0.12535476684570312, B-A: 0.042913615703582764\n",
            "epoch: 1322, train_error(A): 0.08245106786489487, test_error(B): 0.123499296605587, B-A: 0.04104822874069214\n",
            "epoch: 1324, train_error(A): 0.0824352279305458, test_error(B): 0.12443258613348007, B-A: 0.041997358202934265\n",
            "epoch: 1326, train_error(A): 0.08244114369153976, test_error(B): 0.12591232359409332, B-A: 0.04347117990255356\n",
            "epoch: 1328, train_error(A): 0.08242996782064438, test_error(B): 0.1251748949289322, B-A: 0.04274492710828781\n",
            "epoch: 1330, train_error(A): 0.08243244886398315, test_error(B): 0.12393587082624435, B-A: 0.0415034219622612\n",
            "epoch: 1332, train_error(A): 0.08242487907409668, test_error(B): 0.12442121654748917, B-A: 0.04199633747339249\n",
            "epoch: 1334, train_error(A): 0.08242471516132355, test_error(B): 0.12546874582767487, B-A: 0.04304403066635132\n",
            "epoch: 1336, train_error(A): 0.08241979777812958, test_error(B): 0.12520499527454376, B-A: 0.042785197496414185\n",
            "epoch: 1338, train_error(A): 0.08241771906614304, test_error(B): 0.12431445717811584, B-A: 0.04189673811197281\n",
            "epoch: 1340, train_error(A): 0.0824146494269371, test_error(B): 0.12436196953058243, B-A: 0.041947320103645325\n",
            "epoch: 1342, train_error(A): 0.08241134881973267, test_error(B): 0.12507878243923187, B-A: 0.04266743361949921\n",
            "epoch: 1344, train_error(A): 0.08240935206413269, test_error(B): 0.12518705427646637, B-A: 0.04277770221233368\n",
            "epoch: 1346, train_error(A): 0.08240548521280289, test_error(B): 0.12462242692708969, B-A: 0.042216941714286804\n",
            "epoch: 1348, train_error(A): 0.08240383118391037, test_error(B): 0.12436692416667938, B-A: 0.04196309298276901\n",
            "epoch: 1350, train_error(A): 0.08240002393722534, test_error(B): 0.12473030388355255, B-A: 0.04233027994632721\n",
            "epoch: 1352, train_error(A): 0.08239812403917313, test_error(B): 0.125043585896492, B-A: 0.04264546185731888\n",
            "epoch: 1354, train_error(A): 0.08239482343196869, test_error(B): 0.12485196441411972, B-A: 0.04245714098215103\n",
            "epoch: 1356, train_error(A): 0.08239235728979111, test_error(B): 0.12451720982789993, B-A: 0.042124852538108826\n",
            "epoch: 1358, train_error(A): 0.08238965272903442, test_error(B): 0.12452280521392822, B-A: 0.0421331524848938\n",
            "epoch: 1360, train_error(A): 0.08238672465085983, test_error(B): 0.12478514015674591, B-A: 0.04239841550588608\n",
            "epoch: 1362, train_error(A): 0.08238430321216583, test_error(B): 0.12489794939756393, B-A: 0.0425136461853981\n",
            "epoch: 1364, train_error(A): 0.08238133043050766, test_error(B): 0.12473929673433304, B-A: 0.04235796630382538\n",
            "epoch: 1366, train_error(A): 0.08237877488136292, test_error(B): 0.12455924600362778, B-A: 0.04218047112226486\n",
            "epoch: 1368, train_error(A): 0.08237603306770325, test_error(B): 0.12457778304815292, B-A: 0.042201749980449677\n",
            "epoch: 1370, train_error(A): 0.0823732540011406, test_error(B): 0.12472577393054962, B-A: 0.04235251992940903\n",
            "epoch: 1372, train_error(A): 0.08237064629793167, test_error(B): 0.124798484146595, B-A: 0.04242783784866333\n",
            "epoch: 1374, train_error(A): 0.08236785233020782, test_error(B): 0.12472371757030487, B-A: 0.042355865240097046\n",
            "epoch: 1376, train_error(A): 0.08236515522003174, test_error(B): 0.12460880726575851, B-A: 0.042243652045726776\n",
            "epoch: 1378, train_error(A): 0.08236246556043625, test_error(B): 0.12457965314388275, B-A: 0.0422171875834465\n",
            "epoch: 1380, train_error(A): 0.0823596939444542, test_error(B): 0.12464411556720734, B-A: 0.04228442162275314\n",
            "epoch: 1382, train_error(A): 0.0823569968342781, test_error(B): 0.12471318989992142, B-A: 0.04235619306564331\n",
            "epoch: 1384, train_error(A): 0.08235427737236023, test_error(B): 0.12471288442611694, B-A: 0.042358607053756714\n",
            "epoch: 1386, train_error(A): 0.08235152065753937, test_error(B): 0.12465327978134155, B-A: 0.042301759123802185\n",
            "epoch: 1388, train_error(A): 0.08234880119562149, test_error(B): 0.12459755688905716, B-A: 0.04224875569343567\n",
            "epoch: 1390, train_error(A): 0.08234605938196182, test_error(B): 0.12459073960781097, B-A: 0.04224468022584915\n",
            "epoch: 1392, train_error(A): 0.08234330266714096, test_error(B): 0.12462404370307922, B-A: 0.04228074103593826\n",
            "epoch: 1394, train_error(A): 0.08234056830406189, test_error(B): 0.12465757876634598, B-A: 0.04231701046228409\n",
            "epoch: 1396, train_error(A): 0.08233781903982162, test_error(B): 0.12466186285018921, B-A: 0.042324043810367584\n",
            "epoch: 1398, train_error(A): 0.08233504742383957, test_error(B): 0.12463684380054474, B-A: 0.04230179637670517\n",
            "epoch: 1400, train_error(A): 0.08233228325843811, test_error(B): 0.1246032789349556, B-A: 0.04227099567651749\n",
            "epoch: 1402, train_error(A): 0.08232951909303665, test_error(B): 0.12458228319883347, B-A: 0.042252764105796814\n",
            "epoch: 1404, train_error(A): 0.082326740026474, test_error(B): 0.12458205968141556, B-A: 0.04225531965494156\n",
            "epoch: 1406, train_error(A): 0.08232396095991135, test_error(B): 0.12459510564804077, B-A: 0.042271144688129425\n",
            "epoch: 1408, train_error(A): 0.0823211818933487, test_error(B): 0.12460804730653763, B-A: 0.042286865413188934\n",
            "epoch: 1410, train_error(A): 0.08231840282678604, test_error(B): 0.12461143732070923, B-A: 0.04229303449392319\n",
            "epoch: 1412, train_error(A): 0.0823156014084816, test_error(B): 0.12460386008024216, B-A: 0.04228825867176056\n",
            "epoch: 1414, train_error(A): 0.08231280744075775, test_error(B): 0.12458920478820801, B-A: 0.042276397347450256\n",
            "epoch: 1416, train_error(A): 0.08230999857187271, test_error(B): 0.12457345426082611, B-A: 0.0422634556889534\n",
            "epoch: 1418, train_error(A): 0.08230718970298767, test_error(B): 0.12456158548593521, B-A: 0.04225439578294754\n",
            "epoch: 1420, train_error(A): 0.08230438083410263, test_error(B): 0.12455523014068604, B-A: 0.042250849306583405\n",
            "epoch: 1422, train_error(A): 0.0823015570640564, test_error(B): 0.124553382396698, B-A: 0.0422518253326416\n",
            "epoch: 1424, train_error(A): 0.08229873329401016, test_error(B): 0.12455369532108307, B-A: 0.042254962027072906\n",
            "epoch: 1426, train_error(A): 0.08229590952396393, test_error(B): 0.12455472350120544, B-A: 0.042258813977241516\n",
            "epoch: 1428, train_error(A): 0.0822930783033371, test_error(B): 0.12455526739358902, B-A: 0.04226218909025192\n",
            "epoch: 1430, train_error(A): 0.08229024708271027, test_error(B): 0.12455451488494873, B-A: 0.042264267802238464\n",
            "epoch: 1432, train_error(A): 0.08228740841150284, test_error(B): 0.12455197423696518, B-A: 0.04226456582546234\n",
            "epoch: 1434, train_error(A): 0.08228456228971481, test_error(B): 0.1245485171675682, B-A: 0.042263954877853394\n",
            "epoch: 1436, train_error(A): 0.08228170871734619, test_error(B): 0.12454484403133392, B-A: 0.04226313531398773\n",
            "epoch: 1438, train_error(A): 0.08227885514497757, test_error(B): 0.12454111129045486, B-A: 0.042262256145477295\n",
            "epoch: 1440, train_error(A): 0.08227599412202835, test_error(B): 0.12453825771808624, B-A: 0.04226226359605789\n",
            "epoch: 1442, train_error(A): 0.08227314054965973, test_error(B): 0.12453684955835342, B-A: 0.042263709008693695\n",
            "epoch: 1444, train_error(A): 0.08227027207612991, test_error(B): 0.12453755736351013, B-A: 0.04226728528738022\n",
            "epoch: 1446, train_error(A): 0.0822673961520195, test_error(B): 0.12454165518283844, B-A: 0.04227425903081894\n",
            "epoch: 1448, train_error(A): 0.08226452767848969, test_error(B): 0.12455139309167862, B-A: 0.042286865413188934\n",
            "epoch: 1450, train_error(A): 0.08226166665554047, test_error(B): 0.12457112967967987, B-A: 0.042309463024139404\n",
            "epoch: 1452, train_error(A): 0.08225884288549423, test_error(B): 0.12460850179195404, B-A: 0.04234965890645981\n",
            "epoch: 1454, train_error(A): 0.08225612342357635, test_error(B): 0.12467815726995468, B-A: 0.042422033846378326\n",
            "epoch: 1456, train_error(A): 0.08225376904010773, test_error(B): 0.12480903416872025, B-A: 0.04255526512861252\n",
            "epoch: 1458, train_error(A): 0.08225267380475998, test_error(B): 0.12505944073200226, B-A: 0.04280676692724228\n",
            "epoch: 1460, train_error(A): 0.08225615322589874, test_error(B): 0.12554802000522614, B-A: 0.04329186677932739\n",
            "epoch: 1462, train_error(A): 0.08227702975273132, test_error(B): 0.12651842832565308, B-A: 0.04424139857292175\n",
            "epoch: 1464, train_error(A): 0.08236560970544815, test_error(B): 0.12846484780311584, B-A: 0.046099238097667694\n",
            "epoch: 1466, train_error(A): 0.08270207792520523, test_error(B): 0.13224267959594727, B-A: 0.049540601670742035\n",
            "epoch: 1468, train_error(A): 0.0836324617266655, test_error(B): 0.1381342113018036, B-A: 0.05450174957513809\n",
            "epoch: 1470, train_error(A): 0.08406952023506165, test_error(B): 0.14027394354343414, B-A: 0.0562044233083725\n",
            "epoch: 1472, train_error(A): 0.08232726901769638, test_error(B): 0.1280403882265091, B-A: 0.045713119208812714\n",
            "epoch: 1474, train_error(A): 0.08301588147878647, test_error(B): 0.11473941057920456, B-A: 0.03172352910041809\n",
            "epoch: 1476, train_error(A): 0.08251199871301651, test_error(B): 0.11873289197683334, B-A: 0.036220893263816833\n",
            "epoch: 1478, train_error(A): 0.08262118697166443, test_error(B): 0.1317106932401657, B-A: 0.04908950626850128\n",
            "epoch: 1480, train_error(A): 0.08244099467992783, test_error(B): 0.12975375354290009, B-A: 0.04731275886297226\n",
            "epoch: 1482, train_error(A): 0.0824701264500618, test_error(B): 0.11892625689506531, B-A: 0.03645613044500351\n",
            "epoch: 1484, train_error(A): 0.08235485851764679, test_error(B): 0.12034443765878677, B-A: 0.037989579141139984\n",
            "epoch: 1486, train_error(A): 0.0823933407664299, test_error(B): 0.12911532819271088, B-A: 0.046721987426280975\n",
            "epoch: 1488, train_error(A): 0.08229682594537735, test_error(B): 0.1275092512369156, B-A: 0.04521242529153824\n",
            "epoch: 1490, train_error(A): 0.0823364406824112, test_error(B): 0.1204080879688263, B-A: 0.0380716472864151\n",
            "epoch: 1492, train_error(A): 0.0822613313794136, test_error(B): 0.12186545878648758, B-A: 0.039604127407073975\n",
            "epoch: 1494, train_error(A): 0.0822959840297699, test_error(B): 0.12762895226478577, B-A: 0.04533296823501587\n",
            "epoch: 1496, train_error(A): 0.08223610371351242, test_error(B): 0.1262221336364746, B-A: 0.04398602992296219\n",
            "epoch: 1498, train_error(A): 0.08226442337036133, test_error(B): 0.12166886031627655, B-A: 0.03940443694591522\n",
            "epoch: 1500, train_error(A): 0.08221937716007233, test_error(B): 0.12301057577133179, B-A: 0.04079119861125946\n",
            "epoch: 1502, train_error(A): 0.0822419673204422, test_error(B): 0.12673354148864746, B-A: 0.04449157416820526\n",
            "epoch: 1504, train_error(A): 0.08220815658569336, test_error(B): 0.12553782761096954, B-A: 0.043329671025276184\n",
            "epoch: 1506, train_error(A): 0.082224041223526, test_error(B): 0.12259279191493988, B-A: 0.04036875069141388\n",
            "epoch: 1508, train_error(A): 0.08220028877258301, test_error(B): 0.12357258796691895, B-A: 0.04137229919433594\n",
            "epoch: 1510, train_error(A): 0.08220963180065155, test_error(B): 0.12596233189105988, B-A: 0.043752700090408325\n",
            "epoch: 1512, train_error(A): 0.08219403028488159, test_error(B): 0.12521672248840332, B-A: 0.04302269220352173\n",
            "epoch: 1514, train_error(A): 0.08219750225543976, test_error(B): 0.12322897464036942, B-A: 0.04103147238492966\n",
            "epoch: 1516, train_error(A): 0.08218881487846375, test_error(B): 0.12362583726644516, B-A: 0.041437022387981415\n",
            "epoch: 1518, train_error(A): 0.08218751102685928, test_error(B): 0.12525580823421478, B-A: 0.0430682972073555\n",
            "epoch: 1520, train_error(A): 0.082183837890625, test_error(B): 0.12515297532081604, B-A: 0.04296913743019104\n",
            "epoch: 1522, train_error(A): 0.08217915147542953, test_error(B): 0.123815156519413, B-A: 0.04163600504398346\n",
            "epoch: 1524, train_error(A): 0.0821785256266594, test_error(B): 0.12363184988498688, B-A: 0.041453324258327484\n",
            "epoch: 1526, train_error(A): 0.08217225223779678, test_error(B): 0.12466029077768326, B-A: 0.042488038539886475\n",
            "epoch: 1528, train_error(A): 0.08217275142669678, test_error(B): 0.12505140900611877, B-A: 0.042878657579422\n",
            "epoch: 1530, train_error(A): 0.08216658979654312, test_error(B): 0.1243181899189949, B-A: 0.04215160012245178\n",
            "epoch: 1532, train_error(A): 0.08216658234596252, test_error(B): 0.12378732115030289, B-A: 0.04162073880434036\n",
            "epoch: 1534, train_error(A): 0.08216171711683273, test_error(B): 0.12419633567333221, B-A: 0.04203461855649948\n",
            "epoch: 1536, train_error(A): 0.0821603313088417, test_error(B): 0.12474597245454788, B-A: 0.04258564114570618\n",
            "epoch: 1538, train_error(A): 0.08215710520744324, test_error(B): 0.12460300326347351, B-A: 0.04244589805603027\n",
            "epoch: 1540, train_error(A): 0.08215434104204178, test_error(B): 0.12409622222185135, B-A: 0.04194188117980957\n",
            "epoch: 1542, train_error(A): 0.08215226233005524, test_error(B): 0.12398629635572433, B-A: 0.0418340340256691\n",
            "epoch: 1544, train_error(A): 0.08214890211820602, test_error(B): 0.12432973831892014, B-A: 0.04218083620071411\n",
            "epoch: 1546, train_error(A): 0.08214699476957321, test_error(B): 0.12457241863012314, B-A: 0.04242542386054993\n",
            "epoch: 1548, train_error(A): 0.08214396983385086, test_error(B): 0.12441334128379822, B-A: 0.04226937144994736\n",
            "epoch: 1550, train_error(A): 0.08214151114225388, test_error(B): 0.12412601709365845, B-A: 0.04198450595140457\n",
            "epoch: 1552, train_error(A): 0.08213908970355988, test_error(B): 0.12408314645290375, B-A: 0.04194405674934387\n",
            "epoch: 1554, train_error(A): 0.08213625848293304, test_error(B): 0.124282605946064, B-A: 0.04214634746313095\n",
            "epoch: 1556, train_error(A): 0.0821339413523674, test_error(B): 0.12443695217370987, B-A: 0.04230301082134247\n",
            "epoch: 1558, train_error(A): 0.0821312740445137, test_error(B): 0.12437230348587036, B-A: 0.04224102944135666\n",
            "epoch: 1560, train_error(A): 0.08212868869304657, test_error(B): 0.12420003116130829, B-A: 0.04207134246826172\n",
            "epoch: 1562, train_error(A): 0.08212626725435257, test_error(B): 0.12412574887275696, B-A: 0.04199948161840439\n",
            "epoch: 1564, train_error(A): 0.08212361484766006, test_error(B): 0.12420374900102615, B-A: 0.04208013415336609\n",
            "epoch: 1566, train_error(A): 0.0821210965514183, test_error(B): 0.12431637942790985, B-A: 0.04219528287649155\n",
            "epoch: 1568, train_error(A): 0.08211860060691833, test_error(B): 0.12433942407369614, B-A: 0.0422208234667778\n",
            "epoch: 1570, train_error(A): 0.08211599290370941, test_error(B): 0.12426598370075226, B-A: 0.04214999079704285\n",
            "epoch: 1572, train_error(A): 0.08211347460746765, test_error(B): 0.12418054044246674, B-A: 0.042067065834999084\n",
            "epoch: 1574, train_error(A): 0.0821109488606453, test_error(B): 0.12415790557861328, B-A: 0.04204695671796799\n",
            "epoch: 1576, train_error(A): 0.08210837841033936, test_error(B): 0.12420029938220978, B-A: 0.04209192097187042\n",
            "epoch: 1578, train_error(A): 0.0821058377623558, test_error(B): 0.1242557093501091, B-A: 0.042149871587753296\n",
            "epoch: 1580, train_error(A): 0.08210330456495285, test_error(B): 0.12427329272031784, B-A: 0.04216998815536499\n",
            "epoch: 1582, train_error(A): 0.08210073411464691, test_error(B): 0.12424380332231522, B-A: 0.042143069207668304\n",
            "epoch: 1584, train_error(A): 0.08209818601608276, test_error(B): 0.12419609725475311, B-A: 0.04209791123867035\n",
            "epoch: 1586, train_error(A): 0.08209564536809921, test_error(B): 0.12416501343250275, B-A: 0.042069368064403534\n",
            "epoch: 1588, train_error(A): 0.08209308981895447, test_error(B): 0.12416442483663559, B-A: 0.04207133501768112\n",
            "epoch: 1590, train_error(A): 0.08209052681922913, test_error(B): 0.12418438494205475, B-A: 0.04209385812282562\n",
            "epoch: 1592, train_error(A): 0.08208796381950378, test_error(B): 0.12420579791069031, B-A: 0.04211783409118652\n",
            "epoch: 1594, train_error(A): 0.08208541572093964, test_error(B): 0.12421388924121857, B-A: 0.04212847352027893\n",
            "epoch: 1596, train_error(A): 0.0820828527212143, test_error(B): 0.12420471757650375, B-A: 0.04212186485528946\n",
            "epoch: 1598, train_error(A): 0.08208028227090836, test_error(B): 0.12418439984321594, B-A: 0.04210411757230759\n",
            "epoch: 1600, train_error(A): 0.08207771927118301, test_error(B): 0.12416315078735352, B-A: 0.0420854315161705\n",
            "epoch: 1602, train_error(A): 0.08207515627145767, test_error(B): 0.12414848804473877, B-A: 0.0420733317732811\n",
            "epoch: 1604, train_error(A): 0.08207257837057114, test_error(B): 0.12414267659187317, B-A: 0.04207009822130203\n",
            "epoch: 1606, train_error(A): 0.0820700079202652, test_error(B): 0.12414364516735077, B-A: 0.04207363724708557\n",
            "epoch: 1608, train_error(A): 0.08206743001937866, test_error(B): 0.12414802610874176, B-A: 0.0420805960893631\n",
            "epoch: 1610, train_error(A): 0.08206485211849213, test_error(B): 0.12415225803852081, B-A: 0.042087405920028687\n",
            "epoch: 1612, train_error(A): 0.08206227421760559, test_error(B): 0.1241539791226387, B-A: 0.04209170490503311\n",
            "epoch: 1614, train_error(A): 0.08205968886613846, test_error(B): 0.12415255606174469, B-A: 0.04209286719560623\n",
            "epoch: 1616, train_error(A): 0.08205710351467133, test_error(B): 0.12414870411157608, B-A: 0.042091600596904755\n",
            "epoch: 1618, train_error(A): 0.0820545181632042, test_error(B): 0.12414328753948212, B-A: 0.042088769376277924\n",
            "epoch: 1620, train_error(A): 0.08205192536115646, test_error(B): 0.1241370439529419, B-A: 0.04208511859178543\n",
            "epoch: 1622, train_error(A): 0.08204933255910873, test_error(B): 0.12413060665130615, B-A: 0.04208127409219742\n",
            "epoch: 1624, train_error(A): 0.082046739757061, test_error(B): 0.12412448227405548, B-A: 0.042077742516994476\n",
            "epoch: 1626, train_error(A): 0.08204414695501328, test_error(B): 0.12411867827177048, B-A: 0.0420745313167572\n",
            "epoch: 1628, train_error(A): 0.08204153925180435, test_error(B): 0.1241135522723198, B-A: 0.04207201302051544\n",
            "epoch: 1630, train_error(A): 0.08203893899917603, test_error(B): 0.12410920113325119, B-A: 0.042070262134075165\n",
            "epoch: 1632, train_error(A): 0.0820363312959671, test_error(B): 0.12410591542720795, B-A: 0.042069584131240845\n",
            "epoch: 1634, train_error(A): 0.08203373104333878, test_error(B): 0.1241038516163826, B-A: 0.04207012057304382\n",
            "epoch: 1636, train_error(A): 0.08203112334012985, test_error(B): 0.12410382926464081, B-A: 0.042072705924510956\n",
            "epoch: 1638, train_error(A): 0.08202851563692093, test_error(B): 0.12410704046487808, B-A: 0.04207852482795715\n",
            "epoch: 1640, train_error(A): 0.0820259153842926, test_error(B): 0.12411592900753021, B-A: 0.04209001362323761\n",
            "epoch: 1642, train_error(A): 0.08202331513166428, test_error(B): 0.12413562834262848, B-A: 0.0421123132109642\n",
            "epoch: 1644, train_error(A): 0.08202075958251953, test_error(B): 0.12417585402727127, B-A: 0.04215509444475174\n",
            "epoch: 1646, train_error(A): 0.08201833814382553, test_error(B): 0.12425577640533447, B-A: 0.04223743826150894\n",
            "epoch: 1648, train_error(A): 0.08201642334461212, test_error(B): 0.12441487610340118, B-A: 0.04239845275878906\n",
            "epoch: 1650, train_error(A): 0.08201644569635391, test_error(B): 0.1247352585196495, B-A: 0.04271881282329559\n",
            "epoch: 1652, train_error(A): 0.08202428370714188, test_error(B): 0.12539079785346985, B-A: 0.04336651414632797\n",
            "epoch: 1654, train_error(A): 0.08206475526094437, test_error(B): 0.12675318121910095, B-A: 0.044688425958156586\n",
            "epoch: 1656, train_error(A): 0.08224208652973175, test_error(B): 0.1295858919620514, B-A: 0.04734380543231964\n",
            "epoch: 1658, train_error(A): 0.0829244926571846, test_error(B): 0.1350908726453781, B-A: 0.05216637998819351\n",
            "epoch: 1660, train_error(A): 0.08440911024808884, test_error(B): 0.14219136536121368, B-A: 0.05778225511312485\n",
            "epoch: 1662, train_error(A): 0.08349283784627914, test_error(B): 0.13837896287441254, B-A: 0.05488612502813339\n",
            "epoch: 1664, train_error(A): 0.08221010863780975, test_error(B): 0.11921168863773346, B-A: 0.037001579999923706\n",
            "epoch: 1666, train_error(A): 0.0831042155623436, test_error(B): 0.11255111545324326, B-A: 0.029446899890899658\n",
            "epoch: 1668, train_error(A): 0.08207275718450546, test_error(B): 0.12706315517425537, B-A: 0.04499039798974991\n",
            "epoch: 1670, train_error(A): 0.08269625902175903, test_error(B): 0.13379085063934326, B-A: 0.05109459161758423\n",
            "epoch: 1672, train_error(A): 0.08211015909910202, test_error(B): 0.1204662024974823, B-A: 0.03835604339838028\n",
            "epoch: 1674, train_error(A): 0.08235045522451401, test_error(B): 0.11737538129091263, B-A: 0.03502492606639862\n",
            "epoch: 1676, train_error(A): 0.08214789628982544, test_error(B): 0.12847141921520233, B-A: 0.04632352292537689\n",
            "epoch: 1678, train_error(A): 0.08214910328388214, test_error(B): 0.12850327789783478, B-A: 0.04635417461395264\n",
            "epoch: 1680, train_error(A): 0.08215627819299698, test_error(B): 0.11932284384965897, B-A: 0.03716656565666199\n",
            "epoch: 1682, train_error(A): 0.08204154670238495, test_error(B): 0.12122779339551926, B-A: 0.03918624669313431\n",
            "epoch: 1684, train_error(A): 0.08213596791028976, test_error(B): 0.12828142940998077, B-A: 0.04614546149969101\n",
            "epoch: 1686, train_error(A): 0.08199244737625122, test_error(B): 0.12505578994750977, B-A: 0.043063342571258545\n",
            "epoch: 1688, train_error(A): 0.08209128677845001, test_error(B): 0.12021971493959427, B-A: 0.03812842816114426\n",
            "epoch: 1690, train_error(A): 0.08197751641273499, test_error(B): 0.12395019829273224, B-A: 0.04197268187999725\n",
            "epoch: 1692, train_error(A): 0.08205004781484604, test_error(B): 0.12713487446308136, B-A: 0.04508482664823532\n",
            "epoch: 1694, train_error(A): 0.08197761327028275, test_error(B): 0.12334583699703217, B-A: 0.04136822372674942\n",
            "epoch: 1696, train_error(A): 0.08201314508914948, test_error(B): 0.12177292257547379, B-A: 0.03975977748632431\n",
            "epoch: 1698, train_error(A): 0.08197901397943497, test_error(B): 0.12518779933452606, B-A: 0.043208785355091095\n",
            "epoch: 1700, train_error(A): 0.08198829740285873, test_error(B): 0.12573106586933136, B-A: 0.043742768466472626\n",
            "epoch: 1702, train_error(A): 0.08197634667158127, test_error(B): 0.1228262409567833, B-A: 0.040849894285202026\n",
            "epoch: 1704, train_error(A): 0.0819723904132843, test_error(B): 0.12286721915006638, B-A: 0.040894828736782074\n",
            "epoch: 1706, train_error(A): 0.08197051286697388, test_error(B): 0.12516526877880096, B-A: 0.04319475591182709\n",
            "epoch: 1708, train_error(A): 0.08196267485618591, test_error(B): 0.1248106136918068, B-A: 0.04284793883562088\n",
            "epoch: 1710, train_error(A): 0.081963449716568, test_error(B): 0.12296394258737564, B-A: 0.04100049287080765\n",
            "epoch: 1712, train_error(A): 0.08195585757493973, test_error(B): 0.12335308641195297, B-A: 0.041397228837013245\n",
            "epoch: 1714, train_error(A): 0.0819564238190651, test_error(B): 0.12481658160686493, B-A: 0.042860157787799835\n",
            "epoch: 1716, train_error(A): 0.08195019513368607, test_error(B): 0.12445877492427826, B-A: 0.042508579790592194\n",
            "epoch: 1718, train_error(A): 0.08194977045059204, test_error(B): 0.1232708990573883, B-A: 0.041321128606796265\n",
            "epoch: 1720, train_error(A): 0.08194506913423538, test_error(B): 0.12352455407381058, B-A: 0.041579484939575195\n",
            "epoch: 1722, train_error(A): 0.08194371312856674, test_error(B): 0.12448497116565704, B-A: 0.0425412580370903\n",
            "epoch: 1724, train_error(A): 0.08194024115800858, test_error(B): 0.12432274967432022, B-A: 0.042382508516311646\n",
            "epoch: 1726, train_error(A): 0.08193810284137726, test_error(B): 0.12351847440004349, B-A: 0.04158037155866623\n",
            "epoch: 1728, train_error(A): 0.08193551748991013, test_error(B): 0.12354843318462372, B-A: 0.04161291569471359\n",
            "epoch: 1730, train_error(A): 0.08193281292915344, test_error(B): 0.12418315559625626, B-A: 0.042250342667102814\n",
            "epoch: 1732, train_error(A): 0.08193080127239227, test_error(B): 0.12423720955848694, B-A: 0.042306408286094666\n",
            "epoch: 1734, train_error(A): 0.08192778378725052, test_error(B): 0.12371788918972015, B-A: 0.041790105402469635\n",
            "epoch: 1736, train_error(A): 0.08192606270313263, test_error(B): 0.12355373799800873, B-A: 0.0416276752948761\n",
            "epoch: 1738, train_error(A): 0.0819229856133461, test_error(B): 0.12392108142375946, B-A: 0.04199809581041336\n",
            "epoch: 1740, train_error(A): 0.08192126452922821, test_error(B): 0.12413734942674637, B-A: 0.04221608489751816\n",
            "epoch: 1742, train_error(A): 0.08191836625337601, test_error(B): 0.12389253824949265, B-A: 0.04197417199611664\n",
            "epoch: 1744, train_error(A): 0.08191640675067902, test_error(B): 0.1236354410648346, B-A: 0.04171903431415558\n",
            "epoch: 1746, train_error(A): 0.08191382139921188, test_error(B): 0.12373971939086914, B-A: 0.04182589799165726\n",
            "epoch: 1748, train_error(A): 0.08191157132387161, test_error(B): 0.12397809326648712, B-A: 0.04206652194261551\n",
            "epoch: 1750, train_error(A): 0.08190927654504776, test_error(B): 0.12398048490285873, B-A: 0.042071208357810974\n",
            "epoch: 1752, train_error(A): 0.08190682530403137, test_error(B): 0.12378498911857605, B-A: 0.04187816381454468\n",
            "epoch: 1754, train_error(A): 0.08190464228391647, test_error(B): 0.12369177490472794, B-A: 0.04178713262081146\n",
            "epoch: 1756, train_error(A): 0.08190217614173889, test_error(B): 0.12379787117242813, B-A: 0.04189569503068924\n",
            "epoch: 1758, train_error(A): 0.08189994096755981, test_error(B): 0.12391814589500427, B-A: 0.04201820492744446\n",
            "epoch: 1760, train_error(A): 0.08189758658409119, test_error(B): 0.12389062345027924, B-A: 0.04199303686618805\n",
            "epoch: 1762, train_error(A): 0.08189523220062256, test_error(B): 0.12377393990755081, B-A: 0.04187870770692825\n",
            "epoch: 1764, train_error(A): 0.0818929523229599, test_error(B): 0.12372101098299026, B-A: 0.041828058660030365\n",
            "epoch: 1766, train_error(A): 0.08189058303833008, test_error(B): 0.12377510219812393, B-A: 0.041884519159793854\n",
            "epoch: 1768, train_error(A): 0.08188827335834503, test_error(B): 0.12384675443172455, B-A: 0.04195848107337952\n",
            "epoch: 1770, train_error(A): 0.08188594877719879, test_error(B): 0.12384667247533798, B-A: 0.04196072369813919\n",
            "epoch: 1772, train_error(A): 0.08188359439373016, test_error(B): 0.12378384172916412, B-A: 0.04190024733543396\n",
            "epoch: 1774, train_error(A): 0.08188128471374512, test_error(B): 0.12373299151659012, B-A: 0.041851706802845\n",
            "epoch: 1776, train_error(A): 0.08187893778085709, test_error(B): 0.1237398162484169, B-A: 0.041860878467559814\n",
            "epoch: 1778, train_error(A): 0.08187659084796906, test_error(B): 0.12378089874982834, B-A: 0.04190430790185928\n",
            "epoch: 1780, train_error(A): 0.08187427371740341, test_error(B): 0.12380355596542358, B-A: 0.04192928224802017\n",
            "epoch: 1782, train_error(A): 0.08187191933393478, test_error(B): 0.12378524988889694, B-A: 0.04191333055496216\n",
            "epoch: 1784, train_error(A): 0.08186957240104675, test_error(B): 0.12374714016914368, B-A: 0.041877567768096924\n",
            "epoch: 1786, train_error(A): 0.08186724036931992, test_error(B): 0.123722605407238, B-A: 0.04185536503791809\n",
            "epoch: 1788, train_error(A): 0.08186488598585129, test_error(B): 0.12372498214244843, B-A: 0.04186009615659714\n",
            "epoch: 1790, train_error(A): 0.08186254650354385, test_error(B): 0.12374222278594971, B-A: 0.04187967628240585\n",
            "epoch: 1792, train_error(A): 0.08186019957065582, test_error(B): 0.12375365197658539, B-A: 0.041893452405929565\n",
            "epoch: 1794, train_error(A): 0.0818578451871872, test_error(B): 0.12374766170978546, B-A: 0.04188981652259827\n",
            "epoch: 1796, train_error(A): 0.08185549080371857, test_error(B): 0.1237286701798439, B-A: 0.041873179376125336\n",
            "epoch: 1798, train_error(A): 0.08185314387083054, test_error(B): 0.12370908260345459, B-A: 0.041855938732624054\n",
            "epoch: 1800, train_error(A): 0.08185077458620071, test_error(B): 0.12369872629642487, B-A: 0.04184795171022415\n",
            "epoch: 1802, train_error(A): 0.08184842020273209, test_error(B): 0.12369872629642487, B-A: 0.04185030609369278\n",
            "epoch: 1804, train_error(A): 0.08184606581926346, test_error(B): 0.12370343506336212, B-A: 0.04185736924409866\n",
            "epoch: 1806, train_error(A): 0.08184369653463364, test_error(B): 0.12370625138282776, B-A: 0.04186255484819412\n",
            "epoch: 1808, train_error(A): 0.08184133470058441, test_error(B): 0.12370322644710541, B-A: 0.041861891746520996\n",
            "epoch: 1810, train_error(A): 0.08183896541595459, test_error(B): 0.1236945390701294, B-A: 0.041855573654174805\n",
            "epoch: 1812, train_error(A): 0.08183659613132477, test_error(B): 0.12368326634168625, B-A: 0.04184667021036148\n",
            "epoch: 1814, train_error(A): 0.08183421939611435, test_error(B): 0.12367265671491623, B-A: 0.04183843731880188\n",
            "epoch: 1816, train_error(A): 0.08183185011148453, test_error(B): 0.12366463243961334, B-A: 0.041832782328128815\n",
            "epoch: 1818, train_error(A): 0.08182947337627411, test_error(B): 0.12365949898958206, B-A: 0.04183002561330795\n",
            "epoch: 1820, train_error(A): 0.08182709664106369, test_error(B): 0.12365634739398956, B-A: 0.04182925075292587\n",
            "epoch: 1822, train_error(A): 0.08182471245527267, test_error(B): 0.12365394085645676, B-A: 0.04182922840118408\n",
            "epoch: 1824, train_error(A): 0.08182232081890106, test_error(B): 0.12365119904279709, B-A: 0.04182887822389603\n",
            "epoch: 1826, train_error(A): 0.08181994408369064, test_error(B): 0.1236477941274643, B-A: 0.04182785004377365\n",
            "epoch: 1828, train_error(A): 0.08181755244731903, test_error(B): 0.12364333868026733, B-A: 0.0418257862329483\n",
            "epoch: 1830, train_error(A): 0.08181516081094742, test_error(B): 0.12363828718662262, B-A: 0.0418231263756752\n",
            "epoch: 1832, train_error(A): 0.0818127691745758, test_error(B): 0.12363281100988388, B-A: 0.041820041835308075\n",
            "epoch: 1834, train_error(A): 0.0818103775382042, test_error(B): 0.12362709641456604, B-A: 0.04181671887636185\n",
            "epoch: 1836, train_error(A): 0.08180797845125198, test_error(B): 0.12362129986286163, B-A: 0.04181332141160965\n",
            "epoch: 1838, train_error(A): 0.08180557936429977, test_error(B): 0.12361542135477066, B-A: 0.041809841990470886\n",
            "epoch: 1840, train_error(A): 0.08180318027734756, test_error(B): 0.12360969930887222, B-A: 0.04180651903152466\n",
            "epoch: 1842, train_error(A): 0.08180077373981476, test_error(B): 0.12360406666994095, B-A: 0.04180329293012619\n",
            "epoch: 1844, train_error(A): 0.08179836720228195, test_error(B): 0.12359882146120071, B-A: 0.04180045425891876\n",
            "epoch: 1846, train_error(A): 0.08179596066474915, test_error(B): 0.123594269156456, B-A: 0.04179830849170685\n",
            "epoch: 1848, train_error(A): 0.08179356157779694, test_error(B): 0.12359052151441574, B-A: 0.041796959936618805\n",
            "epoch: 1850, train_error(A): 0.08179114013910294, test_error(B): 0.12358833104372025, B-A: 0.04179719090461731\n",
            "epoch: 1852, train_error(A): 0.08178873360157013, test_error(B): 0.12358840554952621, B-A: 0.041799671947956085\n",
            "epoch: 1854, train_error(A): 0.08178631961345673, test_error(B): 0.12359257787466049, B-A: 0.041806258261203766\n",
            "epoch: 1856, train_error(A): 0.08178391307592392, test_error(B): 0.1236041933298111, B-A: 0.041820280253887177\n",
            "epoch: 1858, train_error(A): 0.08178151398897171, test_error(B): 0.12363012135028839, B-A: 0.04184860736131668\n",
            "epoch: 1860, train_error(A): 0.08177918940782547, test_error(B): 0.12368323653936386, B-A: 0.04190404713153839\n",
            "epoch: 1862, train_error(A): 0.08177709579467773, test_error(B): 0.12378998100757599, B-A: 0.042012885212898254\n",
            "epoch: 1864, train_error(A): 0.08177591115236282, test_error(B): 0.12400473654270172, B-A: 0.0422288253903389\n",
            "epoch: 1866, train_error(A): 0.08177828788757324, test_error(B): 0.12444198131561279, B-A: 0.04266369342803955\n",
            "epoch: 1868, train_error(A): 0.08179543912410736, test_error(B): 0.12534913420677185, B-A: 0.04355369508266449\n",
            "epoch: 1870, train_error(A): 0.08187572658061981, test_error(B): 0.12725569307804108, B-A: 0.045379966497421265\n",
            "epoch: 1872, train_error(A): 0.08221913874149323, test_error(B): 0.1312103122472763, B-A: 0.04899117350578308\n",
            "epoch: 1874, train_error(A): 0.0834117904305458, test_error(B): 0.13839149475097656, B-A: 0.054979704320430756\n",
            "epoch: 1876, train_error(A): 0.08487419784069061, test_error(B): 0.14429213106632233, B-A: 0.059417933225631714\n",
            "epoch: 1878, train_error(A): 0.08228041976690292, test_error(B): 0.13199514150619507, B-A: 0.049714721739292145\n",
            "epoch: 1880, train_error(A): 0.08278552442789078, test_error(B): 0.1125519648194313, B-A: 0.029766440391540527\n",
            "epoch: 1882, train_error(A): 0.08229580521583557, test_error(B): 0.11571710556745529, B-A: 0.03342130035161972\n",
            "epoch: 1884, train_error(A): 0.08244454115629196, test_error(B): 0.13318504393100739, B-A: 0.050740502774715424\n",
            "epoch: 1886, train_error(A): 0.0819609984755516, test_error(B): 0.12869489192962646, B-A: 0.04673389345407486\n",
            "epoch: 1888, train_error(A): 0.0823097825050354, test_error(B): 0.11538012325763702, B-A: 0.033070340752601624\n",
            "epoch: 1890, train_error(A): 0.08178769052028656, test_error(B): 0.12166229635477066, B-A: 0.0398746058344841\n",
            "epoch: 1892, train_error(A): 0.08219511806964874, test_error(B): 0.1310453861951828, B-A: 0.04885026812553406\n",
            "epoch: 1894, train_error(A): 0.0817592591047287, test_error(B): 0.12274639308452606, B-A: 0.04098713397979736\n",
            "epoch: 1896, train_error(A): 0.08201439678668976, test_error(B): 0.11764510720968246, B-A: 0.035630710422992706\n",
            "epoch: 1898, train_error(A): 0.08178777992725372, test_error(B): 0.12543931603431702, B-A: 0.04365153610706329\n",
            "epoch: 1900, train_error(A): 0.0818849429488182, test_error(B): 0.12756401300430298, B-A: 0.04567907005548477\n",
            "epoch: 1902, train_error(A): 0.08181366324424744, test_error(B): 0.12057584524154663, B-A: 0.038762181997299194\n",
            "epoch: 1904, train_error(A): 0.0817929208278656, test_error(B): 0.12097856402397156, B-A: 0.03918564319610596\n",
            "epoch: 1906, train_error(A): 0.08181829005479813, test_error(B): 0.12661537528038025, B-A: 0.04479708522558212\n",
            "epoch: 1908, train_error(A): 0.08174879848957062, test_error(B): 0.12464223802089691, B-A: 0.042893439531326294\n",
            "epoch: 1910, train_error(A): 0.08180069178342819, test_error(B): 0.12080157548189163, B-A: 0.03900088369846344\n",
            "epoch: 1912, train_error(A): 0.081736259162426, test_error(B): 0.12353579699993134, B-A: 0.04179953783750534\n",
            "epoch: 1914, train_error(A): 0.08177697658538818, test_error(B): 0.12589988112449646, B-A: 0.044122904539108276\n",
            "epoch: 1916, train_error(A): 0.08173481374979019, test_error(B): 0.12296492606401443, B-A: 0.04123011231422424\n",
            "epoch: 1918, train_error(A): 0.08175362646579742, test_error(B): 0.12179530411958694, B-A: 0.04004167765378952\n",
            "epoch: 1920, train_error(A): 0.08173346519470215, test_error(B): 0.12436185777187347, B-A: 0.042628392577171326\n",
            "epoch: 1922, train_error(A): 0.08173799514770508, test_error(B): 0.12474507838487625, B-A: 0.04300708323717117\n",
            "epoch: 1924, train_error(A): 0.08172987401485443, test_error(B): 0.12255454063415527, B-A: 0.04082466661930084\n",
            "epoch: 1926, train_error(A): 0.08172762393951416, test_error(B): 0.12254238873720169, B-A: 0.04081476479768753\n",
            "epoch: 1928, train_error(A): 0.08172465860843658, test_error(B): 0.124290831387043, B-A: 0.042566172778606415\n",
            "epoch: 1930, train_error(A): 0.0817202553153038, test_error(B): 0.12411320954561234, B-A: 0.04239295423030853\n",
            "epoch: 1932, train_error(A): 0.0817188248038292, test_error(B): 0.12270487844944, B-A: 0.04098605364561081\n",
            "epoch: 1934, train_error(A): 0.08171436190605164, test_error(B): 0.12291645258665085, B-A: 0.04120209068059921\n",
            "epoch: 1936, train_error(A): 0.08171314746141434, test_error(B): 0.12403524667024612, B-A: 0.04232209920883179\n",
            "epoch: 1938, train_error(A): 0.08170928061008453, test_error(B): 0.12382440268993378, B-A: 0.04211512207984924\n",
            "epoch: 1940, train_error(A): 0.08170776814222336, test_error(B): 0.12290247529745102, B-A: 0.04119470715522766\n",
            "epoch: 1942, train_error(A): 0.08170458674430847, test_error(B): 0.12303188443183899, B-A: 0.04132729768753052\n",
            "epoch: 1944, train_error(A): 0.08170266449451447, test_error(B): 0.12375994026660919, B-A: 0.04205727577209473\n",
            "epoch: 1946, train_error(A): 0.08170006424188614, test_error(B): 0.12368004024028778, B-A: 0.04197997599840164\n",
            "epoch: 1948, train_error(A): 0.0816977471113205, test_error(B): 0.12306443601846695, B-A: 0.041366688907146454\n",
            "epoch: 1950, train_error(A): 0.08169563114643097, test_error(B): 0.12303905189037323, B-A: 0.04134342074394226\n",
            "epoch: 1952, train_error(A): 0.08169303834438324, test_error(B): 0.12351563572883606, B-A: 0.04182259738445282\n",
            "epoch: 1954, train_error(A): 0.0816912055015564, test_error(B): 0.12360180169343948, B-A: 0.04191059619188309\n",
            "epoch: 1956, train_error(A): 0.08168850094079971, test_error(B): 0.12322144955396652, B-A: 0.04153294861316681\n",
            "epoch: 1958, train_error(A): 0.08168675005435944, test_error(B): 0.12305974215269089, B-A: 0.04137299209833145\n",
            "epoch: 1960, train_error(A): 0.08168409019708633, test_error(B): 0.12331919372081757, B-A: 0.04163510352373123\n",
            "epoch: 1962, train_error(A): 0.08168226480484009, test_error(B): 0.12351136654615402, B-A: 0.041829101741313934\n",
            "epoch: 1964, train_error(A): 0.08167976886034012, test_error(B): 0.12335025519132614, B-A: 0.04167048633098602\n",
            "epoch: 1966, train_error(A): 0.08167776465415955, test_error(B): 0.12313845008611679, B-A: 0.041460685431957245\n",
            "epoch: 1968, train_error(A): 0.08167548477649689, test_error(B): 0.12318965047597885, B-A: 0.041514165699481964\n",
            "epoch: 1970, train_error(A): 0.08167329430580139, test_error(B): 0.1233706921339035, B-A: 0.04169739782810211\n",
            "epoch: 1972, train_error(A): 0.08167116343975067, test_error(B): 0.12339120358228683, B-A: 0.04172004014253616\n",
            "epoch: 1974, train_error(A): 0.08166889101266861, test_error(B): 0.12324685603380203, B-A: 0.04157796502113342\n",
            "epoch: 1976, train_error(A): 0.08166678994894028, test_error(B): 0.1231592446565628, B-A: 0.04149245470762253\n",
            "epoch: 1978, train_error(A): 0.08166453242301941, test_error(B): 0.12322508543729782, B-A: 0.04156055301427841\n",
            "epoch: 1980, train_error(A): 0.0816623792052269, test_error(B): 0.12331949174404144, B-A: 0.041657112538814545\n",
            "epoch: 1982, train_error(A): 0.0816601887345314, test_error(B): 0.1233096793293953, B-A: 0.04164949059486389\n",
            "epoch: 1984, train_error(A): 0.08165798336267471, test_error(B): 0.12322255969047546, B-A: 0.04156457632780075\n",
            "epoch: 1986, train_error(A): 0.08165581524372101, test_error(B): 0.1231730654835701, B-A: 0.04151725023984909\n",
            "epoch: 1988, train_error(A): 0.08165360242128372, test_error(B): 0.12320580333471298, B-A: 0.04155220091342926\n",
            "epoch: 1990, train_error(A): 0.08165140450000763, test_error(B): 0.12326007336378098, B-A: 0.041608668863773346\n",
            "epoch: 1992, train_error(A): 0.08164922147989273, test_error(B): 0.12326382845640182, B-A: 0.041614606976509094\n",
            "epoch: 1994, train_error(A): 0.08164700120687485, test_error(B): 0.1232166439294815, B-A: 0.04156964272260666\n",
            "epoch: 1996, train_error(A): 0.08164481073617935, test_error(B): 0.12317351251840591, B-A: 0.04152870178222656\n",
            "epoch: 1998, train_error(A): 0.08164260536432266, test_error(B): 0.12317360192537308, B-A: 0.041530996561050415\n",
            "epoch: 2000, train_error(A): 0.08164039254188538, test_error(B): 0.12320241332054138, B-A: 0.041562020778656006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhsQRDZYOxuo",
        "colab_type": "code",
        "outputId": "05f8c1d2-61f6-42c3-cbca-80131a5a266c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 하이퍼파라미터 출력\n",
        "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
        "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
        " \n",
        "print(',seq_length:', seq_length, end='')\n",
        "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
        "print(',forget_bias:', forget_bias, end='')\n",
        "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
        "print(',keep_prob:', keep_prob, end='')\n",
        " \n",
        "print(',epoch_num:', epoch_num, end='')\n",
        "print(',learning_rate:', learning_rate, end='')\n",
        " \n",
        "print(',train_error:', train_error_summary[-1], end='')\n",
        "print(',test_error:', test_error_summary[-1], end='')\n",
        "print(',min_test_error:', np.min(test_error_summary))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_data_column_cnt: 5,output_data_column_cnt: 1,seq_length: 7,rnn_cell_hidden_dim: 12,forget_bias: 1,num_stacked_layers: 4,keep_prob: 1.0,epoch_num: 2000,learning_rate: 0.001,train_error: 0.08164039,test_error: 0.12320241,min_test_error: 0.112551115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfFDfVFOxus",
        "colab_type": "code",
        "outputId": "17e60e00-19be-4ba0-deea-9d4fd6ba8022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "# 결과 그래프 출력\n",
        "plt.figure(1)\n",
        "plt.plot(train_error_summary, 'gold')\n",
        "plt.plot(test_error_summary, 'b')\n",
        "plt.xlabel('Epoch(x100)')\n",
        "plt.ylabel('Root Mean Square Error')\n",
        " \n",
        "plt.figure(2)\n",
        "plt.plot(testY, 'r')\n",
        "plt.plot(test_predict, 'b')\n",
        "plt.xlabel('Time Period')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne1j+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5cnCOedcXJ4snHPOxeXJwjnnXFz/Dyv5AMdflHEeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-yCUwDrRt5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBf8ry2lRug4",
        "colab_type": "code",
        "outputId": "a29fd36e-d106-4104-c664-0986b59df6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "error1 = mean_absolute_percentage_error(testY, test_predict)\n",
        "print(\"MAPE :\",error1,\"%\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE : 23.958218005836862 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKSIUE7XKD3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "8d3050a6-bcf8-4998-92ea-c491b9679f60"
      },
      "source": [
        "testY"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50901335],\n",
              "       [0.43360396],\n",
              "       [0.33796615],\n",
              "       [0.39521123],\n",
              "       [0.5017201 ],\n",
              "       [0.5377735 ],\n",
              "       [0.35269024]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8yGnXcAOxuy",
        "colab_type": "code",
        "outputId": "42c3eefe-716f-41ef-ea2b-752ff9596ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
        "recent_data = np.array([x[len(x)-seq_length : ]])\n",
        "print(\"recent_data.shape:\", recent_data.shape)\n",
        "print(\"recent_data:\", recent_data)\n",
        " \n",
        "# 내일 방문자를 예측\n",
        "test_predict1 = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        " \n",
        "print(\"test_predict\", test_predict1[0])\n",
        "test_predict1 = reverse_min_max_scaling(visitor, test_predict) # 금액데이터 역정규화한다\n",
        "print(\"visitors\", test_predict1[0]) # 예측한 visitor를 출력한다"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recent_data.shape: (1, 7, 5)\n",
            "recent_data: [[[0.28571428 0.         0.14285714 0.         0.50901335]\n",
            "  [0.42857142 0.         0.14285714 0.         0.43360396]\n",
            "  [0.57142856 0.         0.14285714 0.         0.33796615]\n",
            "  [0.7142857  0.         0.14285714 0.         0.39521123]\n",
            "  [0.85714284 0.14285714 0.         0.         0.5017201 ]\n",
            "  [0.99999999 0.14285714 0.         0.         0.5377735 ]\n",
            "  [0.14285714 0.         0.14285714 0.         0.35269024]]]\n",
            "test_predict [0.40972668]\n",
            "visitors [2048.6255]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUxRj2UyujUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}