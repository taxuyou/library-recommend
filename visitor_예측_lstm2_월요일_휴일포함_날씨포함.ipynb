{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "visitor_예측_lstm2 월요일 휴일포함_날씨포함.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taxuyou/library-recommend-and-timeseries-predict/blob/master/visitor_%EC%98%88%EC%B8%A1_lstm2_%EC%9B%94%EC%9A%94%EC%9D%BC_%ED%9C%B4%EC%9D%BC%ED%8F%AC%ED%95%A8_%EB%82%A0%EC%94%A8%ED%8F%AC%ED%95%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_WUk368Oxtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2hZnGv6Oxts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardization\n",
        "def data_standardization(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.mean()) / x_np.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9DlduZOxtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
        "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
        "# Min-Max scaling\n",
        "def min_max_scaling(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
        " \n",
        "# 정규화된 값을 원래의 값으로 되돌린다\n",
        "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
        "def reverse_min_max_scaling(org_x, x):\n",
        "    org_x_np = np.asarray(org_x)\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TbAY-pwzpcq",
        "colab": {}
      },
      "source": [
        "# 하이퍼파라미터\n",
        "input_data_column_cnt = 11  # 입력데이터의 컬럼 개수(Variable 개수)\n",
        "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
        " \n",
        "seq_length = 7           # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
        "rnn_cell_hidden_dim = 12   # 각 셀의 (hidden)출력 크기\n",
        "forget_bias = 1          # 망각편향(기본값 1.0)\n",
        "num_stacked_layers = 4     # stacked LSTM layers 개수\n",
        "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
        " \n",
        "epoch_num = 2000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
        "learning_rate = 0.001       # 학습률"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU7YchG0Oxt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터를 로딩한다.\n",
        "from datetime import datetime\n",
        "raw_dataframe = pd.read_csv('test날씨_요일데이터.csv', \n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G6pH7m6Lucl",
        "colab_type": "code",
        "outputId": "c80943c0-e01a-42de-d9ee-edcc5fb8f211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "raw_dataframe.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average_temperature</th>\n",
              "      <th>Minimum_Temperature</th>\n",
              "      <th>Maximum_Temperature</th>\n",
              "      <th>Daily_precipitation</th>\n",
              "      <th>Max_instantaneous_wind_speed</th>\n",
              "      <th>Average_wind_speed</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>closed</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.4</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.8</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>11.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.4</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.4</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.6</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>9.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Average_temperature  Minimum_Temperature  ...  closed  visitors\n",
              "0                  1.4                 -2.6  ...       0      2221\n",
              "1                  3.8                 -2.1  ...       0      2447\n",
              "2                  1.4                 -4.5  ...       0      2963\n",
              "3                  2.4                 -3.0  ...       0      2653\n",
              "4                  3.6                 -2.7  ...       0      2627\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYr_K2OoLKGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe['date'] = pd.to_datetime(raw_dataframe['date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zShkIqy-L0my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe.set_index('date', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7rsd-V8NnVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe[['days','holiday','workingday','visitors']].resample('D').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ9bReIeP1Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe = raw_dataframe[['days','holiday','workingday','visitors']].resample('D').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AK7-Np7bXLc",
        "colab_type": "code",
        "outputId": "2a154031-62d7-435f-f6df-e9a0c0d38c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "raw_dataframe.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average_temperature</th>\n",
              "      <th>Minimum_Temperature</th>\n",
              "      <th>Maximum_Temperature</th>\n",
              "      <th>Daily_precipitation</th>\n",
              "      <th>Max_instantaneous_wind_speed</th>\n",
              "      <th>Average_wind_speed</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>closed</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>1.4</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-02</th>\n",
              "      <td>3.8</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>11.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>1.4</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>2.4</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>3.6</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>9.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-06</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-07</th>\n",
              "      <td>2.5</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-08</th>\n",
              "      <td>7.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>14.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-10</th>\n",
              "      <td>3.7</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-11</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Average_temperature  Minimum_Temperature  ...  closed  visitors\n",
              "date                                                  ...                  \n",
              "2017-01-01                  1.4                 -2.6  ...       0      2221\n",
              "2017-01-02                  3.8                 -2.1  ...       0      2447\n",
              "2017-01-03                  1.4                 -4.5  ...       0      2963\n",
              "2017-01-04                  2.4                 -3.0  ...       0      2653\n",
              "2017-01-05                  3.6                 -2.7  ...       0      2627\n",
              "2017-01-06                  5.0                 -1.2  ...       0      2646\n",
              "2017-01-07                  2.5                 -3.7  ...       0      3346\n",
              "2017-01-08                  7.2                  1.8  ...       0      4291\n",
              "2017-01-10                  3.7                 -3.4  ...       1         1\n",
              "2017-01-11                 -1.0                 -5.0  ...       0      3121\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Strbh1UYbjYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe = raw_dataframe.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htIaRH_1cMkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe['date'] = raw_dataframe['date'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65zMykWlblYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##   date를 받아와서 휴일, 일하는 날 구하기 \n",
        "# import datetime\n",
        "# def getDayName(a,b,c):\n",
        "   \n",
        "#   return ['1','2','3','4','5','6','7'][datetime.date(int(a),int(b),int(c)).weekday()]\n",
        "\n",
        "# # 리스트로 저장 -> DataFrame으로 변환순으로 가면되여\n",
        "# # 빈리스트 선언\n",
        "# list1 = []\n",
        "# for i in raw_dataframe['date']:\n",
        "#     a = i[0:4]\n",
        "#     b = i[5:7]\n",
        "#     c = i[8:10]\n",
        "#     # print(getDayName(a,b,c))\n",
        "#     # 리스트에 추가\n",
        "#     list1.append(getDayName(a,b,c))\n",
        "\n",
        "# # 리스트 -> DataFrame으로 전환    \n",
        "# raw_dataframe['days'] = list1\n",
        "# raw_dataframe.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjA3ZA70cVFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## date 칼럼으로 요일 칼럼 holiday 만들어줌\n",
        "# list2 = []\n",
        "# for i in raw_dataframe['days']:\n",
        "#   if i == '7':\n",
        "#     list2.append(1)\n",
        "#   elif i == '6':\n",
        "#     list2.append(1)\n",
        "#   else:\n",
        "#     list2.append(0)\n",
        "# raw_dataframe[\"holiday\"] = list2\n",
        "# raw_dataframe.head(10) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7941KQcoiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## 일하는 날 칼럼 만들어줌\n",
        "# list3 = []\n",
        "# for i in raw_dataframe['holiday']:\n",
        "#   if i == 0:\n",
        "#     list3.append(1)\n",
        "#   else:\n",
        "#     list3.append(0)\n",
        "\n",
        "# raw_dataframe['workingday'] = list3\n",
        "# raw_dataframe.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVc99yBVgswL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list4 = []\n",
        "# for i in raw_dataframe['visitors']:\n",
        "#   if i % 1==0:\n",
        "#     list4.append(0)\n",
        "#   else:\n",
        "#     list4.append(1)\n",
        "\n",
        "# raw_dataframe['closed'] = list4\n",
        "# raw_dataframe.tail(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOOCyeNpWT3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe=raw_dataframe.fillna(raw_dataframe.mean(axis=0)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyFv_clRdZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataframe = raw_dataframe[['Average_temperature','Minimum_Temperature','Maximum_Temperature',\n",
        "                               'Daily_precipitation','Average_wind_speed','Max_instantaneous_wind_speed','days','holiday','workingday',\n",
        "                               'closed','visitors']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phQxWFdqV6bi",
        "colab_type": "code",
        "outputId": "e165fe92-1685-4ef7-c396-90f7d498754e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "raw_dataframe.tail()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average_temperature</th>\n",
              "      <th>Minimum_Temperature</th>\n",
              "      <th>Maximum_Temperature</th>\n",
              "      <th>Daily_precipitation</th>\n",
              "      <th>Max_instantaneous_wind_speed</th>\n",
              "      <th>Average_wind_speed</th>\n",
              "      <th>days</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>closed</th>\n",
              "      <th>visitors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>25.7</td>\n",
              "      <td>25.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>26.4</td>\n",
              "      <td>24.7</td>\n",
              "      <td>29.5</td>\n",
              "      <td>11.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>27.7</td>\n",
              "      <td>24.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>26.1</td>\n",
              "      <td>24.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>27.9</td>\n",
              "      <td>23.5</td>\n",
              "      <td>33.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Average_temperature  Minimum_Temperature  ...  closed  visitors\n",
              "935                 25.7                 25.0  ...       0      2457\n",
              "936                 26.4                 24.7  ...       0      2873\n",
              "937                 27.7                 24.2  ...       0      3647\n",
              "938                 26.1                 24.6  ...       0      3909\n",
              "939                 27.9                 23.5  ...       0      2564\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgWdYaHpaFGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1K-uGrJWw6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_dataframe.to_csv('test3.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcRIU6SygcI",
        "colab_type": "code",
        "outputId": "cf9c56a8-8e2c-495c-bf53-225eafa375ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data_info = raw_dataframe.values[0:].astype(np.float) #  문자열을 부동소수점형으로 변환한다\n",
        "print(\"data_info.shape: \", data_info.shape)\n",
        "print(\"data_info[0]: \", data_info[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_info.shape:  (940, 11)\n",
            "data_info[0]:  [ 1.400e+00 -2.600e+00  9.200e+00  0.000e+00  3.400e+00  5.000e-01\n",
            "  7.000e+00  1.000e+00  0.000e+00  0.000e+00  2.221e+03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCFxy3Y8sgYN",
        "colab_type": "code",
        "outputId": "d3ddf53e-7c0d-4f86-c583-3f8036b65ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "data_info"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.400e+00, -2.600e+00,  9.200e+00, ...,  0.000e+00,  0.000e+00,\n",
              "         2.221e+03],\n",
              "       [ 3.800e+00, -2.100e+00,  1.140e+01, ...,  1.000e+00,  0.000e+00,\n",
              "         2.447e+03],\n",
              "       [ 1.400e+00, -4.500e+00,  8.700e+00, ...,  1.000e+00,  0.000e+00,\n",
              "         2.963e+03],\n",
              "       ...,\n",
              "       [ 2.770e+01,  2.420e+01,  3.210e+01, ...,  0.000e+00,  0.000e+00,\n",
              "         3.647e+03],\n",
              "       [ 2.610e+01,  2.460e+01,  3.000e+01, ...,  0.000e+00,  0.000e+00,\n",
              "         3.909e+03],\n",
              "       [ 2.790e+01,  2.350e+01,  3.320e+01, ...,  1.000e+00,  0.000e+00,\n",
              "         2.564e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd3c95sOxuA",
        "colab_type": "code",
        "outputId": "e698ea0e-eefb-4abe-adca-9e463bcec139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# 데이터들을 정규화한다\n",
        "# ['days','holiday','workingday','closed', 'visitors']에서 'workingday'까지 취함\n",
        "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
        "day = data_info[:,:10]\n",
        "norm_day = min_max_scaling(day) # 가격형태 데이터 정규화 처리\n",
        "print(\"day.shape: \", day.shape)\n",
        "print(\"day[0]: \", day[0])\n",
        "print(\"norm_day[0]: \", norm_day[0])\n",
        "print(\"=\"*100) # 화면상 구분용"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day.shape:  (940, 10)\n",
            "day[0]:  [ 1.4 -2.6  9.2  0.   3.4  0.5  7.   1.   0.   0. ]\n",
            "norm_day[0]:  [0.11321873 0.089508   0.15945465 0.10491998 0.1250741  0.10788382\n",
            " 0.14641375 0.11084766 0.10491998 0.10491998]\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInLXQzHOxuF",
        "colab_type": "code",
        "outputId": "92920047-f4e3-4ce0-d38f-a135164df727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "# 방문자 데이터를 정규화한다\n",
        "# ['days','holiday','workingday','visitors']에서 마지막 'visitors'만 취함\n",
        "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
        "visitor = data_info[:,-1:]\n",
        "norm_visitor = min_max_scaling(visitor) # 거래량형태 데이터 정규화 처리\n",
        "print(\"visitor.shape: \", visitor.shape)\n",
        "print(\"vitisor[0]: \", visitor[0])\n",
        "print(\"norm_visitor[0]: \", norm_visitor[0])\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
        "x = np.concatenate((norm_day, norm_visitor), axis=1) # axis=1, 세로로 합친다\n",
        "print(\"x.shape: \", x.shape)\n",
        "print(\"x[0]: \", x[0])    # x의 첫 값\n",
        "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "y = x[:, [0]] # 타켓은 방문자다\n",
        "print(\"y[0]: \",y[10])     # y의 첫 값\n",
        "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
        " \n",
        " \n",
        "dataX = [] # 입력으로 사용될 Sequence Data\n",
        "dataY = [] # 출력(타켓)으로 사용\n",
        "\n",
        "\n",
        "for i in range(0, len(y) - seq_length):\n",
        "    _x = x[i : i+seq_length]\n",
        "    _y = y[i + seq_length] # 다음 나타날 방문자수(정답)\n",
        "    if i is 0:\n",
        "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
        "    dataX.append(_x) # dataX 리스트에 추가\n",
        "    dataY.append(_y) # dataY 리스트에 추가"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "visitor.shape:  (940, 1)\n",
            "vitisor[0]:  [2221.]\n",
            "norm_visitor[0]:  [0.30549057]\n",
            "====================================================================================================\n",
            "x.shape:  (940, 11)\n",
            "x[0]:  [0.11321873 0.089508   0.15945465 0.10491998 0.1250741  0.10788382\n",
            " 0.14641375 0.11084766 0.10491998 0.10491998 0.30549057]\n",
            "x[-1]:  [0.27030231 0.24422051 0.30171903 0.10491998 0.14167161 0.11084766\n",
            " 0.11084766 0.10491998 0.11084766 0.10491998 0.35269024]\n",
            "====================================================================================================\n",
            "y[0]:  [0.08298755]\n",
            "y[-1]:  [0.27030231]\n",
            "[[0.11321873 0.089508   0.15945465 0.10491998 0.1250741  0.10788382\n",
            "  0.14641375 0.11084766 0.10491998 0.10491998 0.30549057]\n",
            " [0.12744517 0.09247184 0.17249555 0.10491998 0.1398933  0.11084766\n",
            "  0.11084766 0.10491998 0.11084766 0.10491998 0.33659006]\n",
            " [0.11321873 0.07824541 0.15649081 0.10491998 0.13159455 0.10966212\n",
            "  0.11677534 0.10491998 0.11084766 0.10491998 0.40759598]\n",
            " [0.11914641 0.08713693 0.16953171 0.10491998 0.12388856 0.10847659\n",
            "  0.12270302 0.10491998 0.11084766 0.10491998 0.36493739]\n",
            " [0.12625963 0.08891523 0.16004742 0.10491998 0.14997036 0.11203319\n",
            "  0.12863071 0.10491998 0.11084766 0.10491998 0.36135957]\n",
            " [0.13455839 0.09780676 0.17308832 0.10491998 0.13515116 0.10966212\n",
            "  0.13455839 0.10491998 0.11084766 0.10491998 0.36397413]\n",
            " [0.11973918 0.08298755 0.15886188 0.10491998 0.12803794 0.10847659\n",
            "  0.14048607 0.11084766 0.10491998 0.10491998 0.46029999]] -> [0.14759929]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXFGhBzOxuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습용/테스트용 데이터 생성\n",
        "# 전체 70%를 학습용 데이터로 사용\n",
        "train_size = int(len(dataY) * 0.993)\n",
        "\n",
        "# 나머지(30%)를 테스트용 데이터로 사용\n",
        "test_size = len(dataY) - train_size\n",
        " \n",
        "# 데이터를 잘라 학습용 데이터 생성\n",
        "trainX = np.array(dataX[0:train_size])\n",
        "trainY = np.array(dataY[0:train_size])\n",
        " \n",
        "# 데이터를 잘라 테스트용 데이터 생성\n",
        "testX = np.array(dataX[train_size:len(dataX)])\n",
        "testY = np.array(dataY[train_size:len(dataY)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8xOz2SJT5m",
        "colab_type": "code",
        "outputId": "c210dd4a-75bf-407c-e018-268e1f16a612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_size"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVC5TGyOxuM",
        "colab_type": "code",
        "outputId": "3064f788-9422-4d41-9ec1-e0bbfd7f258b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 텐서플로우 플레이스홀더 생성\n",
        "# 입력 X, 출력 Y를 생성한다\n",
        "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
        "print(\"X: \", X)\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"Y: \", Y)\n",
        " \n",
        "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
        "targets = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"targets: \", targets)\n",
        " \n",
        "predictions = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"predictions: \", predictions)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  Tensor(\"Placeholder:0\", shape=(?, 7, 11), dtype=float32)\n",
            "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
            "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
            "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsh5_GgAOxuQ",
        "colab_type": "code",
        "outputId": "7c1e952a-225a-411c-abfc-299716bd562d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# 모델(LSTM 네트워크) 생성\n",
        "def lstm_cell():\n",
        "    # LSTM셀을 생성\n",
        "    # num_units: 각 Cell 출력 크기\n",
        "    # forget_bias:  to the biases of the forget gate \n",
        "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
        "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
        "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
        "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
        "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    if keep_prob < 1.0:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "    return cell\n",
        " \n",
        "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
        "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
        "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-26-668a829a3f10>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-26-668a829a3f10>:16: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QGqL_YOxuW",
        "colab_type": "code",
        "outputId": "87210aa6-bc12-430d-f81a-2574d509ec2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
        "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "print(\"hypothesis: \", hypothesis)\n",
        " \n",
        "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
        "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
        "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
        " \n",
        " \n",
        "# 손실함수로 평균제곱오차를 사용한다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "# 최적화함수로 AdamOptimizer를 사용한다\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
        " \n",
        "train = optimizer.minimize(loss)\n",
        " \n",
        "# RMSE(Root Mean Square Error)\n",
        "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
        "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
        "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
        " \n",
        " \n",
        "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
        "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
        "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
        " \n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-a2b6404f5de1>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8bfee3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8bfee3a0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8bfee3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8bfee3a0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bff011f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bff011f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bff011f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bff011f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bf1367be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bf1367be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bf1367be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8bf1367be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f8befddd828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 12), dtype=float32)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8bfeeac5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8bfeeac5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8bfeeac5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8bfeeac5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kx6tvlt03lvu",
        "outputId": "abca175d-7a0c-4200-e1a5-0dd26ccd9cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 학습한다\n",
        "# start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
        "print('학습을 시작합니다...')\n",
        "for epoch in range(epoch_num):\n",
        "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
        "    if ((epoch+1) % 2 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
        "        # 학습용데이터로 rmse오차를 구한다\n",
        "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
        "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
        "        train_error_summary.append(train_error)\n",
        " \n",
        "        # 테스트용데이터로 rmse오차를 구한다\n",
        "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
        "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
        "        test_error_summary.append(test_error)\n",
        "        \n",
        "        # 현재 오류를 출력한다\n",
        "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
        "        \n",
        "# end_time = datetime.datetime.now() # 종료시간을 기록한 다\n",
        "# elapsed_time = end_time - start_time # 경과시간을 구한다\n",
        "# print('elapsed_time:',elapsed_time)\n",
        "# print('elapsed_time per epoch:',elapsed_time/epoch_num)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습을 시작합니다...\n",
            "epoch: 2, train_error(A): 0.32521894574165344, test_error(B): 0.42796966433525085, B-A: 0.10275071859359741\n",
            "epoch: 4, train_error(A): 0.3120677173137665, test_error(B): 0.4129064679145813, B-A: 0.10083875060081482\n",
            "epoch: 6, train_error(A): 0.29872119426727295, test_error(B): 0.3974165916442871, B-A: 0.09869539737701416\n",
            "epoch: 8, train_error(A): 0.28513556718826294, test_error(B): 0.3813914358615875, B-A: 0.09625586867332458\n",
            "epoch: 10, train_error(A): 0.27129653096199036, test_error(B): 0.36473625898361206, B-A: 0.0934397280216217\n",
            "epoch: 12, train_error(A): 0.2572289705276489, test_error(B): 0.3473770320415497, B-A: 0.09014806151390076\n",
            "epoch: 14, train_error(A): 0.24300731718540192, test_error(B): 0.32926082611083984, B-A: 0.08625350892543793\n",
            "epoch: 16, train_error(A): 0.22876973450183868, test_error(B): 0.31036287546157837, B-A: 0.08159314095973969\n",
            "epoch: 18, train_error(A): 0.21473464369773865, test_error(B): 0.2906925678253174, B-A: 0.07595792412757874\n",
            "epoch: 20, train_error(A): 0.20121917128562927, test_error(B): 0.27030402421951294, B-A: 0.06908485293388367\n",
            "epoch: 22, train_error(A): 0.188655287027359, test_error(B): 0.24931329488754272, B-A: 0.060658007860183716\n",
            "epoch: 24, train_error(A): 0.17759054899215698, test_error(B): 0.22792546451091766, B-A: 0.05033491551876068\n",
            "epoch: 26, train_error(A): 0.16864624619483948, test_error(B): 0.20647577941417694, B-A: 0.03782953321933746\n",
            "epoch: 28, train_error(A): 0.16239577531814575, test_error(B): 0.18548160791397095, B-A: 0.023085832595825195\n",
            "epoch: 30, train_error(A): 0.1591474711894989, test_error(B): 0.16569392383098602, B-A: 0.006546452641487122\n",
            "epoch: 32, train_error(A): 0.15869176387786865, test_error(B): 0.14810910820960999, B-A: -0.010582655668258667\n",
            "epoch: 34, train_error(A): 0.16017675399780273, test_error(B): 0.1338517814874649, B-A: -0.02632497251033783\n",
            "epoch: 36, train_error(A): 0.16230782866477966, test_error(B): 0.12383938580751419, B-A: -0.03846844285726547\n",
            "epoch: 38, train_error(A): 0.1638852059841156, test_error(B): 0.11837169528007507, B-A: -0.04551351070404053\n",
            "epoch: 40, train_error(A): 0.16430455446243286, test_error(B): 0.11706908047199249, B-A: -0.04723547399044037\n",
            "epoch: 42, train_error(A): 0.1636257916688919, test_error(B): 0.1191713809967041, B-A: -0.044454410672187805\n",
            "epoch: 44, train_error(A): 0.16229835152626038, test_error(B): 0.12379512935876846, B-A: -0.03850322216749191\n",
            "epoch: 46, train_error(A): 0.16084161400794983, test_error(B): 0.13003690540790558, B-A: -0.03080470860004425\n",
            "epoch: 48, train_error(A): 0.1596389263868332, test_error(B): 0.13703663647174835, B-A: -0.02260228991508484\n",
            "epoch: 50, train_error(A): 0.15886659920215607, test_error(B): 0.14404748380184174, B-A: -0.014819115400314331\n",
            "epoch: 52, train_error(A): 0.15852075815200806, test_error(B): 0.15048854053020477, B-A: -0.008032217621803284\n",
            "epoch: 54, train_error(A): 0.1584896445274353, test_error(B): 0.15596257150173187, B-A: -0.00252707302570343\n",
            "epoch: 56, train_error(A): 0.15862701833248138, test_error(B): 0.1602426916360855, B-A: 0.001615673303604126\n",
            "epoch: 58, train_error(A): 0.15880350768566132, test_error(B): 0.16324275732040405, B-A: 0.004439249634742737\n",
            "epoch: 60, train_error(A): 0.15893153846263885, test_error(B): 0.16498422622680664, B-A: 0.006052687764167786\n",
            "epoch: 62, train_error(A): 0.15896989405155182, test_error(B): 0.1655665934085846, B-A: 0.006596699357032776\n",
            "epoch: 64, train_error(A): 0.15891633927822113, test_error(B): 0.16514411568641663, B-A: 0.006227776408195496\n",
            "epoch: 66, train_error(A): 0.15879477560520172, test_error(B): 0.16390778124332428, B-A: 0.005113005638122559\n",
            "epoch: 68, train_error(A): 0.15864120423793793, test_error(B): 0.16207095980644226, B-A: 0.0034297555685043335\n",
            "epoch: 70, train_error(A): 0.15849119424819946, test_error(B): 0.15985678136348724, B-A: 0.0013655871152877808\n",
            "epoch: 72, train_error(A): 0.15837082266807556, test_error(B): 0.15748566389083862, B-A: -0.0008851587772369385\n",
            "epoch: 74, train_error(A): 0.15829181671142578, test_error(B): 0.15516266226768494, B-A: -0.0031291544437408447\n",
            "epoch: 76, train_error(A): 0.15825167298316956, test_error(B): 0.1530647575855255, B-A: -0.005186915397644043\n",
            "epoch: 78, train_error(A): 0.15823763608932495, test_error(B): 0.1513294279575348, B-A: -0.006908208131790161\n",
            "epoch: 80, train_error(A): 0.15823306143283844, test_error(B): 0.15004630386829376, B-A: -0.008186757564544678\n",
            "epoch: 82, train_error(A): 0.15822342038154602, test_error(B): 0.14925333857536316, B-A: -0.008970081806182861\n",
            "epoch: 84, train_error(A): 0.15820035338401794, test_error(B): 0.14893843233585358, B-A: -0.009261921048164368\n",
            "epoch: 86, train_error(A): 0.15816256403923035, test_error(B): 0.14904634654521942, B-A: -0.009116217494010925\n",
            "epoch: 88, train_error(A): 0.15811410546302795, test_error(B): 0.14948929846286774, B-A: -0.008624807000160217\n",
            "epoch: 90, train_error(A): 0.1580612063407898, test_error(B): 0.15016032755374908, B-A: -0.00790087878704071\n",
            "epoch: 92, train_error(A): 0.15800932049751282, test_error(B): 0.15094655752182007, B-A: -0.007062762975692749\n",
            "epoch: 94, train_error(A): 0.1579613834619522, test_error(B): 0.1517413854598999, B-A: -0.006219998002052307\n",
            "epoch: 96, train_error(A): 0.1579173505306244, test_error(B): 0.15245385468006134, B-A: -0.005463495850563049\n",
            "epoch: 98, train_error(A): 0.15787510573863983, test_error(B): 0.15301519632339478, B-A: -0.004859909415245056\n",
            "epoch: 100, train_error(A): 0.15783166885375977, test_error(B): 0.1533818542957306, B-A: -0.004449814558029175\n",
            "epoch: 102, train_error(A): 0.15778449177742004, test_error(B): 0.15353591740131378, B-A: -0.004248574376106262\n",
            "epoch: 104, train_error(A): 0.1577320545911789, test_error(B): 0.15348303318023682, B-A: -0.004249021410942078\n",
            "epoch: 106, train_error(A): 0.15767399966716766, test_error(B): 0.1532483845949173, B-A: -0.004425615072250366\n",
            "epoch: 108, train_error(A): 0.15761080384254456, test_error(B): 0.15287168323993683, B-A: -0.004739120602607727\n",
            "epoch: 110, train_error(A): 0.1575431078672409, test_error(B): 0.15240126848220825, B-A: -0.005141839385032654\n",
            "epoch: 112, train_error(A): 0.15747126936912537, test_error(B): 0.15188804268836975, B-A: -0.005583226680755615\n",
            "epoch: 114, train_error(A): 0.15739509463310242, test_error(B): 0.15137991309165955, B-A: -0.006015181541442871\n",
            "epoch: 116, train_error(A): 0.15731371939182281, test_error(B): 0.1509166955947876, B-A: -0.006397023797035217\n",
            "epoch: 118, train_error(A): 0.15722595155239105, test_error(B): 0.15052685141563416, B-A: -0.006699100136756897\n",
            "epoch: 120, train_error(A): 0.15713046491146088, test_error(B): 0.15022505819797516, B-A: -0.006905406713485718\n",
            "epoch: 122, train_error(A): 0.15702597796916962, test_error(B): 0.15001191198825836, B-A: -0.007014065980911255\n",
            "epoch: 124, train_error(A): 0.15691141784191132, test_error(B): 0.14987531304359436, B-A: -0.007036104798316956\n",
            "epoch: 126, train_error(A): 0.15678571164608002, test_error(B): 0.14979270100593567, B-A: -0.006993010640144348\n",
            "epoch: 128, train_error(A): 0.15664765238761902, test_error(B): 0.14973509311676025, B-A: -0.006912559270858765\n",
            "epoch: 130, train_error(A): 0.15649567544460297, test_error(B): 0.14967051148414612, B-A: -0.006825163960456848\n",
            "epoch: 132, train_error(A): 0.1563277691602707, test_error(B): 0.14956851303577423, B-A: -0.00675925612449646\n",
            "epoch: 134, train_error(A): 0.15614141523838043, test_error(B): 0.1494034081697464, B-A: -0.006738007068634033\n",
            "epoch: 136, train_error(A): 0.1559336632490158, test_error(B): 0.14915719628334045, B-A: -0.006776466965675354\n",
            "epoch: 138, train_error(A): 0.15570108592510223, test_error(B): 0.1488208919763565, B-A: -0.0068801939487457275\n",
            "epoch: 140, train_error(A): 0.1554398238658905, test_error(B): 0.14839483797550201, B-A: -0.007044985890388489\n",
            "epoch: 142, train_error(A): 0.15514551103115082, test_error(B): 0.1478872299194336, B-A: -0.007258281111717224\n",
            "epoch: 144, train_error(A): 0.1548129916191101, test_error(B): 0.1473114937543869, B-A: -0.007501497864723206\n",
            "epoch: 146, train_error(A): 0.15443618595600128, test_error(B): 0.146682009100914, B-A: -0.00775417685508728\n",
            "epoch: 148, train_error(A): 0.1540079414844513, test_error(B): 0.14600896835327148, B-A: -0.00799897313117981\n",
            "epoch: 150, train_error(A): 0.15351997315883636, test_error(B): 0.14529213309288025, B-A: -0.008227840065956116\n",
            "epoch: 152, train_error(A): 0.15296274423599243, test_error(B): 0.14451470971107483, B-A: -0.008448034524917603\n",
            "epoch: 154, train_error(A): 0.15232539176940918, test_error(B): 0.14363904297351837, B-A: -0.008686348795890808\n",
            "epoch: 156, train_error(A): 0.15159551799297333, test_error(B): 0.14260834455490112, B-A: -0.008987173438072205\n",
            "epoch: 158, train_error(A): 0.15075966715812683, test_error(B): 0.14135468006134033, B-A: -0.009404987096786499\n",
            "epoch: 160, train_error(A): 0.14980459213256836, test_error(B): 0.13981257379055023, B-A: -0.009992018342018127\n",
            "epoch: 162, train_error(A): 0.14871802926063538, test_error(B): 0.13794146478176117, B-A: -0.010776564478874207\n",
            "epoch: 164, train_error(A): 0.14749065041542053, test_error(B): 0.13575062155723572, B-A: -0.011740028858184814\n",
            "epoch: 166, train_error(A): 0.14611844718456268, test_error(B): 0.1332884132862091, B-A: -0.012830033898353577\n",
            "epoch: 168, train_error(A): 0.14460554718971252, test_error(B): 0.13058628141880035, B-A: -0.01401926577091217\n",
            "epoch: 170, train_error(A): 0.14296682178974152, test_error(B): 0.1276116669178009, B-A: -0.015355154871940613\n",
            "epoch: 172, train_error(A): 0.14123018085956573, test_error(B): 0.12434284389019012, B-A: -0.01688733696937561\n",
            "epoch: 174, train_error(A): 0.13943882286548615, test_error(B): 0.12099085748195648, B-A: -0.018447965383529663\n",
            "epoch: 176, train_error(A): 0.1376529484987259, test_error(B): 0.11798116564750671, B-A: -0.019671782851219177\n",
            "epoch: 178, train_error(A): 0.13594847917556763, test_error(B): 0.11553919315338135, B-A: -0.02040928602218628\n",
            "epoch: 180, train_error(A): 0.13441109657287598, test_error(B): 0.11381365358829498, B-A: -0.020597442984580994\n",
            "epoch: 182, train_error(A): 0.1331256479024887, test_error(B): 0.11339380592107773, B-A: -0.01973184198141098\n",
            "epoch: 184, train_error(A): 0.1321548968553543, test_error(B): 0.11452977359294891, B-A: -0.017625123262405396\n",
            "epoch: 186, train_error(A): 0.13151341676712036, test_error(B): 0.11685244739055634, B-A: -0.014660969376564026\n",
            "epoch: 188, train_error(A): 0.13114728033542633, test_error(B): 0.12032543122768402, B-A: -0.01082184910774231\n",
            "epoch: 190, train_error(A): 0.1309346854686737, test_error(B): 0.12391237914562225, B-A: -0.007022306323051453\n",
            "epoch: 192, train_error(A): 0.13072723150253296, test_error(B): 0.12702471017837524, B-A: -0.003702521324157715\n",
            "epoch: 194, train_error(A): 0.13041751086711884, test_error(B): 0.12907017767429352, B-A: -0.0013473331928253174\n",
            "epoch: 196, train_error(A): 0.12998531758785248, test_error(B): 0.12981140613555908, B-A: -0.000173911452293396\n",
            "epoch: 198, train_error(A): 0.1294841170310974, test_error(B): 0.12968073785305023, B-A: 0.00019662082195281982\n",
            "epoch: 200, train_error(A): 0.12899266183376312, test_error(B): 0.12875774502754211, B-A: -0.0002349168062210083\n",
            "epoch: 202, train_error(A): 0.1285681277513504, test_error(B): 0.12767624855041504, B-A: -0.0008918792009353638\n",
            "epoch: 204, train_error(A): 0.12822642922401428, test_error(B): 0.12652640044689178, B-A: -0.0017000287771224976\n",
            "epoch: 206, train_error(A): 0.12794740498065948, test_error(B): 0.12552495300769806, B-A: -0.0024224519729614258\n",
            "epoch: 208, train_error(A): 0.1276942640542984, test_error(B): 0.12480390816926956, B-A: -0.002890355885028839\n",
            "epoch: 210, train_error(A): 0.12743353843688965, test_error(B): 0.12427331507205963, B-A: -0.003160223364830017\n",
            "epoch: 212, train_error(A): 0.12714742124080658, test_error(B): 0.12404993176460266, B-A: -0.0030974894762039185\n",
            "epoch: 214, train_error(A): 0.12683552503585815, test_error(B): 0.12404411286115646, B-A: -0.0027914121747016907\n",
            "epoch: 216, train_error(A): 0.12650947272777557, test_error(B): 0.12425488233566284, B-A: -0.002254590392112732\n",
            "epoch: 218, train_error(A): 0.12618447840213776, test_error(B): 0.12469581514596939, B-A: -0.0014886632561683655\n",
            "epoch: 220, train_error(A): 0.12587210536003113, test_error(B): 0.12524978816509247, B-A: -0.0006223171949386597\n",
            "epoch: 222, train_error(A): 0.12557601928710938, test_error(B): 0.12589305639266968, B-A: 0.00031703710556030273\n",
            "epoch: 224, train_error(A): 0.12529237568378448, test_error(B): 0.1265115886926651, B-A: 0.0012192130088806152\n",
            "epoch: 226, train_error(A): 0.12501363456249237, test_error(B): 0.12704794108867645, B-A: 0.002034306526184082\n",
            "epoch: 228, train_error(A): 0.12473317235708237, test_error(B): 0.1274597942829132, B-A: 0.002726621925830841\n",
            "epoch: 230, train_error(A): 0.124448262155056, test_error(B): 0.12770918011665344, B-A: 0.0032609179615974426\n",
            "epoch: 232, train_error(A): 0.12416021525859833, test_error(B): 0.12783019244670868, B-A: 0.0036699771881103516\n",
            "epoch: 234, train_error(A): 0.12387246638536453, test_error(B): 0.12782803177833557, B-A: 0.003955565392971039\n",
            "epoch: 236, train_error(A): 0.1235879436135292, test_error(B): 0.12777486443519592, B-A: 0.0041869208216667175\n",
            "epoch: 238, train_error(A): 0.12330743670463562, test_error(B): 0.12769757211208344, B-A: 0.004390135407447815\n",
            "epoch: 240, train_error(A): 0.12302961200475693, test_error(B): 0.1276618242263794, B-A: 0.004632212221622467\n",
            "epoch: 242, train_error(A): 0.12275231629610062, test_error(B): 0.12768372893333435, B-A: 0.004931412637233734\n",
            "epoch: 244, train_error(A): 0.12247408926486969, test_error(B): 0.12779073417186737, B-A: 0.005316644906997681\n",
            "epoch: 246, train_error(A): 0.12219478189945221, test_error(B): 0.12799151241779327, B-A: 0.0057967305183410645\n",
            "epoch: 248, train_error(A): 0.12191528081893921, test_error(B): 0.12827347218990326, B-A: 0.00635819137096405\n",
            "epoch: 250, train_error(A): 0.12163680791854858, test_error(B): 0.1286197304725647, B-A: 0.006982922554016113\n",
            "epoch: 252, train_error(A): 0.12136013060808182, test_error(B): 0.12899526953697205, B-A: 0.007635138928890228\n",
            "epoch: 254, train_error(A): 0.1210852712392807, test_error(B): 0.12938548624515533, B-A: 0.008300215005874634\n",
            "epoch: 256, train_error(A): 0.12081179022789001, test_error(B): 0.12974593043327332, B-A: 0.0089341402053833\n",
            "epoch: 258, train_error(A): 0.12053929269313812, test_error(B): 0.13007843494415283, B-A: 0.00953914225101471\n",
            "epoch: 260, train_error(A): 0.12026781588792801, test_error(B): 0.13035650551319122, B-A: 0.010088689625263214\n",
            "epoch: 262, train_error(A): 0.11999768018722534, test_error(B): 0.13060003519058228, B-A: 0.010602355003356934\n",
            "epoch: 264, train_error(A): 0.11972929537296295, test_error(B): 0.13080959022045135, B-A: 0.011080294847488403\n",
            "epoch: 266, train_error(A): 0.11946281045675278, test_error(B): 0.13100488483905792, B-A: 0.011542074382305145\n",
            "epoch: 268, train_error(A): 0.11919821053743362, test_error(B): 0.13120660185813904, B-A: 0.012008391320705414\n",
            "epoch: 270, train_error(A): 0.11893545836210251, test_error(B): 0.13141949474811554, B-A: 0.012484036386013031\n",
            "epoch: 272, train_error(A): 0.11867456138134003, test_error(B): 0.13165396451950073, B-A: 0.012979403138160706\n",
            "epoch: 274, train_error(A): 0.11841575056314468, test_error(B): 0.13190090656280518, B-A: 0.013485155999660492\n",
            "epoch: 276, train_error(A): 0.11815933138132095, test_error(B): 0.13216927647590637, B-A: 0.014009945094585419\n",
            "epoch: 278, train_error(A): 0.11790543794631958, test_error(B): 0.13243499398231506, B-A: 0.014529556035995483\n",
            "epoch: 280, train_error(A): 0.11765415221452713, test_error(B): 0.13270607590675354, B-A: 0.01505192369222641\n",
            "epoch: 282, train_error(A): 0.11740539222955704, test_error(B): 0.13294938206672668, B-A: 0.015543989837169647\n",
            "epoch: 284, train_error(A): 0.11715922504663467, test_error(B): 0.1331932246685028, B-A: 0.016033999621868134\n",
            "epoch: 286, train_error(A): 0.11691576987504959, test_error(B): 0.13341842591762543, B-A: 0.016502656042575836\n",
            "epoch: 288, train_error(A): 0.11667510867118835, test_error(B): 0.1336507946252823, B-A: 0.016975685954093933\n",
            "epoch: 290, train_error(A): 0.11643726378679276, test_error(B): 0.13388198614120483, B-A: 0.01744472235441208\n",
            "epoch: 292, train_error(A): 0.11620223522186279, test_error(B): 0.13413095474243164, B-A: 0.017928719520568848\n",
            "epoch: 294, train_error(A): 0.11596997827291489, test_error(B): 0.1343841850757599, B-A: 0.018414206802845\n",
            "epoch: 296, train_error(A): 0.11574048548936844, test_error(B): 0.13464868068695068, B-A: 0.018908195197582245\n",
            "epoch: 298, train_error(A): 0.11551371216773987, test_error(B): 0.13491597771644592, B-A: 0.019402265548706055\n",
            "epoch: 300, train_error(A): 0.11528953164815903, test_error(B): 0.1351657211780548, B-A: 0.019876189529895782\n",
            "epoch: 302, train_error(A): 0.11506767570972443, test_error(B): 0.13539884984493256, B-A: 0.02033117413520813\n",
            "epoch: 304, train_error(A): 0.11484790593385696, test_error(B): 0.13561265170574188, B-A: 0.020764745771884918\n",
            "epoch: 306, train_error(A): 0.11463010311126709, test_error(B): 0.1358298361301422, B-A: 0.021199733018875122\n",
            "epoch: 308, train_error(A): 0.11441396921873093, test_error(B): 0.136030375957489, B-A: 0.021616406738758087\n",
            "epoch: 310, train_error(A): 0.11419910192489624, test_error(B): 0.13623063266277313, B-A: 0.022031530737876892\n",
            "epoch: 312, train_error(A): 0.11398511379957199, test_error(B): 0.1364336460828781, B-A: 0.022448532283306122\n",
            "epoch: 314, train_error(A): 0.11377164721488953, test_error(B): 0.13664056360721588, B-A: 0.022868916392326355\n",
            "epoch: 316, train_error(A): 0.11355838924646378, test_error(B): 0.13685403764247894, B-A: 0.023295648396015167\n",
            "epoch: 318, train_error(A): 0.11334509402513504, test_error(B): 0.13705997169017792, B-A: 0.023714877665042877\n",
            "epoch: 320, train_error(A): 0.1131318211555481, test_error(B): 0.13724683225154877, B-A: 0.02411501109600067\n",
            "epoch: 322, train_error(A): 0.11291865259408951, test_error(B): 0.1374090611934662, B-A: 0.02449040859937668\n",
            "epoch: 324, train_error(A): 0.11270570755004883, test_error(B): 0.13752804696559906, B-A: 0.024822339415550232\n",
            "epoch: 326, train_error(A): 0.1124926507472992, test_error(B): 0.13759073615074158, B-A: 0.025098085403442383\n",
            "epoch: 328, train_error(A): 0.1122790053486824, test_error(B): 0.13759556412696838, B-A: 0.02531655877828598\n",
            "epoch: 330, train_error(A): 0.11206412315368652, test_error(B): 0.13754360377788544, B-A: 0.025479480624198914\n",
            "epoch: 332, train_error(A): 0.11184720695018768, test_error(B): 0.13745135068893433, B-A: 0.025604143738746643\n",
            "epoch: 334, train_error(A): 0.1116274893283844, test_error(B): 0.13737992942333221, B-A: 0.025752440094947815\n",
            "epoch: 336, train_error(A): 0.11140435189008713, test_error(B): 0.13734345138072968, B-A: 0.025939099490642548\n",
            "epoch: 338, train_error(A): 0.11117683351039886, test_error(B): 0.13736256957054138, B-A: 0.026185736060142517\n",
            "epoch: 340, train_error(A): 0.1109439879655838, test_error(B): 0.137434184551239, B-A: 0.026490196585655212\n",
            "epoch: 342, train_error(A): 0.11070515215396881, test_error(B): 0.13752496242523193, B-A: 0.026819810271263123\n",
            "epoch: 344, train_error(A): 0.11045952141284943, test_error(B): 0.13759297132492065, B-A: 0.027133449912071228\n",
            "epoch: 346, train_error(A): 0.11020606011152267, test_error(B): 0.13759277760982513, B-A: 0.02738671749830246\n",
            "epoch: 348, train_error(A): 0.10994353145360947, test_error(B): 0.13751788437366486, B-A: 0.02757435292005539\n",
            "epoch: 350, train_error(A): 0.10967057943344116, test_error(B): 0.13742321729660034, B-A: 0.02775263786315918\n",
            "epoch: 352, train_error(A): 0.10938739776611328, test_error(B): 0.13773773610591888, B-A: 0.028350338339805603\n",
            "epoch: 354, train_error(A): 0.10914622247219086, test_error(B): 0.14126907289028168, B-A: 0.03212285041809082\n",
            "epoch: 356, train_error(A): 0.10918767750263214, test_error(B): 0.14777815341949463, B-A: 0.03859047591686249\n",
            "epoch: 358, train_error(A): 0.10877257585525513, test_error(B): 0.1272999495267868, B-A: 0.018527373671531677\n",
            "epoch: 360, train_error(A): 0.10834194719791412, test_error(B): 0.13874034583568573, B-A: 0.030398398637771606\n",
            "epoch: 362, train_error(A): 0.10810242593288422, test_error(B): 0.13856706023216248, B-A: 0.03046463429927826\n",
            "epoch: 364, train_error(A): 0.10793032497167587, test_error(B): 0.1296488493680954, B-A: 0.021718524396419525\n",
            "epoch: 366, train_error(A): 0.1077452227473259, test_error(B): 0.14229193329811096, B-A: 0.034546710550785065\n",
            "epoch: 368, train_error(A): 0.10750406980514526, test_error(B): 0.12789274752140045, B-A: 0.020388677716255188\n",
            "epoch: 370, train_error(A): 0.10719461739063263, test_error(B): 0.13933289051055908, B-A: 0.03213827311992645\n",
            "epoch: 372, train_error(A): 0.10690146684646606, test_error(B): 0.13369131088256836, B-A: 0.026789844036102295\n",
            "epoch: 374, train_error(A): 0.10669749975204468, test_error(B): 0.13118749856948853, B-A: 0.024489998817443848\n",
            "epoch: 376, train_error(A): 0.10652285069227219, test_error(B): 0.1389886438846588, B-A: 0.03246579319238663\n",
            "epoch: 378, train_error(A): 0.10626868903636932, test_error(B): 0.1305558830499649, B-A: 0.02428719401359558\n",
            "epoch: 380, train_error(A): 0.10603155940771103, test_error(B): 0.13281914591789246, B-A: 0.026787586510181427\n",
            "epoch: 382, train_error(A): 0.10588476806879044, test_error(B): 0.13843673467636108, B-A: 0.03255196660757065\n",
            "epoch: 384, train_error(A): 0.10564454644918442, test_error(B): 0.13307493925094604, B-A: 0.027430392801761627\n",
            "epoch: 386, train_error(A): 0.10551054775714874, test_error(B): 0.13044419884681702, B-A: 0.024933651089668274\n",
            "epoch: 388, train_error(A): 0.105306476354599, test_error(B): 0.134403258562088, B-A: 0.029096782207489014\n",
            "epoch: 390, train_error(A): 0.10520422458648682, test_error(B): 0.13777925074100494, B-A: 0.03257502615451813\n",
            "epoch: 392, train_error(A): 0.10507100075483322, test_error(B): 0.13742415606975555, B-A: 0.03235315531492233\n",
            "epoch: 394, train_error(A): 0.10492211580276489, test_error(B): 0.1351402848958969, B-A: 0.03021816909313202\n",
            "epoch: 396, train_error(A): 0.1048114150762558, test_error(B): 0.13296787440776825, B-A: 0.02815645933151245\n",
            "epoch: 398, train_error(A): 0.10473673045635223, test_error(B): 0.13078223168849945, B-A: 0.026045501232147217\n",
            "epoch: 400, train_error(A): 0.10479795187711716, test_error(B): 0.12627187371253967, B-A: 0.021473921835422516\n",
            "epoch: 402, train_error(A): 0.10528513789176941, test_error(B): 0.11935896426439285, B-A: 0.014073826372623444\n",
            "epoch: 404, train_error(A): 0.1045178547501564, test_error(B): 0.13064587116241455, B-A: 0.026128016412258148\n",
            "epoch: 406, train_error(A): 0.10497473180294037, test_error(B): 0.14570863544940948, B-A: 0.040733903646469116\n",
            "epoch: 408, train_error(A): 0.10459715873003006, test_error(B): 0.12577538192272186, B-A: 0.021178223192691803\n",
            "epoch: 410, train_error(A): 0.10433553904294968, test_error(B): 0.13177461922168732, B-A: 0.02743908017873764\n",
            "epoch: 412, train_error(A): 0.10451499372720718, test_error(B): 0.14079472422599792, B-A: 0.03627973049879074\n",
            "epoch: 414, train_error(A): 0.10450881719589233, test_error(B): 0.12400098890066147, B-A: 0.019492171704769135\n",
            "epoch: 416, train_error(A): 0.10426080971956253, test_error(B): 0.1367396116256714, B-A: 0.032478801906108856\n",
            "epoch: 418, train_error(A): 0.10413108766078949, test_error(B): 0.13246838748455048, B-A: 0.028337299823760986\n",
            "epoch: 420, train_error(A): 0.10414538532495499, test_error(B): 0.12759071588516235, B-A: 0.023445330560207367\n",
            "epoch: 422, train_error(A): 0.10414522886276245, test_error(B): 0.13686083257198334, B-A: 0.032715603709220886\n",
            "epoch: 424, train_error(A): 0.10406827926635742, test_error(B): 0.12691941857337952, B-A: 0.022851139307022095\n",
            "epoch: 426, train_error(A): 0.10396067798137665, test_error(B): 0.13348619639873505, B-A: 0.0295255184173584\n",
            "epoch: 428, train_error(A): 0.1038983017206192, test_error(B): 0.1318987011909485, B-A: 0.028000399470329285\n",
            "epoch: 430, train_error(A): 0.10387705266475677, test_error(B): 0.1285392791032791, B-A: 0.02466222643852234\n",
            "epoch: 432, train_error(A): 0.10384666174650192, test_error(B): 0.13420723378658295, B-A: 0.030360572040081024\n",
            "epoch: 434, train_error(A): 0.10378661006689072, test_error(B): 0.1281827688217163, B-A: 0.024396158754825592\n",
            "epoch: 436, train_error(A): 0.10371872782707214, test_error(B): 0.13152818381786346, B-A: 0.02780945599079132\n",
            "epoch: 438, train_error(A): 0.10367234796285629, test_error(B): 0.13118146359920502, B-A: 0.027509115636348724\n",
            "epoch: 440, train_error(A): 0.10363903641700745, test_error(B): 0.12818293273448944, B-A: 0.024543896317481995\n",
            "epoch: 442, train_error(A): 0.10359325259923935, test_error(B): 0.13188552856445312, B-A: 0.028292275965213776\n",
            "epoch: 444, train_error(A): 0.10353634506464005, test_error(B): 0.12882159650325775, B-A: 0.025285251438617706\n",
            "epoch: 446, train_error(A): 0.10348740965127945, test_error(B): 0.12927354872226715, B-A: 0.0257861390709877\n",
            "epoch: 448, train_error(A): 0.10344760119915009, test_error(B): 0.13080887496471405, B-A: 0.027361273765563965\n",
            "epoch: 450, train_error(A): 0.10340150445699692, test_error(B): 0.12808823585510254, B-A: 0.02468673139810562\n",
            "epoch: 452, train_error(A): 0.1033494621515274, test_error(B): 0.12968283891677856, B-A: 0.02633337676525116\n",
            "epoch: 454, train_error(A): 0.10330381244421005, test_error(B): 0.12969481945037842, B-A: 0.026391007006168365\n",
            "epoch: 456, train_error(A): 0.10326013714075089, test_error(B): 0.12790781259536743, B-A: 0.024647675454616547\n",
            "epoch: 458, train_error(A): 0.10321062803268433, test_error(B): 0.1293259710073471, B-A: 0.02611534297466278\n",
            "epoch: 460, train_error(A): 0.10316311568021774, test_error(B): 0.12892146408557892, B-A: 0.025758348405361176\n",
            "epoch: 462, train_error(A): 0.10311824083328247, test_error(B): 0.12767332792282104, B-A: 0.024555087089538574\n",
            "epoch: 464, train_error(A): 0.10306957364082336, test_error(B): 0.12866730988025665, B-A: 0.02559773623943329\n",
            "epoch: 466, train_error(A): 0.10302241146564484, test_error(B): 0.12848646938800812, B-A: 0.02546405792236328\n",
            "epoch: 468, train_error(A): 0.10297606140375137, test_error(B): 0.12744088470935822, B-A: 0.024464823305606842\n",
            "epoch: 470, train_error(A): 0.10292746871709824, test_error(B): 0.12796828150749207, B-A: 0.02504081279039383\n",
            "epoch: 472, train_error(A): 0.10288072377443314, test_error(B): 0.12818722426891327, B-A: 0.025306500494480133\n",
            "epoch: 474, train_error(A): 0.10283268988132477, test_error(B): 0.12732885777950287, B-A: 0.0244961678981781\n",
            "epoch: 476, train_error(A): 0.10278479009866714, test_error(B): 0.12724669277668, B-A: 0.024461902678012848\n",
            "epoch: 478, train_error(A): 0.10273704677820206, test_error(B): 0.12768226861953735, B-A: 0.024945221841335297\n",
            "epoch: 480, train_error(A): 0.10268857330083847, test_error(B): 0.12734650075435638, B-A: 0.024657927453517914\n",
            "epoch: 482, train_error(A): 0.10264057666063309, test_error(B): 0.12679998576641083, B-A: 0.02415940910577774\n",
            "epoch: 484, train_error(A): 0.10259179770946503, test_error(B): 0.12687945365905762, B-A: 0.02428765594959259\n",
            "epoch: 486, train_error(A): 0.10254335403442383, test_error(B): 0.1271037459373474, B-A: 0.024560391902923584\n",
            "epoch: 488, train_error(A): 0.10249432176351547, test_error(B): 0.1268760710954666, B-A: 0.02438174933195114\n",
            "epoch: 490, train_error(A): 0.1024453341960907, test_error(B): 0.12648645043373108, B-A: 0.02404111623764038\n",
            "epoch: 492, train_error(A): 0.10239608585834503, test_error(B): 0.12638349831104279, B-A: 0.023987412452697754\n",
            "epoch: 494, train_error(A): 0.1023465096950531, test_error(B): 0.1265024095773697, B-A: 0.02415589988231659\n",
            "epoch: 496, train_error(A): 0.10229694098234177, test_error(B): 0.1265335977077484, B-A: 0.024236656725406647\n",
            "epoch: 498, train_error(A): 0.10224694758653641, test_error(B): 0.1263628602027893, B-A: 0.0241159126162529\n",
            "epoch: 500, train_error(A): 0.10219673812389374, test_error(B): 0.12611570954322815, B-A: 0.02391897141933441\n",
            "epoch: 502, train_error(A): 0.10214637964963913, test_error(B): 0.12593746185302734, B-A: 0.023791082203388214\n",
            "epoch: 504, train_error(A): 0.10209566354751587, test_error(B): 0.1258619725704193, B-A: 0.023766309022903442\n",
            "epoch: 506, train_error(A): 0.10204464197158813, test_error(B): 0.12584622204303741, B-A: 0.02380158007144928\n",
            "epoch: 508, train_error(A): 0.10199334472417831, test_error(B): 0.12584136426448822, B-A: 0.023848019540309906\n",
            "epoch: 510, train_error(A): 0.1019418016076088, test_error(B): 0.12582702934741974, B-A: 0.023885227739810944\n",
            "epoch: 512, train_error(A): 0.1018899604678154, test_error(B): 0.1258123517036438, B-A: 0.0239223912358284\n",
            "epoch: 514, train_error(A): 0.10183791071176529, test_error(B): 0.12582862377166748, B-A: 0.02399071305990219\n",
            "epoch: 516, train_error(A): 0.10178586095571518, test_error(B): 0.125943124294281, B-A: 0.024157263338565826\n",
            "epoch: 518, train_error(A): 0.10173536092042923, test_error(B): 0.1263209581375122, B-A: 0.024585597217082977\n",
            "epoch: 520, train_error(A): 0.10169652104377747, test_error(B): 0.1274460405111313, B-A: 0.02574951946735382\n",
            "epoch: 522, train_error(A): 0.1017455905675888, test_error(B): 0.13077130913734436, B-A: 0.029025718569755554\n",
            "epoch: 524, train_error(A): 0.10230235010385513, test_error(B): 0.13910828530788422, B-A: 0.03680593520402908\n",
            "epoch: 526, train_error(A): 0.1024271547794342, test_error(B): 0.14085356891155243, B-A: 0.038426414132118225\n",
            "epoch: 528, train_error(A): 0.10174543410539627, test_error(B): 0.11848358064889908, B-A: 0.016738146543502808\n",
            "epoch: 530, train_error(A): 0.10165099799633026, test_error(B): 0.11940712481737137, B-A: 0.017756126821041107\n",
            "epoch: 532, train_error(A): 0.1019209772348404, test_error(B): 0.1373375803232193, B-A: 0.035416603088378906\n",
            "epoch: 534, train_error(A): 0.10143180191516876, test_error(B): 0.12198357284069061, B-A: 0.02055177092552185\n",
            "epoch: 536, train_error(A): 0.10141121596097946, test_error(B): 0.12124371528625488, B-A: 0.01983249932527542\n",
            "epoch: 538, train_error(A): 0.10154794156551361, test_error(B): 0.1332223117351532, B-A: 0.03167437016963959\n",
            "epoch: 540, train_error(A): 0.10132276266813278, test_error(B): 0.12113010883331299, B-A: 0.019807346165180206\n",
            "epoch: 542, train_error(A): 0.10122224688529968, test_error(B): 0.1232214942574501, B-A: 0.02199924737215042\n",
            "epoch: 544, train_error(A): 0.10131074488162994, test_error(B): 0.1310458928346634, B-A: 0.029735147953033447\n",
            "epoch: 546, train_error(A): 0.10120002925395966, test_error(B): 0.12126694619655609, B-A: 0.020066916942596436\n",
            "epoch: 548, train_error(A): 0.10108371078968048, test_error(B): 0.12470950931310654, B-A: 0.023625798523426056\n",
            "epoch: 550, train_error(A): 0.10112666338682175, test_error(B): 0.12991102039813995, B-A: 0.028784357011318207\n",
            "epoch: 552, train_error(A): 0.10105244070291519, test_error(B): 0.12197691947221756, B-A: 0.020924478769302368\n",
            "epoch: 554, train_error(A): 0.1009567454457283, test_error(B): 0.12465737760066986, B-A: 0.02370063215494156\n",
            "epoch: 556, train_error(A): 0.1009727492928505, test_error(B): 0.1288931965827942, B-A: 0.027920447289943695\n",
            "epoch: 558, train_error(A): 0.10089308768510818, test_error(B): 0.12283165007829666, B-A: 0.021938562393188477\n",
            "epoch: 560, train_error(A): 0.10083509236574173, test_error(B): 0.12362797558307648, B-A: 0.022792883217334747\n",
            "epoch: 562, train_error(A): 0.10082145780324936, test_error(B): 0.12797227501869202, B-A: 0.027150817215442657\n",
            "epoch: 564, train_error(A): 0.10073984414339066, test_error(B): 0.12453227490186691, B-A: 0.023792430758476257\n",
            "epoch: 566, train_error(A): 0.10071532428264618, test_error(B): 0.12299854308366776, B-A: 0.022283218801021576\n",
            "epoch: 568, train_error(A): 0.10065821558237076, test_error(B): 0.12645678222179413, B-A: 0.02579856663942337\n",
            "epoch: 570, train_error(A): 0.10061405599117279, test_error(B): 0.12650644779205322, B-A: 0.025892391800880432\n",
            "epoch: 572, train_error(A): 0.1005699560046196, test_error(B): 0.12368830293416977, B-A: 0.02311834692955017\n",
            "epoch: 574, train_error(A): 0.10051902383565903, test_error(B): 0.1241506040096283, B-A: 0.02363158017396927\n",
            "epoch: 576, train_error(A): 0.10047680884599686, test_error(B): 0.12632989883422852, B-A: 0.02585308998823166\n",
            "epoch: 578, train_error(A): 0.1004265546798706, test_error(B): 0.12589044868946075, B-A: 0.02546389400959015\n",
            "epoch: 580, train_error(A): 0.10038083046674728, test_error(B): 0.12412280589342117, B-A: 0.02374197542667389\n",
            "epoch: 582, train_error(A): 0.10033432394266129, test_error(B): 0.12412644177675247, B-A: 0.023792117834091187\n",
            "epoch: 584, train_error(A): 0.10028378665447235, test_error(B): 0.12554745376110077, B-A: 0.025263667106628418\n",
            "epoch: 586, train_error(A): 0.10024034976959229, test_error(B): 0.12617485225200653, B-A: 0.025934502482414246\n",
            "epoch: 588, train_error(A): 0.10018803924322128, test_error(B): 0.12543371319770813, B-A: 0.025245673954486847\n",
            "epoch: 590, train_error(A): 0.10014176368713379, test_error(B): 0.12454044073820114, B-A: 0.024398677051067352\n",
            "epoch: 592, train_error(A): 0.1000940203666687, test_error(B): 0.12445380538702011, B-A: 0.02435978502035141\n",
            "epoch: 594, train_error(A): 0.10004256665706635, test_error(B): 0.12505172193050385, B-A: 0.0250091552734375\n",
            "epoch: 596, train_error(A): 0.09999413788318634, test_error(B): 0.12570534646511078, B-A: 0.02571120858192444\n",
            "epoch: 598, train_error(A): 0.099946029484272, test_error(B): 0.12600558996200562, B-A: 0.026059560477733612\n",
            "epoch: 600, train_error(A): 0.09989549964666367, test_error(B): 0.12594559788703918, B-A: 0.02605009824037552\n",
            "epoch: 602, train_error(A): 0.09984400868415833, test_error(B): 0.1257147192955017, B-A: 0.025870710611343384\n",
            "epoch: 604, train_error(A): 0.09979286044836044, test_error(B): 0.1254732459783554, B-A: 0.025680385529994965\n",
            "epoch: 606, train_error(A): 0.09974201768636703, test_error(B): 0.12527574598789215, B-A: 0.025533728301525116\n",
            "epoch: 608, train_error(A): 0.09969125688076019, test_error(B): 0.12508736550807953, B-A: 0.025396108627319336\n",
            "epoch: 610, train_error(A): 0.09964125603437424, test_error(B): 0.12480492144823074, B-A: 0.025163665413856506\n",
            "epoch: 612, train_error(A): 0.09959553927183151, test_error(B): 0.1242254227399826, B-A: 0.024629883468151093\n",
            "epoch: 614, train_error(A): 0.09957148134708405, test_error(B): 0.1228947639465332, B-A: 0.023323282599449158\n",
            "epoch: 616, train_error(A): 0.09965934604406357, test_error(B): 0.11982563138008118, B-A: 0.02016628533601761\n",
            "epoch: 618, train_error(A): 0.1001667007803917, test_error(B): 0.11423083394765854, B-A: 0.014064133167266846\n",
            "epoch: 620, train_error(A): 0.10036667436361313, test_error(B): 0.11283355206251144, B-A: 0.012466877698898315\n",
            "epoch: 622, train_error(A): 0.09934049844741821, test_error(B): 0.12718957662582397, B-A: 0.02784907817840576\n",
            "epoch: 624, train_error(A): 0.10000579059123993, test_error(B): 0.13932104408740997, B-A: 0.039315253496170044\n",
            "epoch: 626, train_error(A): 0.09926322847604752, test_error(B): 0.12494807690382004, B-A: 0.025684848427772522\n",
            "epoch: 628, train_error(A): 0.0995648056268692, test_error(B): 0.11820510029792786, B-A: 0.018640294671058655\n",
            "epoch: 630, train_error(A): 0.09922321885824203, test_error(B): 0.12987957894802094, B-A: 0.0306563600897789\n",
            "epoch: 632, train_error(A): 0.09930113703012466, test_error(B): 0.13238810002803802, B-A: 0.03308696299791336\n",
            "epoch: 634, train_error(A): 0.09919331222772598, test_error(B): 0.12126107513904572, B-A: 0.022067762911319733\n",
            "epoch: 636, train_error(A): 0.09907809644937515, test_error(B): 0.12301080673933029, B-A: 0.02393271028995514\n",
            "epoch: 638, train_error(A): 0.09912241995334625, test_error(B): 0.13183775544166565, B-A: 0.0327153354883194\n",
            "epoch: 640, train_error(A): 0.09893791377544403, test_error(B): 0.12745586037635803, B-A: 0.028517946600914\n",
            "epoch: 642, train_error(A): 0.09898947924375534, test_error(B): 0.12215856462717056, B-A: 0.023169085383415222\n",
            "epoch: 644, train_error(A): 0.09883905202150345, test_error(B): 0.1267419159412384, B-A: 0.027902863919734955\n",
            "epoch: 646, train_error(A): 0.09886781126260757, test_error(B): 0.13062100112438202, B-A: 0.031753189861774445\n",
            "epoch: 648, train_error(A): 0.0987430289387703, test_error(B): 0.1262894719839096, B-A: 0.027546443045139313\n",
            "epoch: 650, train_error(A): 0.09874669462442398, test_error(B): 0.12334814667701721, B-A: 0.02460145205259323\n",
            "epoch: 652, train_error(A): 0.09864529222249985, test_error(B): 0.1263498216867447, B-A: 0.027704529464244843\n",
            "epoch: 654, train_error(A): 0.0986325591802597, test_error(B): 0.1293760985136032, B-A: 0.030743539333343506\n",
            "epoch: 656, train_error(A): 0.09855141490697861, test_error(B): 0.12780556082725525, B-A: 0.029254145920276642\n",
            "epoch: 658, train_error(A): 0.09851210564374924, test_error(B): 0.12507155537605286, B-A: 0.02655944973230362\n",
            "epoch: 660, train_error(A): 0.0984618216753006, test_error(B): 0.12513239681720734, B-A: 0.02667057514190674\n",
            "epoch: 662, train_error(A): 0.09839441627264023, test_error(B): 0.12734392285346985, B-A: 0.02894950658082962\n",
            "epoch: 664, train_error(A): 0.09835858643054962, test_error(B): 0.1288125216960907, B-A: 0.030453935265541077\n",
            "epoch: 666, train_error(A): 0.09829754382371902, test_error(B): 0.12825161218643188, B-A: 0.02995406836271286\n",
            "epoch: 668, train_error(A): 0.09823721647262573, test_error(B): 0.12673062086105347, B-A: 0.028493404388427734\n",
            "epoch: 670, train_error(A): 0.09819275140762329, test_error(B): 0.12571975588798523, B-A: 0.02752700448036194\n",
            "epoch: 672, train_error(A): 0.09813983738422394, test_error(B): 0.1257081925868988, B-A: 0.027568355202674866\n",
            "epoch: 674, train_error(A): 0.0980781838297844, test_error(B): 0.12637974321842194, B-A: 0.028301559388637543\n",
            "epoch: 676, train_error(A): 0.09801935404539108, test_error(B): 0.12723217904567719, B-A: 0.029212825000286102\n",
            "epoch: 678, train_error(A): 0.09796537458896637, test_error(B): 0.12796440720558167, B-A: 0.029999032616615295\n",
            "epoch: 680, train_error(A): 0.09791354835033417, test_error(B): 0.12854401767253876, B-A: 0.03063046932220459\n",
            "epoch: 682, train_error(A): 0.09786396473646164, test_error(B): 0.12912152707576752, B-A: 0.03125756233930588\n",
            "epoch: 684, train_error(A): 0.09782281517982483, test_error(B): 0.1299637407064438, B-A: 0.03214092552661896\n",
            "epoch: 686, train_error(A): 0.097811259329319, test_error(B): 0.13148237764835358, B-A: 0.033671118319034576\n",
            "epoch: 688, train_error(A): 0.09789608418941498, test_error(B): 0.1343131959438324, B-A: 0.03641711175441742\n",
            "epoch: 690, train_error(A): 0.09821026772260666, test_error(B): 0.13884788751602173, B-A: 0.04063761979341507\n",
            "epoch: 692, train_error(A): 0.09844011813402176, test_error(B): 0.14156606793403625, B-A: 0.043125949800014496\n",
            "epoch: 694, train_error(A): 0.09769147634506226, test_error(B): 0.13423028588294983, B-A: 0.03653880953788757\n",
            "epoch: 696, train_error(A): 0.09762705117464066, test_error(B): 0.1230032667517662, B-A: 0.02537621557712555\n",
            "epoch: 698, train_error(A): 0.09779343008995056, test_error(B): 0.12019308656454086, B-A: 0.0223996564745903\n",
            "epoch: 700, train_error(A): 0.09736442565917969, test_error(B): 0.1276099532842636, B-A: 0.030245527625083923\n",
            "epoch: 702, train_error(A): 0.09755223244428635, test_error(B): 0.13506804406642914, B-A: 0.03751581162214279\n",
            "epoch: 704, train_error(A): 0.09736303985118866, test_error(B): 0.13261963427066803, B-A: 0.03525659441947937\n",
            "epoch: 706, train_error(A): 0.09725634008646011, test_error(B): 0.12528087198734283, B-A: 0.02802453190088272\n",
            "epoch: 708, train_error(A): 0.09731575846672058, test_error(B): 0.12305096536874771, B-A: 0.02573520690202713\n",
            "epoch: 710, train_error(A): 0.09711359441280365, test_error(B): 0.1274387240409851, B-A: 0.030325129628181458\n",
            "epoch: 712, train_error(A): 0.09713073819875717, test_error(B): 0.13258226215839386, B-A: 0.03545152395963669\n",
            "epoch: 714, train_error(A): 0.09709398448467255, test_error(B): 0.13303691148757935, B-A: 0.0359429270029068\n",
            "epoch: 716, train_error(A): 0.09695609658956528, test_error(B): 0.12951990962028503, B-A: 0.03256381303071976\n",
            "epoch: 718, train_error(A): 0.09694637358188629, test_error(B): 0.12617315351963043, B-A: 0.02922677993774414\n",
            "epoch: 720, train_error(A): 0.09692534059286118, test_error(B): 0.1253771334886551, B-A: 0.028451792895793915\n",
            "epoch: 722, train_error(A): 0.09682805091142654, test_error(B): 0.126968115568161, B-A: 0.030140064656734467\n",
            "epoch: 724, train_error(A): 0.09675563126802444, test_error(B): 0.1294514685869217, B-A: 0.03269583731889725\n",
            "epoch: 726, train_error(A): 0.09673140197992325, test_error(B): 0.13146214187145233, B-A: 0.03473073989152908\n",
            "epoch: 728, train_error(A): 0.09670925885438919, test_error(B): 0.13252368569374084, B-A: 0.035814426839351654\n",
            "epoch: 730, train_error(A): 0.09666721522808075, test_error(B): 0.1327953189611435, B-A: 0.036128103733062744\n",
            "epoch: 732, train_error(A): 0.09661169350147247, test_error(B): 0.13262605667114258, B-A: 0.036014363169670105\n",
            "epoch: 734, train_error(A): 0.09655475616455078, test_error(B): 0.132359117269516, B-A: 0.03580436110496521\n",
            "epoch: 736, train_error(A): 0.09650436788797379, test_error(B): 0.13227573037147522, B-A: 0.035771362483501434\n",
            "epoch: 738, train_error(A): 0.09646660089492798, test_error(B): 0.13260653614997864, B-A: 0.03613993525505066\n",
            "epoch: 740, train_error(A): 0.09645511209964752, test_error(B): 0.13360853493213654, B-A: 0.037153422832489014\n",
            "epoch: 742, train_error(A): 0.09650851041078568, test_error(B): 0.13563676178455353, B-A: 0.03912825137376785\n",
            "epoch: 744, train_error(A): 0.09670224785804749, test_error(B): 0.13893868029117584, B-A: 0.04223643243312836\n",
            "epoch: 746, train_error(A): 0.09697230905294418, test_error(B): 0.14215736091136932, B-A: 0.04518505185842514\n",
            "epoch: 748, train_error(A): 0.09670230001211166, test_error(B): 0.1401812583208084, B-A: 0.04347895830869675\n",
            "epoch: 750, train_error(A): 0.09615863859653473, test_error(B): 0.13115397095680237, B-A: 0.03499533236026764\n",
            "epoch: 752, train_error(A): 0.09635776281356812, test_error(B): 0.12314453721046448, B-A: 0.026786774396896362\n",
            "epoch: 754, train_error(A): 0.09635352343320847, test_error(B): 0.12253984063863754, B-A: 0.026186317205429077\n",
            "epoch: 756, train_error(A): 0.09603423625230789, test_error(B): 0.12889188528060913, B-A: 0.03285764902830124\n",
            "epoch: 758, train_error(A): 0.09614398330450058, test_error(B): 0.13520197570323944, B-A: 0.03905799239873886\n",
            "epoch: 760, train_error(A): 0.09610769897699356, test_error(B): 0.13535472750663757, B-A: 0.03924702852964401\n",
            "epoch: 762, train_error(A): 0.09591244906187057, test_error(B): 0.13035722076892853, B-A: 0.03444477170705795\n",
            "epoch: 764, train_error(A): 0.09595926851034164, test_error(B): 0.12594915926456451, B-A: 0.02998989075422287\n",
            "epoch: 766, train_error(A): 0.09594280272722244, test_error(B): 0.12556643784046173, B-A: 0.02962363511323929\n",
            "epoch: 768, train_error(A): 0.09580668807029724, test_error(B): 0.12861622869968414, B-A: 0.0328095406293869\n",
            "epoch: 770, train_error(A): 0.09577447175979614, test_error(B): 0.13225491344928741, B-A: 0.03648044168949127\n",
            "epoch: 772, train_error(A): 0.09579138457775116, test_error(B): 0.13414226472377777, B-A: 0.03835088014602661\n",
            "epoch: 774, train_error(A): 0.09574050456285477, test_error(B): 0.13380980491638184, B-A: 0.03806930035352707\n",
            "epoch: 776, train_error(A): 0.09565511345863342, test_error(B): 0.13208509981632233, B-A: 0.036429986357688904\n",
            "epoch: 778, train_error(A): 0.0956006646156311, test_error(B): 0.1301012933254242, B-A: 0.03450062870979309\n",
            "epoch: 780, train_error(A): 0.09557998925447464, test_error(B): 0.12854084372520447, B-A: 0.03296085447072983\n",
            "epoch: 782, train_error(A): 0.09557032585144043, test_error(B): 0.12747497856616974, B-A: 0.03190465271472931\n",
            "epoch: 784, train_error(A): 0.0955633595585823, test_error(B): 0.12666407227516174, B-A: 0.031100712716579437\n",
            "epoch: 786, train_error(A): 0.09556546062231064, test_error(B): 0.1258264183998108, B-A: 0.030260957777500153\n",
            "epoch: 788, train_error(A): 0.09558867663145065, test_error(B): 0.12478183209896088, B-A: 0.029193155467510223\n",
            "epoch: 790, train_error(A): 0.09563972055912018, test_error(B): 0.12355811148881912, B-A: 0.027918390929698944\n",
            "epoch: 792, train_error(A): 0.09568609297275543, test_error(B): 0.12262335419654846, B-A: 0.02693726122379303\n",
            "epoch: 794, train_error(A): 0.09562508016824722, test_error(B): 0.12301048636436462, B-A: 0.0273854061961174\n",
            "epoch: 796, train_error(A): 0.09541606903076172, test_error(B): 0.12557357549667358, B-A: 0.030157506465911865\n",
            "epoch: 798, train_error(A): 0.09524517506361008, test_error(B): 0.12963108718395233, B-A: 0.034385912120342255\n",
            "epoch: 800, train_error(A): 0.09524083137512207, test_error(B): 0.13341300189495087, B-A: 0.038172170519828796\n",
            "epoch: 802, train_error(A): 0.09530393779277802, test_error(B): 0.13584433495998383, B-A: 0.04054039716720581\n",
            "epoch: 804, train_error(A): 0.09531717747449875, test_error(B): 0.13674986362457275, B-A: 0.041432686150074005\n",
            "epoch: 806, train_error(A): 0.0952436551451683, test_error(B): 0.13616973161697388, B-A: 0.04092607647180557\n",
            "epoch: 808, train_error(A): 0.09512834995985031, test_error(B): 0.13441435992717743, B-A: 0.03928600996732712\n",
            "epoch: 810, train_error(A): 0.09504323452711105, test_error(B): 0.13220688700675964, B-A: 0.03716365247964859\n",
            "epoch: 812, train_error(A): 0.09500833600759506, test_error(B): 0.13020117580890656, B-A: 0.03519283980131149\n",
            "epoch: 814, train_error(A): 0.09500538557767868, test_error(B): 0.12853731215000153, B-A: 0.033531926572322845\n",
            "epoch: 816, train_error(A): 0.0950302705168724, test_error(B): 0.1269291341304779, B-A: 0.0318988636136055\n",
            "epoch: 818, train_error(A): 0.09511198848485947, test_error(B): 0.12494128197431564, B-A: 0.029829293489456177\n",
            "epoch: 820, train_error(A): 0.09530427306890488, test_error(B): 0.1223457008600235, B-A: 0.027041427791118622\n",
            "epoch: 822, train_error(A): 0.09555431455373764, test_error(B): 0.12003915011882782, B-A: 0.02448483556509018\n",
            "epoch: 824, train_error(A): 0.09541488438844681, test_error(B): 0.12113278359174728, B-A: 0.025717899203300476\n",
            "epoch: 826, train_error(A): 0.09486128389835358, test_error(B): 0.12796881794929504, B-A: 0.03310753405094147\n",
            "epoch: 828, train_error(A): 0.0948677659034729, test_error(B): 0.13631212711334229, B-A: 0.041444361209869385\n",
            "epoch: 830, train_error(A): 0.09507229924201965, test_error(B): 0.1397085189819336, B-A: 0.04463621973991394\n",
            "epoch: 832, train_error(A): 0.0948200449347496, test_error(B): 0.13615992665290833, B-A: 0.04133988171815872\n",
            "epoch: 834, train_error(A): 0.09468656778335571, test_error(B): 0.1295478790998459, B-A: 0.03486131131649017\n",
            "epoch: 836, train_error(A): 0.09481696784496307, test_error(B): 0.12564341723918915, B-A: 0.030826449394226074\n",
            "epoch: 838, train_error(A): 0.09473897516727448, test_error(B): 0.12666864693164825, B-A: 0.03192967176437378\n",
            "epoch: 840, train_error(A): 0.09458678960800171, test_error(B): 0.13100039958953857, B-A: 0.036413609981536865\n",
            "epoch: 842, train_error(A): 0.09460931271314621, test_error(B): 0.13510024547576904, B-A: 0.04049093276262283\n",
            "epoch: 844, train_error(A): 0.09464108198881149, test_error(B): 0.13665524125099182, B-A: 0.04201415926218033\n",
            "epoch: 846, train_error(A): 0.09456534683704376, test_error(B): 0.1355612874031067, B-A: 0.04099594056606293\n",
            "epoch: 848, train_error(A): 0.09447580575942993, test_error(B): 0.13305053114891052, B-A: 0.03857472538948059\n",
            "epoch: 850, train_error(A): 0.0944489985704422, test_error(B): 0.1305703967809677, B-A: 0.03612139821052551\n",
            "epoch: 852, train_error(A): 0.09445909410715103, test_error(B): 0.12886042892932892, B-A: 0.03440133482217789\n",
            "epoch: 854, train_error(A): 0.09446868300437927, test_error(B): 0.1279037594795227, B-A: 0.03343507647514343\n",
            "epoch: 856, train_error(A): 0.09446901082992554, test_error(B): 0.1273953765630722, B-A: 0.03292636573314667\n",
            "epoch: 858, train_error(A): 0.09446462988853455, test_error(B): 0.12704944610595703, B-A: 0.032584816217422485\n",
            "epoch: 860, train_error(A): 0.09446077793836594, test_error(B): 0.12669235467910767, B-A: 0.03223157674074173\n",
            "epoch: 862, train_error(A): 0.09445999562740326, test_error(B): 0.12627574801445007, B-A: 0.031815752387046814\n",
            "epoch: 864, train_error(A): 0.094459168612957, test_error(B): 0.12587866187095642, B-A: 0.03141949325799942\n",
            "epoch: 866, train_error(A): 0.09444508701562881, test_error(B): 0.12570464611053467, B-A: 0.03125955909490585\n",
            "epoch: 868, train_error(A): 0.09439820051193237, test_error(B): 0.12602034211158752, B-A: 0.03162214159965515\n",
            "epoch: 870, train_error(A): 0.0943124070763588, test_error(B): 0.12698890268802643, B-A: 0.03267649561166763\n",
            "epoch: 872, train_error(A): 0.09421248733997345, test_error(B): 0.1284891664981842, B-A: 0.034276679158210754\n",
            "epoch: 874, train_error(A): 0.0941326916217804, test_error(B): 0.13016115128993988, B-A: 0.036028459668159485\n",
            "epoch: 876, train_error(A): 0.09408415108919144, test_error(B): 0.13167321681976318, B-A: 0.03758906573057175\n",
            "epoch: 878, train_error(A): 0.09405748546123505, test_error(B): 0.13293473422527313, B-A: 0.038877248764038086\n",
            "epoch: 880, train_error(A): 0.09404446929693222, test_error(B): 0.13409781455993652, B-A: 0.0400533452630043\n",
            "epoch: 882, train_error(A): 0.09405162930488586, test_error(B): 0.13550390303134918, B-A: 0.04145227372646332\n",
            "epoch: 884, train_error(A): 0.09411843121051788, test_error(B): 0.13772286474704742, B-A: 0.04360443353652954\n",
            "epoch: 886, train_error(A): 0.09437138587236404, test_error(B): 0.14160627126693726, B-A: 0.04723488539457321\n",
            "epoch: 888, train_error(A): 0.09501469135284424, test_error(B): 0.14739100635051727, B-A: 0.052376314997673035\n",
            "epoch: 890, train_error(A): 0.09539277851581573, test_error(B): 0.15022997558116913, B-A: 0.054837197065353394\n",
            "epoch: 892, train_error(A): 0.09415025264024734, test_error(B): 0.14037641882896423, B-A: 0.04622616618871689\n",
            "epoch: 894, train_error(A): 0.09420217573642731, test_error(B): 0.1252472996711731, B-A: 0.03104512393474579\n",
            "epoch: 896, train_error(A): 0.09446350485086441, test_error(B): 0.12227502465248108, B-A: 0.02781151980161667\n",
            "epoch: 898, train_error(A): 0.0938183143734932, test_error(B): 0.13330836594104767, B-A: 0.039490051567554474\n",
            "epoch: 900, train_error(A): 0.09423157572746277, test_error(B): 0.141525536775589, B-A: 0.04729396104812622\n",
            "epoch: 902, train_error(A): 0.09382403641939163, test_error(B): 0.1357104480266571, B-A: 0.04188641160726547\n",
            "epoch: 904, train_error(A): 0.09395036101341248, test_error(B): 0.12667936086654663, B-A: 0.032728999853134155\n",
            "epoch: 906, train_error(A): 0.09387017041444778, test_error(B): 0.12770168483257294, B-A: 0.03383151441812515\n",
            "epoch: 908, train_error(A): 0.09373365342617035, test_error(B): 0.13562051951885223, B-A: 0.041886866092681885\n",
            "epoch: 910, train_error(A): 0.09384971857070923, test_error(B): 0.13888095319271088, B-A: 0.04503123462200165\n",
            "epoch: 912, train_error(A): 0.09365490823984146, test_error(B): 0.13440416753292084, B-A: 0.040749259293079376\n",
            "epoch: 914, train_error(A): 0.09370981156826019, test_error(B): 0.12927238643169403, B-A: 0.03556257486343384\n",
            "epoch: 916, train_error(A): 0.09367980808019638, test_error(B): 0.12928827106952667, B-A: 0.03560846298933029\n",
            "epoch: 918, train_error(A): 0.0935734212398529, test_error(B): 0.13320201635360718, B-A: 0.03962859511375427\n",
            "epoch: 920, train_error(A): 0.09361192584037781, test_error(B): 0.1363462656736374, B-A: 0.04273433983325958\n",
            "epoch: 922, train_error(A): 0.0935785323381424, test_error(B): 0.13615888357162476, B-A: 0.04258035123348236\n",
            "epoch: 924, train_error(A): 0.09350109100341797, test_error(B): 0.1336003541946411, B-A: 0.040099263191223145\n",
            "epoch: 926, train_error(A): 0.09349861741065979, test_error(B): 0.13112254440784454, B-A: 0.03762392699718475\n",
            "epoch: 928, train_error(A): 0.09349764883518219, test_error(B): 0.1302635669708252, B-A: 0.036765918135643005\n",
            "epoch: 930, train_error(A): 0.0934506431221962, test_error(B): 0.1310284435749054, B-A: 0.0375778004527092\n",
            "epoch: 932, train_error(A): 0.0934034213423729, test_error(B): 0.13257071375846863, B-A: 0.039167292416095734\n",
            "epoch: 934, train_error(A): 0.09338296949863434, test_error(B): 0.13403941690921783, B-A: 0.040656447410583496\n",
            "epoch: 936, train_error(A): 0.09337437152862549, test_error(B): 0.135019913315773, B-A: 0.04164554178714752\n",
            "epoch: 938, train_error(A): 0.09336140006780624, test_error(B): 0.13551649451255798, B-A: 0.04215509444475174\n",
            "epoch: 940, train_error(A): 0.09334190934896469, test_error(B): 0.13573232293128967, B-A: 0.04239041358232498\n",
            "epoch: 942, train_error(A): 0.0933208242058754, test_error(B): 0.13588948547840118, B-A: 0.04256866127252579\n",
            "epoch: 944, train_error(A): 0.09330403804779053, test_error(B): 0.13616502285003662, B-A: 0.042860984802246094\n",
            "epoch: 946, train_error(A): 0.09329910576343536, test_error(B): 0.13671542704105377, B-A: 0.04341632127761841\n",
            "epoch: 948, train_error(A): 0.09332083910703659, test_error(B): 0.1377357840538025, B-A: 0.0444149449467659\n",
            "epoch: 950, train_error(A): 0.09340047836303711, test_error(B): 0.13946884870529175, B-A: 0.04606837034225464\n",
            "epoch: 952, train_error(A): 0.09358654171228409, test_error(B): 0.14204704761505127, B-A: 0.04846050590276718\n",
            "epoch: 954, train_error(A): 0.09385544061660767, test_error(B): 0.14481119811534882, B-A: 0.05095575749874115\n",
            "epoch: 956, train_error(A): 0.09386667609214783, test_error(B): 0.14521118998527527, B-A: 0.05134451389312744\n",
            "epoch: 958, train_error(A): 0.09334897994995117, test_error(B): 0.140338733792305, B-A: 0.04698975384235382\n",
            "epoch: 960, train_error(A): 0.09307800233364105, test_error(B): 0.13224060833454132, B-A: 0.03916260600090027\n",
            "epoch: 962, train_error(A): 0.09332968294620514, test_error(B): 0.12647834420204163, B-A: 0.03314866125583649\n",
            "epoch: 964, train_error(A): 0.0933268666267395, test_error(B): 0.12622399628162384, B-A: 0.03289712965488434\n",
            "epoch: 966, train_error(A): 0.09303902834653854, test_error(B): 0.1308843195438385, B-A: 0.03784529119729996\n",
            "epoch: 968, train_error(A): 0.09303194284439087, test_error(B): 0.1364680826663971, B-A: 0.043436139822006226\n",
            "epoch: 970, train_error(A): 0.0931423008441925, test_error(B): 0.1391962766647339, B-A: 0.04605397582054138\n",
            "epoch: 972, train_error(A): 0.09305638074874878, test_error(B): 0.1382041871547699, B-A: 0.04514780640602112\n",
            "epoch: 974, train_error(A): 0.09291896224021912, test_error(B): 0.13498353958129883, B-A: 0.04206457734107971\n",
            "epoch: 976, train_error(A): 0.09290996938943863, test_error(B): 0.13172335922718048, B-A: 0.03881338983774185\n",
            "epoch: 978, train_error(A): 0.0929579883813858, test_error(B): 0.1297374963760376, B-A: 0.036779507994651794\n",
            "epoch: 980, train_error(A): 0.09295694530010223, test_error(B): 0.12923666834831238, B-A: 0.036279723048210144\n",
            "epoch: 982, train_error(A): 0.09290038049221039, test_error(B): 0.12984736263751984, B-A: 0.03694698214530945\n",
            "epoch: 984, train_error(A): 0.09283134341239929, test_error(B): 0.13101617991924286, B-A: 0.03818483650684357\n",
            "epoch: 986, train_error(A): 0.09277860820293427, test_error(B): 0.13225561380386353, B-A: 0.03947700560092926\n",
            "epoch: 988, train_error(A): 0.09274443984031677, test_error(B): 0.1332998275756836, B-A: 0.04055538773536682\n",
            "epoch: 990, train_error(A): 0.0927213802933693, test_error(B): 0.13412335515022278, B-A: 0.041401974856853485\n",
            "epoch: 992, train_error(A): 0.09270551800727844, test_error(B): 0.13489219546318054, B-A: 0.0421866774559021\n",
            "epoch: 994, train_error(A): 0.09270289540290833, test_error(B): 0.1359093338251114, B-A: 0.043206438422203064\n",
            "epoch: 996, train_error(A): 0.0927443727850914, test_error(B): 0.13767807185649872, B-A: 0.04493369907140732\n",
            "epoch: 998, train_error(A): 0.0929463803768158, test_error(B): 0.1410965472459793, B-A: 0.04815016686916351\n",
            "epoch: 1000, train_error(A): 0.09365600347518921, test_error(B): 0.14736753702163696, B-A: 0.053711533546447754\n",
            "epoch: 1002, train_error(A): 0.09491468966007233, test_error(B): 0.15455017983913422, B-A: 0.05963549017906189\n",
            "epoch: 1004, train_error(A): 0.09387204796075821, test_error(B): 0.14947360754013062, B-A: 0.055601559579372406\n",
            "epoch: 1006, train_error(A): 0.09270823746919632, test_error(B): 0.12923964858055115, B-A: 0.03653141111135483\n",
            "epoch: 1008, train_error(A): 0.09375692158937454, test_error(B): 0.12015783786773682, B-A: 0.026400916278362274\n",
            "epoch: 1010, train_error(A): 0.09252510219812393, test_error(B): 0.13388191163539886, B-A: 0.04135680943727493\n",
            "epoch: 1012, train_error(A): 0.09322024881839752, test_error(B): 0.14460629224777222, B-A: 0.051386043429374695\n",
            "epoch: 1014, train_error(A): 0.09249203652143478, test_error(B): 0.13452576100826263, B-A: 0.04203372448682785\n",
            "epoch: 1016, train_error(A): 0.09297117590904236, test_error(B): 0.12488485872745514, B-A: 0.03191368281841278\n",
            "epoch: 1018, train_error(A): 0.09244947880506516, test_error(B): 0.13285084068775177, B-A: 0.040401361882686615\n",
            "epoch: 1020, train_error(A): 0.09274383634328842, test_error(B): 0.14125344157218933, B-A: 0.04850960522890091\n",
            "epoch: 1022, train_error(A): 0.0924215018749237, test_error(B): 0.13591693341732025, B-A: 0.043495431542396545\n",
            "epoch: 1024, train_error(A): 0.09258478134870529, test_error(B): 0.12846294045448303, B-A: 0.03587815910577774\n",
            "epoch: 1026, train_error(A): 0.09240708500146866, test_error(B): 0.1313037872314453, B-A: 0.038896702229976654\n",
            "epoch: 1028, train_error(A): 0.09242549538612366, test_error(B): 0.13791649043560028, B-A: 0.045490995049476624\n",
            "epoch: 1030, train_error(A): 0.09240338951349258, test_error(B): 0.13772127032279968, B-A: 0.0453178808093071\n",
            "epoch: 1032, train_error(A): 0.09230060875415802, test_error(B): 0.1322837918996811, B-A: 0.03998318314552307\n",
            "epoch: 1034, train_error(A): 0.09236645698547363, test_error(B): 0.12974977493286133, B-A: 0.037383317947387695\n",
            "epoch: 1036, train_error(A): 0.09225402027368546, test_error(B): 0.13256634771823883, B-A: 0.040312327444553375\n",
            "epoch: 1038, train_error(A): 0.09226156026124954, test_error(B): 0.13628427684307098, B-A: 0.04402271658182144\n",
            "epoch: 1040, train_error(A): 0.09225470572710037, test_error(B): 0.1366775929927826, B-A: 0.04442288726568222\n",
            "epoch: 1042, train_error(A): 0.09218200296163559, test_error(B): 0.13414454460144043, B-A: 0.04196254163980484\n",
            "epoch: 1044, train_error(A): 0.09218556433916092, test_error(B): 0.13170255720615387, B-A: 0.03951699286699295\n",
            "epoch: 1046, train_error(A): 0.09217500686645508, test_error(B): 0.13131454586982727, B-A: 0.03913953900337219\n",
            "epoch: 1048, train_error(A): 0.0921231061220169, test_error(B): 0.1327131986618042, B-A: 0.04059009253978729\n",
            "epoch: 1050, train_error(A): 0.0921006053686142, test_error(B): 0.1344827115535736, B-A: 0.04238210618495941\n",
            "epoch: 1052, train_error(A): 0.09209664911031723, test_error(B): 0.13548852503299713, B-A: 0.0433918759226799\n",
            "epoch: 1054, train_error(A): 0.09207328408956528, test_error(B): 0.13542436063289642, B-A: 0.043351076543331146\n",
            "epoch: 1056, train_error(A): 0.0920376181602478, test_error(B): 0.1345977485179901, B-A: 0.04256013035774231\n",
            "epoch: 1058, train_error(A): 0.09201095998287201, test_error(B): 0.13353829085826874, B-A: 0.04152733087539673\n",
            "epoch: 1060, train_error(A): 0.09199512004852295, test_error(B): 0.13268190622329712, B-A: 0.04068678617477417\n",
            "epoch: 1062, train_error(A): 0.09198036789894104, test_error(B): 0.13221944868564606, B-A: 0.04023908078670502\n",
            "epoch: 1064, train_error(A): 0.0919610932469368, test_error(B): 0.13211765885353088, B-A: 0.040156565606594086\n",
            "epoch: 1066, train_error(A): 0.09193817526102066, test_error(B): 0.13222603499889374, B-A: 0.04028785973787308\n",
            "epoch: 1068, train_error(A): 0.0919143334031105, test_error(B): 0.13238783180713654, B-A: 0.04047349840402603\n",
            "epoch: 1070, train_error(A): 0.09189144521951675, test_error(B): 0.13250067830085754, B-A: 0.04060923308134079\n",
            "epoch: 1072, train_error(A): 0.09187038242816925, test_error(B): 0.13250423967838287, B-A: 0.04063385725021362\n",
            "epoch: 1074, train_error(A): 0.09185229241847992, test_error(B): 0.13233081996440887, B-A: 0.040478527545928955\n",
            "epoch: 1076, train_error(A): 0.09184075891971588, test_error(B): 0.13186833262443542, B-A: 0.04002757370471954\n",
            "epoch: 1078, train_error(A): 0.0918474867939949, test_error(B): 0.13092607259750366, B-A: 0.03907858580350876\n",
            "epoch: 1080, train_error(A): 0.09191087633371353, test_error(B): 0.12915955483913422, B-A: 0.037248678505420685\n",
            "epoch: 1082, train_error(A): 0.0921534076333046, test_error(B): 0.1259823739528656, B-A: 0.033828966319561005\n",
            "epoch: 1084, train_error(A): 0.09286434203386307, test_error(B): 0.12093716114759445, B-A: 0.028072819113731384\n",
            "epoch: 1086, train_error(A): 0.09391499310731888, test_error(B): 0.11622396111488342, B-A: 0.022308968007564545\n",
            "epoch: 1088, train_error(A): 0.09298230707645416, test_error(B): 0.12043453007936478, B-A: 0.027452223002910614\n",
            "epoch: 1090, train_error(A): 0.09172036498785019, test_error(B): 0.1358659863471985, B-A: 0.0441456213593483\n",
            "epoch: 1092, train_error(A): 0.09260892868041992, test_error(B): 0.1458783745765686, B-A: 0.05326944589614868\n",
            "epoch: 1094, train_error(A): 0.0918613150715828, test_error(B): 0.13907429575920105, B-A: 0.047212980687618256\n",
            "epoch: 1096, train_error(A): 0.09199980646371841, test_error(B): 0.12652301788330078, B-A: 0.03452321141958237\n",
            "epoch: 1098, train_error(A): 0.09200473129749298, test_error(B): 0.12641486525535583, B-A: 0.034410133957862854\n",
            "epoch: 1100, train_error(A): 0.09166688472032547, test_error(B): 0.1367429941892624, B-A: 0.04507610946893692\n",
            "epoch: 1102, train_error(A): 0.09194835275411606, test_error(B): 0.14126691222190857, B-A: 0.04931855946779251\n",
            "epoch: 1104, train_error(A): 0.09158588200807571, test_error(B): 0.1351443976163864, B-A: 0.0435585156083107\n",
            "epoch: 1106, train_error(A): 0.09175235033035278, test_error(B): 0.12843124568462372, B-A: 0.036678895354270935\n",
            "epoch: 1108, train_error(A): 0.09166186302900314, test_error(B): 0.1295011192560196, B-A: 0.03783925622701645\n",
            "epoch: 1110, train_error(A): 0.09153236448764801, test_error(B): 0.13537155091762543, B-A: 0.04383918642997742\n",
            "epoch: 1112, train_error(A): 0.09164543449878693, test_error(B): 0.13835938274860382, B-A: 0.046713948249816895\n",
            "epoch: 1114, train_error(A): 0.09151634573936462, test_error(B): 0.13592827320098877, B-A: 0.044411927461624146\n",
            "epoch: 1116, train_error(A): 0.09147778153419495, test_error(B): 0.1315976232290268, B-A: 0.04011984169483185\n",
            "epoch: 1118, train_error(A): 0.09153221547603607, test_error(B): 0.12965060770511627, B-A: 0.0381183922290802\n",
            "epoch: 1120, train_error(A): 0.09145356714725494, test_error(B): 0.1310865879058838, B-A: 0.039633020758628845\n",
            "epoch: 1122, train_error(A): 0.09140299260616302, test_error(B): 0.13396167755126953, B-A: 0.042558684945106506\n",
            "epoch: 1124, train_error(A): 0.091427743434906, test_error(B): 0.13596057891845703, B-A: 0.044532835483551025\n",
            "epoch: 1126, train_error(A): 0.09141496568918228, test_error(B): 0.13613811135292053, B-A: 0.04472314566373825\n",
            "epoch: 1128, train_error(A): 0.09136093407869339, test_error(B): 0.1348741054534912, B-A: 0.04351317137479782\n",
            "epoch: 1130, train_error(A): 0.09132665395736694, test_error(B): 0.1331363469362259, B-A: 0.04180969297885895\n",
            "epoch: 1132, train_error(A): 0.09132243692874908, test_error(B): 0.1317416876554489, B-A: 0.04041925072669983\n",
            "epoch: 1134, train_error(A): 0.09132146835327148, test_error(B): 0.13102179765701294, B-A: 0.039700329303741455\n",
            "epoch: 1136, train_error(A): 0.09130724519491196, test_error(B): 0.13090945780277252, B-A: 0.039602212607860565\n",
            "epoch: 1138, train_error(A): 0.09128149598836899, test_error(B): 0.13116353750228882, B-A: 0.03988204151391983\n",
            "epoch: 1140, train_error(A): 0.09125234186649323, test_error(B): 0.13156510889530182, B-A: 0.040312767028808594\n",
            "epoch: 1142, train_error(A): 0.09122544527053833, test_error(B): 0.13198785483837128, B-A: 0.04076240956783295\n",
            "epoch: 1144, train_error(A): 0.0912020355463028, test_error(B): 0.13236546516418457, B-A: 0.041163429617881775\n",
            "epoch: 1146, train_error(A): 0.09118124097585678, test_error(B): 0.1326490044593811, B-A: 0.04146776348352432\n",
            "epoch: 1148, train_error(A): 0.09116187691688538, test_error(B): 0.1328120082616806, B-A: 0.04165013134479523\n",
            "epoch: 1150, train_error(A): 0.09114320576190948, test_error(B): 0.13286596536636353, B-A: 0.04172275960445404\n",
            "epoch: 1152, train_error(A): 0.0911249965429306, test_error(B): 0.1328374445438385, B-A: 0.0417124480009079\n",
            "epoch: 1154, train_error(A): 0.09110745042562485, test_error(B): 0.1327141523361206, B-A: 0.04160670191049576\n",
            "epoch: 1156, train_error(A): 0.09109180420637131, test_error(B): 0.13241587579250336, B-A: 0.04132407158613205\n",
            "epoch: 1158, train_error(A): 0.09108296036720276, test_error(B): 0.13177865743637085, B-A: 0.04069569706916809\n",
            "epoch: 1160, train_error(A): 0.0911010205745697, test_error(B): 0.13047903776168823, B-A: 0.03937801718711853\n",
            "epoch: 1162, train_error(A): 0.09123323112726212, test_error(B): 0.12781395018100739, B-A: 0.03658071905374527\n",
            "epoch: 1164, train_error(A): 0.09184274077415466, test_error(B): 0.12246772646903992, B-A: 0.030624985694885254\n",
            "epoch: 1166, train_error(A): 0.09383979439735413, test_error(B): 0.11386722326278687, B-A: 0.02002742886543274\n",
            "epoch: 1168, train_error(A): 0.09494073688983917, test_error(B): 0.11081128567457199, B-A: 0.01587054878473282\n",
            "epoch: 1170, train_error(A): 0.0910632386803627, test_error(B): 0.1305772066116333, B-A: 0.0395139679312706\n",
            "epoch: 1172, train_error(A): 0.09265247732400894, test_error(B): 0.14938800036907196, B-A: 0.05673552304506302\n",
            "epoch: 1174, train_error(A): 0.09117263555526733, test_error(B): 0.1382875293493271, B-A: 0.04711489379405975\n",
            "epoch: 1176, train_error(A): 0.09220916777849197, test_error(B): 0.12046355754137039, B-A: 0.028254389762878418\n",
            "epoch: 1178, train_error(A): 0.0909852683544159, test_error(B): 0.13213343918323517, B-A: 0.041148170828819275\n",
            "epoch: 1180, train_error(A): 0.09167700260877609, test_error(B): 0.14440573751926422, B-A: 0.05272873491048813\n",
            "epoch: 1182, train_error(A): 0.09092986583709717, test_error(B): 0.13313400745391846, B-A: 0.04220414161682129\n",
            "epoch: 1184, train_error(A): 0.0914694294333458, test_error(B): 0.12469316273927689, B-A: 0.03322373330593109\n",
            "epoch: 1186, train_error(A): 0.09091583639383316, test_error(B): 0.1354639232158661, B-A: 0.04454808682203293\n",
            "epoch: 1188, train_error(A): 0.09120935946702957, test_error(B): 0.140783429145813, B-A: 0.04957406967878342\n",
            "epoch: 1190, train_error(A): 0.09087561815977097, test_error(B): 0.1317407190799713, B-A: 0.04086510092020035\n",
            "epoch: 1192, train_error(A): 0.09108640998601913, test_error(B): 0.12715186178684235, B-A: 0.03606545180082321\n",
            "epoch: 1194, train_error(A): 0.0908232182264328, test_error(B): 0.13392916321754456, B-A: 0.043105944991111755\n",
            "epoch: 1196, train_error(A): 0.09097089618444443, test_error(B): 0.13795071840286255, B-A: 0.04697982221841812\n",
            "epoch: 1198, train_error(A): 0.09078140556812286, test_error(B): 0.13309162855148315, B-A: 0.04231022298336029\n",
            "epoch: 1200, train_error(A): 0.09088652580976486, test_error(B): 0.128640815615654, B-A: 0.03775428980588913\n",
            "epoch: 1202, train_error(A): 0.09076452255249023, test_error(B): 0.13119731843471527, B-A: 0.04043279588222504\n",
            "epoch: 1204, train_error(A): 0.09078928828239441, test_error(B): 0.13551297783851624, B-A: 0.044723689556121826\n",
            "epoch: 1206, train_error(A): 0.090764619410038, test_error(B): 0.1353156864643097, B-A: 0.0445510670542717\n",
            "epoch: 1208, train_error(A): 0.09070928394794464, test_error(B): 0.13179205358028412, B-A: 0.04108276963233948\n",
            "epoch: 1210, train_error(A): 0.09074000269174576, test_error(B): 0.12995344400405884, B-A: 0.03921344131231308\n",
            "epoch: 1212, train_error(A): 0.09068036079406738, test_error(B): 0.13153783977031708, B-A: 0.040857478976249695\n",
            "epoch: 1214, train_error(A): 0.0906720906496048, test_error(B): 0.13402748107910156, B-A: 0.043355390429496765\n",
            "epoch: 1216, train_error(A): 0.09067029505968094, test_error(B): 0.13460935652256012, B-A: 0.04393906146287918\n",
            "epoch: 1218, train_error(A): 0.09062819182872772, test_error(B): 0.13307882845401764, B-A: 0.04245063662528992\n",
            "epoch: 1220, train_error(A): 0.09062173962593079, test_error(B): 0.13133087754249573, B-A: 0.04070913791656494\n",
            "epoch: 1222, train_error(A): 0.09061208367347717, test_error(B): 0.13102060556411743, B-A: 0.04040852189064026\n",
            "epoch: 1224, train_error(A): 0.0905817449092865, test_error(B): 0.13212892413139343, B-A: 0.041547179222106934\n",
            "epoch: 1226, train_error(A): 0.09056971222162247, test_error(B): 0.13342319428920746, B-A: 0.04285348206758499\n",
            "epoch: 1228, train_error(A): 0.09055957198143005, test_error(B): 0.13381914794445038, B-A: 0.043259575963020325\n",
            "epoch: 1230, train_error(A): 0.09053687006235123, test_error(B): 0.1332274079322815, B-A: 0.04269053786993027\n",
            "epoch: 1232, train_error(A): 0.09051991999149323, test_error(B): 0.13232970237731934, B-A: 0.04180978238582611\n",
            "epoch: 1234, train_error(A): 0.09050904959440231, test_error(B): 0.13182955980300903, B-A: 0.04132051020860672\n",
            "epoch: 1236, train_error(A): 0.09049266576766968, test_error(B): 0.13194605708122253, B-A: 0.041453391313552856\n",
            "epoch: 1238, train_error(A): 0.09047377109527588, test_error(B): 0.13244810700416565, B-A: 0.04197433590888977\n",
            "epoch: 1240, train_error(A): 0.0904587134718895, test_error(B): 0.13296595215797424, B-A: 0.04250723868608475\n",
            "epoch: 1242, train_error(A): 0.0904453843832016, test_error(B): 0.1332499235868454, B-A: 0.0428045392036438\n",
            "epoch: 1244, train_error(A): 0.09043009579181671, test_error(B): 0.133238285779953, B-A: 0.04280818998813629\n",
            "epoch: 1246, train_error(A): 0.09041325747966766, test_error(B): 0.13300569355487823, B-A: 0.04259243607521057\n",
            "epoch: 1248, train_error(A): 0.09039689600467682, test_error(B): 0.13268601894378662, B-A: 0.0422891229391098\n",
            "epoch: 1250, train_error(A): 0.0903816893696785, test_error(B): 0.13239914178848267, B-A: 0.04201745241880417\n",
            "epoch: 1252, train_error(A): 0.09036705642938614, test_error(B): 0.1322002112865448, B-A: 0.04183315485715866\n",
            "epoch: 1254, train_error(A): 0.09035242348909378, test_error(B): 0.13207873702049255, B-A: 0.04172631353139877\n",
            "epoch: 1256, train_error(A): 0.09033764153718948, test_error(B): 0.1319943219423294, B-A: 0.04165668040513992\n",
            "epoch: 1258, train_error(A): 0.09032289683818817, test_error(B): 0.13190902769565582, B-A: 0.04158613085746765\n",
            "epoch: 1260, train_error(A): 0.09030856937170029, test_error(B): 0.1317901462316513, B-A: 0.04148157685995102\n",
            "epoch: 1262, train_error(A): 0.09029544144868851, test_error(B): 0.1315920501947403, B-A: 0.04129660874605179\n",
            "epoch: 1264, train_error(A): 0.09028540551662445, test_error(B): 0.13124051690101624, B-A: 0.040955111384391785\n",
            "epoch: 1266, train_error(A): 0.0902838259935379, test_error(B): 0.13061490654945374, B-A: 0.04033108055591583\n",
            "epoch: 1268, train_error(A): 0.09030714631080627, test_error(B): 0.12950441241264343, B-A: 0.03919726610183716\n",
            "epoch: 1270, train_error(A): 0.09040793031454086, test_error(B): 0.12751689553260803, B-A: 0.03710896521806717\n",
            "epoch: 1272, train_error(A): 0.09074705094099045, test_error(B): 0.1240290030837059, B-A: 0.033281952142715454\n",
            "epoch: 1274, train_error(A): 0.09167174994945526, test_error(B): 0.1186828464269638, B-A: 0.027011096477508545\n",
            "epoch: 1276, train_error(A): 0.09287289530038834, test_error(B): 0.11416006833314896, B-A: 0.02128717303276062\n",
            "epoch: 1278, train_error(A): 0.09158901125192642, test_error(B): 0.1191999614238739, B-A: 0.02761095017194748\n",
            "epoch: 1280, train_error(A): 0.09021962434053421, test_error(B): 0.1349475383758545, B-A: 0.04472791403532028\n",
            "epoch: 1282, train_error(A): 0.09121479839086533, test_error(B): 0.14477524161338806, B-A: 0.053560443222522736\n",
            "epoch: 1284, train_error(A): 0.09037970006465912, test_error(B): 0.13825257122516632, B-A: 0.0478728711605072\n",
            "epoch: 1286, train_error(A): 0.09053614735603333, test_error(B): 0.12582553923130035, B-A: 0.03528939187526703\n",
            "epoch: 1288, train_error(A): 0.09058160334825516, test_error(B): 0.1253547966480255, B-A: 0.034773193299770355\n",
            "epoch: 1290, train_error(A): 0.0901598334312439, test_error(B): 0.1353948414325714, B-A: 0.045235008001327515\n",
            "epoch: 1292, train_error(A): 0.09050929546356201, test_error(B): 0.14044183492660522, B-A: 0.04993253946304321\n",
            "epoch: 1294, train_error(A): 0.09012521058320999, test_error(B): 0.1350639909505844, B-A: 0.04493878036737442\n",
            "epoch: 1296, train_error(A): 0.09025368839502335, test_error(B): 0.12774735689163208, B-A: 0.037493668496608734\n",
            "epoch: 1298, train_error(A): 0.09024747461080551, test_error(B): 0.12741923332214355, B-A: 0.03717175871133804\n",
            "epoch: 1300, train_error(A): 0.09004326164722443, test_error(B): 0.13282005488872528, B-A: 0.042776793241500854\n",
            "epoch: 1302, train_error(A): 0.09017565101385117, test_error(B): 0.13681063055992126, B-A: 0.0466349795460701\n",
            "epoch: 1304, train_error(A): 0.09009206295013428, test_error(B): 0.13560892641544342, B-A: 0.04551686346530914\n",
            "epoch: 1306, train_error(A): 0.09000195562839508, test_error(B): 0.13137966394424438, B-A: 0.041377708315849304\n",
            "epoch: 1308, train_error(A): 0.09007608145475388, test_error(B): 0.12856212258338928, B-A: 0.038486041128635406\n",
            "epoch: 1310, train_error(A): 0.09002986550331116, test_error(B): 0.1291714459657669, B-A: 0.03914158046245575\n",
            "epoch: 1312, train_error(A): 0.0899549350142479, test_error(B): 0.13190416991710663, B-A: 0.041949234902858734\n",
            "epoch: 1314, train_error(A): 0.08997585624456406, test_error(B): 0.13427519798278809, B-A: 0.04429934173822403\n",
            "epoch: 1316, train_error(A): 0.08998345583677292, test_error(B): 0.13483558595180511, B-A: 0.044852130115032196\n",
            "epoch: 1318, train_error(A): 0.089935801923275, test_error(B): 0.13374461233615875, B-A: 0.04380881041288376\n",
            "epoch: 1320, train_error(A): 0.089899443089962, test_error(B): 0.13202409446239471, B-A: 0.04212465137243271\n",
            "epoch: 1322, train_error(A): 0.08989893645048141, test_error(B): 0.13061365485191345, B-A: 0.04071471840143204\n",
            "epoch: 1324, train_error(A): 0.08990155160427094, test_error(B): 0.129947692155838, B-A: 0.04004614055156708\n",
            "epoch: 1326, train_error(A): 0.08988445997238159, test_error(B): 0.13003166019916534, B-A: 0.04014720022678375\n",
            "epoch: 1328, train_error(A): 0.08985587954521179, test_error(B): 0.13063853979110718, B-A: 0.040782660245895386\n",
            "epoch: 1330, train_error(A): 0.08983146399259567, test_error(B): 0.1314670741558075, B-A: 0.04163561016321182\n",
            "epoch: 1332, train_error(A): 0.08981656283140182, test_error(B): 0.13225291669368744, B-A: 0.042436353862285614\n",
            "epoch: 1334, train_error(A): 0.08980748057365417, test_error(B): 0.13284936547279358, B-A: 0.043041884899139404\n",
            "epoch: 1336, train_error(A): 0.08979950845241547, test_error(B): 0.13324584066867828, B-A: 0.04344633221626282\n",
            "epoch: 1338, train_error(A): 0.08979067951440811, test_error(B): 0.13351115584373474, B-A: 0.04372047632932663\n",
            "epoch: 1340, train_error(A): 0.08978160470724106, test_error(B): 0.1337268054485321, B-A: 0.043945200741291046\n",
            "epoch: 1342, train_error(A): 0.08977442979812622, test_error(B): 0.13396905362606049, B-A: 0.044194623827934265\n",
            "epoch: 1344, train_error(A): 0.08977296203374863, test_error(B): 0.13433654606342316, B-A: 0.04456358402967453\n",
            "epoch: 1346, train_error(A): 0.0897849053144455, test_error(B): 0.13496734201908112, B-A: 0.04518243670463562\n",
            "epoch: 1348, train_error(A): 0.08982762694358826, test_error(B): 0.13604263961315155, B-A: 0.04621501266956329\n",
            "epoch: 1350, train_error(A): 0.08994052559137344, test_error(B): 0.13779759407043457, B-A: 0.04785706847906113\n",
            "epoch: 1352, train_error(A): 0.09019815921783447, test_error(B): 0.14045825600624084, B-A: 0.05026009678840637\n",
            "epoch: 1354, train_error(A): 0.09065548330545425, test_error(B): 0.14381396770477295, B-A: 0.053158484399318695\n",
            "epoch: 1356, train_error(A): 0.09101907908916473, test_error(B): 0.14599864184856415, B-A: 0.054979562759399414\n",
            "epoch: 1358, train_error(A): 0.0905410572886467, test_error(B): 0.14327570796012878, B-A: 0.052734650671482086\n",
            "epoch: 1360, train_error(A): 0.08969912678003311, test_error(B): 0.13488653302192688, B-A: 0.04518740624189377\n",
            "epoch: 1362, train_error(A): 0.08986897021532059, test_error(B): 0.12625816464424133, B-A: 0.036389194428920746\n",
            "epoch: 1364, train_error(A): 0.09019337594509125, test_error(B): 0.1233857050538063, B-A: 0.03319232910871506\n",
            "epoch: 1366, train_error(A): 0.08976700156927109, test_error(B): 0.12755943834781647, B-A: 0.03779243677854538\n",
            "epoch: 1368, train_error(A): 0.08961772173643112, test_error(B): 0.13435393571853638, B-A: 0.044736213982105255\n",
            "epoch: 1370, train_error(A): 0.08985204994678497, test_error(B): 0.13828420639038086, B-A: 0.048432156443595886\n",
            "epoch: 1372, train_error(A): 0.08977839350700378, test_error(B): 0.13744182884693146, B-A: 0.04766343533992767\n",
            "epoch: 1374, train_error(A): 0.08956065028905869, test_error(B): 0.13334569334983826, B-A: 0.04378504306077957\n",
            "epoch: 1376, train_error(A): 0.08958683162927628, test_error(B): 0.12904973328113556, B-A: 0.03946290165185928\n",
            "epoch: 1378, train_error(A): 0.08968547731637955, test_error(B): 0.12689504027366638, B-A: 0.037209562957286835\n",
            "epoch: 1380, train_error(A): 0.08963105827569962, test_error(B): 0.1274396926164627, B-A: 0.03780863434076309\n",
            "epoch: 1382, train_error(A): 0.08951499313116074, test_error(B): 0.12975311279296875, B-A: 0.040238119661808014\n",
            "epoch: 1384, train_error(A): 0.08948051184415817, test_error(B): 0.1323358416557312, B-A: 0.04285532981157303\n",
            "epoch: 1386, train_error(A): 0.08951351046562195, test_error(B): 0.13415129482746124, B-A: 0.044637784361839294\n",
            "epoch: 1388, train_error(A): 0.08953937143087387, test_error(B): 0.1349717676639557, B-A: 0.04543239623308182\n",
            "epoch: 1390, train_error(A): 0.08952800184488297, test_error(B): 0.13500425219535828, B-A: 0.04547625035047531\n",
            "epoch: 1392, train_error(A): 0.08949203789234161, test_error(B): 0.13451889157295227, B-A: 0.04502685368061066\n",
            "epoch: 1394, train_error(A): 0.08945216983556747, test_error(B): 0.13379888236522675, B-A: 0.04434671252965927\n",
            "epoch: 1396, train_error(A): 0.08941979706287384, test_error(B): 0.1331266313791275, B-A: 0.04370683431625366\n",
            "epoch: 1398, train_error(A): 0.08939594030380249, test_error(B): 0.13266946375370026, B-A: 0.043273523449897766\n",
            "epoch: 1400, train_error(A): 0.0893779844045639, test_error(B): 0.1324300765991211, B-A: 0.04305209219455719\n",
            "epoch: 1402, train_error(A): 0.0893637165427208, test_error(B): 0.1323581337928772, B-A: 0.0429944172501564\n",
            "epoch: 1404, train_error(A): 0.08935288339853287, test_error(B): 0.1324750930070877, B-A: 0.04312220960855484\n",
            "epoch: 1406, train_error(A): 0.08934840559959412, test_error(B): 0.13288642466068268, B-A: 0.04353801906108856\n",
            "epoch: 1408, train_error(A): 0.08936072885990143, test_error(B): 0.1337479054927826, B-A: 0.044387176632881165\n",
            "epoch: 1410, train_error(A): 0.08942277729511261, test_error(B): 0.13533519208431244, B-A: 0.04591241478919983\n",
            "epoch: 1412, train_error(A): 0.08963453024625778, test_error(B): 0.13819155097007751, B-A: 0.04855702072381973\n",
            "epoch: 1414, train_error(A): 0.09024905413389206, test_error(B): 0.14305545389652252, B-A: 0.05280639976263046\n",
            "epoch: 1416, train_error(A): 0.09144051373004913, test_error(B): 0.14927826821804047, B-A: 0.05783775448799133\n",
            "epoch: 1418, train_error(A): 0.09164247661828995, test_error(B): 0.15028193593025208, B-A: 0.05863945931196213\n",
            "epoch: 1420, train_error(A): 0.08960109204053879, test_error(B): 0.13840912282466888, B-A: 0.048808030784130096\n",
            "epoch: 1422, train_error(A): 0.08986172080039978, test_error(B): 0.12259018421173096, B-A: 0.03272846341133118\n",
            "epoch: 1424, train_error(A): 0.0903257355093956, test_error(B): 0.11984926462173462, B-A: 0.02952352911233902\n",
            "epoch: 1426, train_error(A): 0.08923564106225967, test_error(B): 0.13216304779052734, B-A: 0.04292740672826767\n",
            "epoch: 1428, train_error(A): 0.0898718610405922, test_error(B): 0.1416519582271576, B-A: 0.0517800971865654\n",
            "epoch: 1430, train_error(A): 0.08938407152891159, test_error(B): 0.13681119680404663, B-A: 0.04742712527513504\n",
            "epoch: 1432, train_error(A): 0.08939896523952484, test_error(B): 0.1263790726661682, B-A: 0.03698010742664337\n",
            "epoch: 1434, train_error(A): 0.08956927806138992, test_error(B): 0.12432657927274704, B-A: 0.03475730121135712\n",
            "epoch: 1436, train_error(A): 0.08916836231946945, test_error(B): 0.13126955926418304, B-A: 0.04210119694471359\n",
            "epoch: 1438, train_error(A): 0.0893947184085846, test_error(B): 0.1369786113500595, B-A: 0.047583892941474915\n",
            "epoch: 1440, train_error(A): 0.0892704576253891, test_error(B): 0.1352158784866333, B-A: 0.0459454208612442\n",
            "epoch: 1442, train_error(A): 0.08914167433977127, test_error(B): 0.12938907742500305, B-A: 0.04024740308523178\n",
            "epoch: 1444, train_error(A): 0.08927955478429794, test_error(B): 0.1262378692626953, B-A: 0.03695831447839737\n",
            "epoch: 1446, train_error(A): 0.08915656805038452, test_error(B): 0.128164604306221, B-A: 0.03900803625583649\n",
            "epoch: 1448, train_error(A): 0.08909781277179718, test_error(B): 0.13219647109508514, B-A: 0.043098658323287964\n",
            "epoch: 1450, train_error(A): 0.08916813880205154, test_error(B): 0.1343895047903061, B-A: 0.04522136598825455\n",
            "epoch: 1452, train_error(A): 0.0891125351190567, test_error(B): 0.13345219194889069, B-A: 0.044339656829833984\n",
            "epoch: 1454, train_error(A): 0.08904629945755005, test_error(B): 0.1307544708251953, B-A: 0.041708171367645264\n",
            "epoch: 1456, train_error(A): 0.08907029032707214, test_error(B): 0.12846718728542328, B-A: 0.039396896958351135\n",
            "epoch: 1458, train_error(A): 0.0890786275267601, test_error(B): 0.1278441995382309, B-A: 0.038765572011470795\n",
            "epoch: 1460, train_error(A): 0.08903297036886215, test_error(B): 0.12879249453544617, B-A: 0.039759524166584015\n",
            "epoch: 1462, train_error(A): 0.08899594843387604, test_error(B): 0.13041017949581146, B-A: 0.041414231061935425\n",
            "epoch: 1464, train_error(A): 0.08899340778589249, test_error(B): 0.131779745221138, B-A: 0.042786337435245514\n",
            "epoch: 1466, train_error(A): 0.08899757266044617, test_error(B): 0.13245989382266998, B-A: 0.043462321162223816\n",
            "epoch: 1468, train_error(A): 0.08898533135652542, test_error(B): 0.1324613243341446, B-A: 0.04347599297761917\n",
            "epoch: 1470, train_error(A): 0.08896026015281677, test_error(B): 0.13198517262935638, B-A: 0.04302491247653961\n",
            "epoch: 1472, train_error(A): 0.08893611282110214, test_error(B): 0.13126792013645172, B-A: 0.04233180731534958\n",
            "epoch: 1474, train_error(A): 0.08891988545656204, test_error(B): 0.13053901493549347, B-A: 0.04161912947893143\n",
            "epoch: 1476, train_error(A): 0.08891009539365768, test_error(B): 0.12995532155036926, B-A: 0.04104522615671158\n",
            "epoch: 1478, train_error(A): 0.08890281617641449, test_error(B): 0.12954099476337433, B-A: 0.04063817858695984\n",
            "epoch: 1480, train_error(A): 0.088895782828331, test_error(B): 0.12922140955924988, B-A: 0.040325626730918884\n",
            "epoch: 1482, train_error(A): 0.08888904750347137, test_error(B): 0.1289120763540268, B-A: 0.04002302885055542\n",
            "epoch: 1484, train_error(A): 0.08888458460569382, test_error(B): 0.1285533756017685, B-A: 0.039668790996074677\n",
            "epoch: 1486, train_error(A): 0.08888647705316544, test_error(B): 0.12807005643844604, B-A: 0.03918357938528061\n",
            "epoch: 1488, train_error(A): 0.08890316635370255, test_error(B): 0.12733420729637146, B-A: 0.038431040942668915\n",
            "epoch: 1490, train_error(A): 0.08895354717969894, test_error(B): 0.1261727213859558, B-A: 0.037219174206256866\n",
            "epoch: 1492, train_error(A): 0.08908029645681381, test_error(B): 0.12438075989484787, B-A: 0.03530046343803406\n",
            "epoch: 1494, train_error(A): 0.0893656387925148, test_error(B): 0.12178010493516922, B-A: 0.03241446614265442\n",
            "epoch: 1496, train_error(A): 0.08987915515899658, test_error(B): 0.1185934990644455, B-A: 0.028714343905448914\n",
            "epoch: 1498, train_error(A): 0.09034741669893265, test_error(B): 0.11637584120035172, B-A: 0.026028424501419067\n",
            "epoch: 1500, train_error(A): 0.08991710841655731, test_error(B): 0.11839266121387482, B-A: 0.028475552797317505\n",
            "epoch: 1502, train_error(A): 0.08891060948371887, test_error(B): 0.1259496957063675, B-A: 0.03703908622264862\n",
            "epoch: 1504, train_error(A): 0.08888690173625946, test_error(B): 0.13478286564350128, B-A: 0.04589596390724182\n",
            "epoch: 1506, train_error(A): 0.08929265290498734, test_error(B): 0.1393943428993225, B-A: 0.050101689994335175\n",
            "epoch: 1508, train_error(A): 0.08902589231729507, test_error(B): 0.13722676038742065, B-A: 0.04820086807012558\n",
            "epoch: 1510, train_error(A): 0.08871279656887054, test_error(B): 0.1306324303150177, B-A: 0.041919633746147156\n",
            "epoch: 1512, train_error(A): 0.08891720324754715, test_error(B): 0.12507617473602295, B-A: 0.0361589714884758\n",
            "epoch: 1514, train_error(A): 0.08898939192295074, test_error(B): 0.1240091621875763, B-A: 0.03501977026462555\n",
            "epoch: 1516, train_error(A): 0.08875469118356705, test_error(B): 0.127086341381073, B-A: 0.03833165019750595\n",
            "epoch: 1518, train_error(A): 0.08867508918046951, test_error(B): 0.13141793012619019, B-A: 0.04274284094572067\n",
            "epoch: 1520, train_error(A): 0.08877953886985779, test_error(B): 0.13425441086292267, B-A: 0.04547487199306488\n",
            "epoch: 1522, train_error(A): 0.0887971967458725, test_error(B): 0.13468095660209656, B-A: 0.04588375985622406\n",
            "epoch: 1524, train_error(A): 0.08869411051273346, test_error(B): 0.13311348855495453, B-A: 0.04441937804222107\n",
            "epoch: 1526, train_error(A): 0.08861688524484634, test_error(B): 0.13056150078773499, B-A: 0.04194461554288864\n",
            "epoch: 1528, train_error(A): 0.088625468313694, test_error(B): 0.12818309664726257, B-A: 0.03955762833356857\n",
            "epoch: 1530, train_error(A): 0.08866474032402039, test_error(B): 0.12670812010765076, B-A: 0.03804337978363037\n",
            "epoch: 1532, train_error(A): 0.08868043124675751, test_error(B): 0.12618985772132874, B-A: 0.03750942647457123\n",
            "epoch: 1534, train_error(A): 0.08866425603628159, test_error(B): 0.12627357244491577, B-A: 0.037609316408634186\n",
            "epoch: 1536, train_error(A): 0.08863166719675064, test_error(B): 0.1266002506017685, B-A: 0.03796858340501785\n",
            "epoch: 1538, train_error(A): 0.08859970420598984, test_error(B): 0.12698949873447418, B-A: 0.038389794528484344\n",
            "epoch: 1540, train_error(A): 0.08857505768537521, test_error(B): 0.12733198702335358, B-A: 0.03875692933797836\n",
            "epoch: 1542, train_error(A): 0.08855877071619034, test_error(B): 0.12748143076896667, B-A: 0.03892266005277634\n",
            "epoch: 1544, train_error(A): 0.08855117857456207, test_error(B): 0.12732264399528503, B-A: 0.03877146542072296\n",
            "epoch: 1546, train_error(A): 0.08855681121349335, test_error(B): 0.12683174014091492, B-A: 0.03827492892742157\n",
            "epoch: 1548, train_error(A): 0.08858869969844818, test_error(B): 0.12595580518245697, B-A: 0.03736710548400879\n",
            "epoch: 1550, train_error(A): 0.08867903798818588, test_error(B): 0.1244949996471405, B-A: 0.03581596165895462\n",
            "epoch: 1552, train_error(A): 0.08889812231063843, test_error(B): 0.12217771261930466, B-A: 0.03327959030866623\n",
            "epoch: 1554, train_error(A): 0.08935776352882385, test_error(B): 0.11894352734088898, B-A: 0.029585763812065125\n",
            "epoch: 1556, train_error(A): 0.0900200828909874, test_error(B): 0.11566263437271118, B-A: 0.025642551481723785\n",
            "epoch: 1558, train_error(A): 0.0901249572634697, test_error(B): 0.11525581777095795, B-A: 0.02513086050748825\n",
            "epoch: 1560, train_error(A): 0.08901899307966232, test_error(B): 0.12109284847974777, B-A: 0.03207385540008545\n",
            "epoch: 1562, train_error(A): 0.08842995762825012, test_error(B): 0.1310013383626938, B-A: 0.042571380734443665\n",
            "epoch: 1564, train_error(A): 0.08893318474292755, test_error(B): 0.13838525116443634, B-A: 0.04945206642150879\n",
            "epoch: 1566, train_error(A): 0.08890455961227417, test_error(B): 0.13851498067378998, B-A: 0.04961042106151581\n",
            "epoch: 1568, train_error(A): 0.08841446787118912, test_error(B): 0.1320122629404068, B-A: 0.04359779506921768\n",
            "epoch: 1570, train_error(A): 0.08855772018432617, test_error(B): 0.12496142089366913, B-A: 0.03640370070934296\n",
            "epoch: 1572, train_error(A): 0.08872528374195099, test_error(B): 0.12277404218912125, B-A: 0.03404875844717026\n",
            "epoch: 1574, train_error(A): 0.08845477551221848, test_error(B): 0.12597545981407166, B-A: 0.03752068430185318\n",
            "epoch: 1576, train_error(A): 0.08835861831903458, test_error(B): 0.131092831492424, B-A: 0.042734213173389435\n",
            "epoch: 1578, train_error(A): 0.08849402517080307, test_error(B): 0.13423816859722137, B-A: 0.045744143426418304\n",
            "epoch: 1580, train_error(A): 0.0884770080447197, test_error(B): 0.13405150175094604, B-A: 0.04557449370622635\n",
            "epoch: 1582, train_error(A): 0.08833836019039154, test_error(B): 0.13148480653762817, B-A: 0.04314644634723663\n",
            "epoch: 1584, train_error(A): 0.0883033499121666, test_error(B): 0.128333181142807, B-A: 0.04002983123064041\n",
            "epoch: 1586, train_error(A): 0.08835908770561218, test_error(B): 0.12610797584056854, B-A: 0.03774888813495636\n",
            "epoch: 1588, train_error(A): 0.08837690204381943, test_error(B): 0.12544375658035278, B-A: 0.037066854536533356\n",
            "epoch: 1590, train_error(A): 0.08832980692386627, test_error(B): 0.12611860036849976, B-A: 0.037788793444633484\n",
            "epoch: 1592, train_error(A): 0.08827079087495804, test_error(B): 0.12746019661426544, B-A: 0.039189405739307404\n",
            "epoch: 1594, train_error(A): 0.08823853731155396, test_error(B): 0.12884899973869324, B-A: 0.04061046242713928\n",
            "epoch: 1596, train_error(A): 0.08823369443416595, test_error(B): 0.1300220787525177, B-A: 0.041788384318351746\n",
            "epoch: 1598, train_error(A): 0.08824226260185242, test_error(B): 0.13098230957984924, B-A: 0.042740046977996826\n",
            "epoch: 1600, train_error(A): 0.08825643360614777, test_error(B): 0.13177350163459778, B-A: 0.04351706802845001\n",
            "epoch: 1602, train_error(A): 0.08827706426382065, test_error(B): 0.13247637450695038, B-A: 0.04419931024312973\n",
            "epoch: 1604, train_error(A): 0.08831314742565155, test_error(B): 0.13329020142555237, B-A: 0.04497705399990082\n",
            "epoch: 1606, train_error(A): 0.08838148415088654, test_error(B): 0.13444207608699799, B-A: 0.04606059193611145\n",
            "epoch: 1608, train_error(A): 0.08850517123937607, test_error(B): 0.1360253244638443, B-A: 0.04752015322446823\n",
            "epoch: 1610, train_error(A): 0.08869954943656921, test_error(B): 0.13792634010314941, B-A: 0.0492267906665802\n",
            "epoch: 1612, train_error(A): 0.08892259001731873, test_error(B): 0.13970142602920532, B-A: 0.0507788360118866\n",
            "epoch: 1614, train_error(A): 0.0889991968870163, test_error(B): 0.14031586050987244, B-A: 0.05131666362285614\n",
            "epoch: 1616, train_error(A): 0.08872504532337189, test_error(B): 0.13842953741550446, B-A: 0.04970449209213257\n",
            "epoch: 1618, train_error(A): 0.08827264606952667, test_error(B): 0.1338600218296051, B-A: 0.04558737576007843\n",
            "epoch: 1620, train_error(A): 0.08810614049434662, test_error(B): 0.12840710580348969, B-A: 0.040300965309143066\n",
            "epoch: 1622, train_error(A): 0.08826665580272675, test_error(B): 0.12432821840047836, B-A: 0.03606156259775162\n",
            "epoch: 1624, train_error(A): 0.0883929654955864, test_error(B): 0.12278716266155243, B-A: 0.034394197165966034\n",
            "epoch: 1626, train_error(A): 0.08829133957624435, test_error(B): 0.12375158071517944, B-A: 0.03546024113893509\n",
            "epoch: 1628, train_error(A): 0.08811413496732712, test_error(B): 0.12632295489311218, B-A: 0.038208819925785065\n",
            "epoch: 1630, train_error(A): 0.08805100619792938, test_error(B): 0.1292830854654312, B-A: 0.04123207926750183\n",
            "epoch: 1632, train_error(A): 0.08809679746627808, test_error(B): 0.13170483708381653, B-A: 0.04360803961753845\n",
            "epoch: 1634, train_error(A): 0.0881558209657669, test_error(B): 0.13310793042182922, B-A: 0.04495210945606232\n",
            "epoch: 1636, train_error(A): 0.08816960453987122, test_error(B): 0.13345427811145782, B-A: 0.04528467357158661\n",
            "epoch: 1638, train_error(A): 0.08813916891813278, test_error(B): 0.1330685168504715, B-A: 0.044929347932338715\n",
            "epoch: 1640, train_error(A): 0.0880902111530304, test_error(B): 0.13235513865947723, B-A: 0.04426492750644684\n",
            "epoch: 1642, train_error(A): 0.08804389089345932, test_error(B): 0.13156746327877045, B-A: 0.04352357238531113\n",
            "epoch: 1644, train_error(A): 0.08800879120826721, test_error(B): 0.13084791600704193, B-A: 0.04283912479877472\n",
            "epoch: 1646, train_error(A): 0.08798490464687347, test_error(B): 0.13032817840576172, B-A: 0.042343273758888245\n",
            "epoch: 1648, train_error(A): 0.08796924352645874, test_error(B): 0.13010117411613464, B-A: 0.0421319305896759\n",
            "epoch: 1650, train_error(A): 0.08796016871929169, test_error(B): 0.1301778256893158, B-A: 0.04221765697002411\n",
            "epoch: 1652, train_error(A): 0.08796004951000214, test_error(B): 0.13056769967079163, B-A: 0.04260765016078949\n",
            "epoch: 1654, train_error(A): 0.0879802405834198, test_error(B): 0.1314128190279007, B-A: 0.043432578444480896\n",
            "epoch: 1656, train_error(A): 0.08805660158395767, test_error(B): 0.13304728269577026, B-A: 0.04499068111181259\n",
            "epoch: 1658, train_error(A): 0.08829295635223389, test_error(B): 0.1360071450471878, B-A: 0.04771418869495392\n",
            "epoch: 1660, train_error(A): 0.0889372006058693, test_error(B): 0.14092202484607697, B-A: 0.05198482424020767\n",
            "epoch: 1662, train_error(A): 0.09018605947494507, test_error(B): 0.14727680385112762, B-A: 0.057090744376182556\n",
            "epoch: 1664, train_error(A): 0.09068770706653595, test_error(B): 0.14942748844623566, B-A: 0.05873978137969971\n",
            "epoch: 1666, train_error(A): 0.08861790597438812, test_error(B): 0.13902150094509125, B-A: 0.050403594970703125\n",
            "epoch: 1668, train_error(A): 0.0882018581032753, test_error(B): 0.12203796952962875, B-A: 0.033836111426353455\n",
            "epoch: 1670, train_error(A): 0.08924724906682968, test_error(B): 0.11547074466943741, B-A: 0.026223495602607727\n",
            "epoch: 1672, train_error(A): 0.08796530961990356, test_error(B): 0.12557220458984375, B-A: 0.037606894969940186\n",
            "epoch: 1674, train_error(A): 0.08836741000413895, test_error(B): 0.13806606829166412, B-A: 0.04969865828752518\n",
            "epoch: 1676, train_error(A): 0.08829466253519058, test_error(B): 0.13724438846111298, B-A: 0.048949725925922394\n",
            "epoch: 1678, train_error(A): 0.08787323534488678, test_error(B): 0.12657225131988525, B-A: 0.038699015974998474\n",
            "epoch: 1680, train_error(A): 0.08829851448535919, test_error(B): 0.12080268561840057, B-A: 0.03250417113304138\n",
            "epoch: 1682, train_error(A): 0.08788333088159561, test_error(B): 0.12562884390354156, B-A: 0.03774551302194595\n",
            "epoch: 1684, train_error(A): 0.08794509619474411, test_error(B): 0.1330859512090683, B-A: 0.04514085501432419\n",
            "epoch: 1686, train_error(A): 0.0880230963230133, test_error(B): 0.13420027494430542, B-A: 0.046177178621292114\n",
            "epoch: 1688, train_error(A): 0.08777842670679092, test_error(B): 0.12909789383411407, B-A: 0.04131946712732315\n",
            "epoch: 1690, train_error(A): 0.08789483457803726, test_error(B): 0.1242414265871048, B-A: 0.036346592009067535\n",
            "epoch: 1692, train_error(A): 0.08787804841995239, test_error(B): 0.12420960515737534, B-A: 0.03633155673742294\n",
            "epoch: 1694, train_error(A): 0.08774369955062866, test_error(B): 0.12785816192626953, B-A: 0.04011446237564087\n",
            "epoch: 1696, train_error(A): 0.08780322223901749, test_error(B): 0.13117028772830963, B-A: 0.043367065489292145\n",
            "epoch: 1698, train_error(A): 0.0878114402294159, test_error(B): 0.1315554827451706, B-A: 0.0437440425157547\n",
            "epoch: 1700, train_error(A): 0.0877254381775856, test_error(B): 0.1293293833732605, B-A: 0.041603945195674896\n",
            "epoch: 1702, train_error(A): 0.0877159908413887, test_error(B): 0.12660054862499237, B-A: 0.03888455778360367\n",
            "epoch: 1704, train_error(A): 0.08774882555007935, test_error(B): 0.1251985877752304, B-A: 0.03744976222515106\n",
            "epoch: 1706, train_error(A): 0.08772756904363632, test_error(B): 0.12556512653827667, B-A: 0.03783755749464035\n",
            "epoch: 1708, train_error(A): 0.08768130093812943, test_error(B): 0.12702570855617523, B-A: 0.03934440761804581\n",
            "epoch: 1710, train_error(A): 0.08766729384660721, test_error(B): 0.12860330939292908, B-A: 0.04093601554632187\n",
            "epoch: 1712, train_error(A): 0.087676040828228, test_error(B): 0.1296442598104477, B-A: 0.041968218982219696\n",
            "epoch: 1714, train_error(A): 0.08767238259315491, test_error(B): 0.12990714609622955, B-A: 0.042234763503074646\n",
            "epoch: 1716, train_error(A): 0.08765067160129547, test_error(B): 0.12944243848323822, B-A: 0.04179176688194275\n",
            "epoch: 1718, train_error(A): 0.08762826770544052, test_error(B): 0.12855692207813263, B-A: 0.04092865437269211\n",
            "epoch: 1720, train_error(A): 0.08761691302061081, test_error(B): 0.12766686081886292, B-A: 0.040049947798252106\n",
            "epoch: 1722, train_error(A): 0.0876130536198616, test_error(B): 0.12704026699066162, B-A: 0.03942721337080002\n",
            "epoch: 1724, train_error(A): 0.087608702480793, test_error(B): 0.1267145425081253, B-A: 0.039105840027332306\n",
            "epoch: 1726, train_error(A): 0.08759989589452744, test_error(B): 0.12662464380264282, B-A: 0.03902474790811539\n",
            "epoch: 1728, train_error(A): 0.08758772164583206, test_error(B): 0.12671567499637604, B-A: 0.039127953350543976\n",
            "epoch: 1730, train_error(A): 0.0875745564699173, test_error(B): 0.12692791223526, B-A: 0.03935335576534271\n",
            "epoch: 1732, train_error(A): 0.08756204694509506, test_error(B): 0.1271689236164093, B-A: 0.03960687667131424\n",
            "epoch: 1734, train_error(A): 0.08755060285329819, test_error(B): 0.1273641437292099, B-A: 0.03981354087591171\n",
            "epoch: 1736, train_error(A): 0.08754005283117294, test_error(B): 0.12750546634197235, B-A: 0.03996541351079941\n",
            "epoch: 1738, train_error(A): 0.08753003925085068, test_error(B): 0.1276121586561203, B-A: 0.04008211940526962\n",
            "epoch: 1740, train_error(A): 0.0875203087925911, test_error(B): 0.12768316268920898, B-A: 0.04016285389661789\n",
            "epoch: 1742, train_error(A): 0.08751068264245987, test_error(B): 0.12771233916282654, B-A: 0.04020165652036667\n",
            "epoch: 1744, train_error(A): 0.08750110864639282, test_error(B): 0.1277196854352951, B-A: 0.04021857678890228\n",
            "epoch: 1746, train_error(A): 0.08749155700206757, test_error(B): 0.12773247063159943, B-A: 0.04024091362953186\n",
            "epoch: 1748, train_error(A): 0.08748199790716171, test_error(B): 0.12775173783302307, B-A: 0.04026973992586136\n",
            "epoch: 1750, train_error(A): 0.08747246861457825, test_error(B): 0.12776683270931244, B-A: 0.04029436409473419\n",
            "epoch: 1752, train_error(A): 0.08746293932199478, test_error(B): 0.1277860850095749, B-A: 0.04032314568758011\n",
            "epoch: 1754, train_error(A): 0.08745349943637848, test_error(B): 0.1278345137834549, B-A: 0.040381014347076416\n",
            "epoch: 1756, train_error(A): 0.08744428306818008, test_error(B): 0.12793777883052826, B-A: 0.040493495762348175\n",
            "epoch: 1758, train_error(A): 0.08743587881326675, test_error(B): 0.1281416267156601, B-A: 0.04070574790239334\n",
            "epoch: 1760, train_error(A): 0.08743064850568771, test_error(B): 0.12856130301952362, B-A: 0.04113065451383591\n",
            "epoch: 1762, train_error(A): 0.08743847906589508, test_error(B): 0.12944844365119934, B-A: 0.04200996458530426\n",
            "epoch: 1764, train_error(A): 0.08750263601541519, test_error(B): 0.13134115934371948, B-A: 0.04383852332830429\n",
            "epoch: 1766, train_error(A): 0.08781508356332779, test_error(B): 0.13541916012763977, B-A: 0.04760407656431198\n",
            "epoch: 1768, train_error(A): 0.08913207054138184, test_error(B): 0.14391441643238068, B-A: 0.05478234589099884\n",
            "epoch: 1770, train_error(A): 0.09265999495983124, test_error(B): 0.15710869431495667, B-A: 0.06444869935512543\n",
            "epoch: 1772, train_error(A): 0.09237771481275558, test_error(B): 0.15644225478172302, B-A: 0.06406453996896744\n",
            "epoch: 1774, train_error(A): 0.08745478093624115, test_error(B): 0.1261809766292572, B-A: 0.03872619569301605\n",
            "epoch: 1776, train_error(A): 0.09122850745916367, test_error(B): 0.10600200295448303, B-A: 0.014773495495319366\n",
            "epoch: 1778, train_error(A): 0.08747635781764984, test_error(B): 0.13003632426261902, B-A: 0.04255996644496918\n",
            "epoch: 1780, train_error(A): 0.08914870023727417, test_error(B): 0.1453513503074646, B-A: 0.05620265007019043\n",
            "epoch: 1782, train_error(A): 0.08761733770370483, test_error(B): 0.12457981705665588, B-A: 0.03696247935295105\n",
            "epoch: 1784, train_error(A): 0.08845221996307373, test_error(B): 0.11722373962402344, B-A: 0.028771519660949707\n",
            "epoch: 1786, train_error(A): 0.08786953240633011, test_error(B): 0.13688862323760986, B-A: 0.049019090831279755\n",
            "epoch: 1788, train_error(A): 0.08776052296161652, test_error(B): 0.13595542311668396, B-A: 0.048194900155067444\n",
            "epoch: 1790, train_error(A): 0.08796460181474686, test_error(B): 0.11958608031272888, B-A: 0.031621478497982025\n",
            "epoch: 1792, train_error(A): 0.08744163811206818, test_error(B): 0.12480717897415161, B-A: 0.037365540862083435\n",
            "epoch: 1794, train_error(A): 0.08778157085180283, test_error(B): 0.1357567459344864, B-A: 0.04797517508268356\n",
            "epoch: 1796, train_error(A): 0.08734502643346786, test_error(B): 0.12940596044063568, B-A: 0.042060934007167816\n",
            "epoch: 1798, train_error(A): 0.08765644580125809, test_error(B): 0.1210981160402298, B-A: 0.03344167023897171\n",
            "epoch: 1800, train_error(A): 0.08730324357748032, test_error(B): 0.1271338015794754, B-A: 0.03983055800199509\n",
            "epoch: 1802, train_error(A): 0.08751267194747925, test_error(B): 0.1330847591161728, B-A: 0.04557208716869354\n",
            "epoch: 1804, train_error(A): 0.08728497475385666, test_error(B): 0.12821468710899353, B-A: 0.04092971235513687\n",
            "epoch: 1806, train_error(A): 0.08741874247789383, test_error(B): 0.12256211787462234, B-A: 0.035143375396728516\n",
            "epoch: 1808, train_error(A): 0.08728010952472687, test_error(B): 0.12525998055934906, B-A: 0.03797987103462219\n",
            "epoch: 1810, train_error(A): 0.0873233750462532, test_error(B): 0.13022947311401367, B-A: 0.04290609806776047\n",
            "epoch: 1812, train_error(A): 0.08728963881731033, test_error(B): 0.12963107228279114, B-A: 0.042341433465480804\n",
            "epoch: 1814, train_error(A): 0.087248794734478, test_error(B): 0.12550397217273712, B-A: 0.038255177438259125\n",
            "epoch: 1816, train_error(A): 0.0872827023267746, test_error(B): 0.12429753690958023, B-A: 0.037014834582805634\n",
            "epoch: 1818, train_error(A): 0.08721300959587097, test_error(B): 0.1270807534456253, B-A: 0.039867743849754333\n",
            "epoch: 1820, train_error(A): 0.08724340796470642, test_error(B): 0.12941874563694, B-A: 0.04217533767223358\n",
            "epoch: 1822, train_error(A): 0.08720796555280685, test_error(B): 0.12841835618019104, B-A: 0.041210390627384186\n",
            "epoch: 1824, train_error(A): 0.08719802647829056, test_error(B): 0.12600161135196686, B-A: 0.0388035848736763\n",
            "epoch: 1826, train_error(A): 0.08720064908266068, test_error(B): 0.125484436750412, B-A: 0.03828378766775131\n",
            "epoch: 1828, train_error(A): 0.0871708020567894, test_error(B): 0.12716363370418549, B-A: 0.03999283164739609\n",
            "epoch: 1830, train_error(A): 0.0871761217713356, test_error(B): 0.1285976618528366, B-A: 0.04142154008150101\n",
            "epoch: 1832, train_error(A): 0.08715957403182983, test_error(B): 0.12812268733978271, B-A: 0.04096311330795288\n",
            "epoch: 1834, train_error(A): 0.08714760839939117, test_error(B): 0.1266363114118576, B-A: 0.03948870301246643\n",
            "epoch: 1836, train_error(A): 0.08714591711759567, test_error(B): 0.1260083168745041, B-A: 0.03886239975690842\n",
            "epoch: 1838, train_error(A): 0.08712957054376602, test_error(B): 0.1267428696155548, B-A: 0.03961329907178879\n",
            "epoch: 1840, train_error(A): 0.08712352067232132, test_error(B): 0.12773869931697845, B-A: 0.040615178644657135\n",
            "epoch: 1842, train_error(A): 0.08711647242307663, test_error(B): 0.12785229086875916, B-A: 0.040735818445682526\n",
            "epoch: 1844, train_error(A): 0.08710399270057678, test_error(B): 0.12712453305721283, B-A: 0.04002054035663605\n",
            "epoch: 1846, train_error(A): 0.08709807693958282, test_error(B): 0.12645454704761505, B-A: 0.03935647010803223\n",
            "epoch: 1848, train_error(A): 0.08708968758583069, test_error(B): 0.1264694631099701, B-A: 0.039379775524139404\n",
            "epoch: 1850, train_error(A): 0.08707938343286514, test_error(B): 0.12698207795619965, B-A: 0.0399026945233345\n",
            "epoch: 1852, train_error(A): 0.08707253634929657, test_error(B): 0.12739382684230804, B-A: 0.040321290493011475\n",
            "epoch: 1854, train_error(A): 0.08706426620483398, test_error(B): 0.12735480070114136, B-A: 0.04029053449630737\n",
            "epoch: 1856, train_error(A): 0.08705485612154007, test_error(B): 0.12699007987976074, B-A: 0.03993522375822067\n",
            "epoch: 1858, train_error(A): 0.0870472714304924, test_error(B): 0.12665608525276184, B-A: 0.03960881382226944\n",
            "epoch: 1860, train_error(A): 0.08703936636447906, test_error(B): 0.12659993767738342, B-A: 0.03956057131290436\n",
            "epoch: 1862, train_error(A): 0.08703049272298813, test_error(B): 0.12680691480636597, B-A: 0.03977642208337784\n",
            "epoch: 1864, train_error(A): 0.08702237904071808, test_error(B): 0.12707383930683136, B-A: 0.04005146026611328\n",
            "epoch: 1866, train_error(A): 0.08701460063457489, test_error(B): 0.12719622254371643, B-A: 0.04018162190914154\n",
            "epoch: 1868, train_error(A): 0.08700624108314514, test_error(B): 0.1271161288022995, B-A: 0.04010988771915436\n",
            "epoch: 1870, train_error(A): 0.0869978666305542, test_error(B): 0.1269281804561615, B-A: 0.0399303138256073\n",
            "epoch: 1872, train_error(A): 0.08698989450931549, test_error(B): 0.1267697811126709, B-A: 0.03977988660335541\n",
            "epoch: 1874, train_error(A): 0.08698191493749619, test_error(B): 0.1267162561416626, B-A: 0.03973434120416641\n",
            "epoch: 1876, train_error(A): 0.08697368949651718, test_error(B): 0.1267610490322113, B-A: 0.03978735953569412\n",
            "epoch: 1878, train_error(A): 0.08696547895669937, test_error(B): 0.12685337662696838, B-A: 0.03988789767026901\n",
            "epoch: 1880, train_error(A): 0.08695744723081589, test_error(B): 0.1269373893737793, B-A: 0.03997994214296341\n",
            "epoch: 1882, train_error(A): 0.0869494304060936, test_error(B): 0.12697401642799377, B-A: 0.04002458602190018\n",
            "epoch: 1884, train_error(A): 0.08694134652614594, test_error(B): 0.12695182859897614, B-A: 0.0400104820728302\n",
            "epoch: 1886, train_error(A): 0.0869332030415535, test_error(B): 0.12689024209976196, B-A: 0.039957039058208466\n",
            "epoch: 1888, train_error(A): 0.08692511171102524, test_error(B): 0.12681810557842255, B-A: 0.03989299386739731\n",
            "epoch: 1890, train_error(A): 0.08691706508398056, test_error(B): 0.12675638496875763, B-A: 0.03983931988477707\n",
            "epoch: 1892, train_error(A): 0.08690903335809708, test_error(B): 0.12671275436878204, B-A: 0.03980372101068497\n",
            "epoch: 1894, train_error(A): 0.086900994181633, test_error(B): 0.1266889125108719, B-A: 0.03978791832923889\n",
            "epoch: 1896, train_error(A): 0.08689294010400772, test_error(B): 0.12668345868587494, B-A: 0.03979051858186722\n",
            "epoch: 1898, train_error(A): 0.08688486367464066, test_error(B): 0.12668994069099426, B-A: 0.03980507701635361\n",
            "epoch: 1900, train_error(A): 0.08687681704759598, test_error(B): 0.126700758934021, B-A: 0.03982394188642502\n",
            "epoch: 1902, train_error(A): 0.0868687704205513, test_error(B): 0.12671057879924774, B-A: 0.03984180837869644\n",
            "epoch: 1904, train_error(A): 0.08686073124408722, test_error(B): 0.1267186403274536, B-A: 0.039857909083366394\n",
            "epoch: 1906, train_error(A): 0.08685269951820374, test_error(B): 0.12672412395477295, B-A: 0.039871424436569214\n",
            "epoch: 1908, train_error(A): 0.08684468269348145, test_error(B): 0.12672580778598785, B-A: 0.03988112509250641\n",
            "epoch: 1910, train_error(A): 0.08683666586875916, test_error(B): 0.1267256885766983, B-A: 0.03988902270793915\n",
            "epoch: 1912, train_error(A): 0.08682864904403687, test_error(B): 0.1267271637916565, B-A: 0.03989851474761963\n",
            "epoch: 1914, train_error(A): 0.08682063966989517, test_error(B): 0.12673319876194, B-A: 0.03991255909204483\n",
            "epoch: 1916, train_error(A): 0.08681266009807587, test_error(B): 0.12674580514431, B-A: 0.03993314504623413\n",
            "epoch: 1918, train_error(A): 0.08680468797683716, test_error(B): 0.1267697811126709, B-A: 0.03996509313583374\n",
            "epoch: 1920, train_error(A): 0.08679678291082382, test_error(B): 0.12681391835212708, B-A: 0.04001713544130325\n",
            "epoch: 1922, train_error(A): 0.086789071559906, test_error(B): 0.12689368426799774, B-A: 0.040104612708091736\n",
            "epoch: 1924, train_error(A): 0.0867818146944046, test_error(B): 0.12703652679920197, B-A: 0.04025471210479736\n",
            "epoch: 1926, train_error(A): 0.08677592873573303, test_error(B): 0.12729355692863464, B-A: 0.04051762819290161\n",
            "epoch: 1928, train_error(A): 0.08677420765161514, test_error(B): 0.12776115536689758, B-A: 0.04098694771528244\n",
            "epoch: 1930, train_error(A): 0.08678595721721649, test_error(B): 0.1286257803440094, B-A: 0.04183982312679291\n",
            "epoch: 1932, train_error(A): 0.08684316277503967, test_error(B): 0.13025380671024323, B-A: 0.04341064393520355\n",
            "epoch: 1934, train_error(A): 0.0870559886097908, test_error(B): 0.1333504170179367, B-A: 0.046294428408145905\n",
            "epoch: 1936, train_error(A): 0.08776721358299255, test_error(B): 0.13906890153884888, B-A: 0.05130168795585632\n",
            "epoch: 1938, train_error(A): 0.08959676325321198, test_error(B): 0.14800147712230682, B-A: 0.05840471386909485\n",
            "epoch: 1940, train_error(A): 0.0911807268857956, test_error(B): 0.15390180051326752, B-A: 0.06272107362747192\n",
            "epoch: 1942, train_error(A): 0.08815251290798187, test_error(B): 0.1417473405599594, B-A: 0.05359482765197754\n",
            "epoch: 1944, train_error(A): 0.08739344030618668, test_error(B): 0.11751225590705872, B-A: 0.03011881560087204\n",
            "epoch: 1946, train_error(A): 0.08884622901678085, test_error(B): 0.11043369024991989, B-A: 0.021587461233139038\n",
            "epoch: 1948, train_error(A): 0.08676287531852722, test_error(B): 0.12877348065376282, B-A: 0.042010605335235596\n",
            "epoch: 1950, train_error(A): 0.08791901916265488, test_error(B): 0.14129310846328735, B-A: 0.05337408930063248\n",
            "epoch: 1952, train_error(A): 0.08676247298717499, test_error(B): 0.1294245421886444, B-A: 0.04266206920146942\n",
            "epoch: 1954, train_error(A): 0.0875672921538353, test_error(B): 0.11651149392127991, B-A: 0.02894420176744461\n",
            "epoch: 1956, train_error(A): 0.0868062674999237, test_error(B): 0.12367317825555801, B-A: 0.03686691075563431\n",
            "epoch: 1958, train_error(A): 0.08713002502918243, test_error(B): 0.13521678745746613, B-A: 0.04808676242828369\n",
            "epoch: 1960, train_error(A): 0.08685377240180969, test_error(B): 0.13188479840755463, B-A: 0.045031026005744934\n",
            "epoch: 1962, train_error(A): 0.08686533570289612, test_error(B): 0.12154402583837509, B-A: 0.03467869013547897\n",
            "epoch: 1964, train_error(A): 0.08691134303808212, test_error(B): 0.12083221226930618, B-A: 0.03392086923122406\n",
            "epoch: 1966, train_error(A): 0.0866747498512268, test_error(B): 0.12861230969429016, B-A: 0.041937559843063354\n",
            "epoch: 1968, train_error(A): 0.0868663489818573, test_error(B): 0.13230496644973755, B-A: 0.04543861746788025\n",
            "epoch: 1970, train_error(A): 0.08665022253990173, test_error(B): 0.1278628706932068, B-A: 0.041212648153305054\n",
            "epoch: 1972, train_error(A): 0.0867227166891098, test_error(B): 0.12240657210350037, B-A: 0.035683855414390564\n",
            "epoch: 1974, train_error(A): 0.08672355115413666, test_error(B): 0.12228890508413315, B-A: 0.03556535392999649\n",
            "epoch: 1976, train_error(A): 0.08660721778869629, test_error(B): 0.12635169923305511, B-A: 0.039744481444358826\n",
            "epoch: 1978, train_error(A): 0.08667855709791183, test_error(B): 0.12944847345352173, B-A: 0.042769916355609894\n",
            "epoch: 1980, train_error(A): 0.08664388209581375, test_error(B): 0.1288478970527649, B-A: 0.04220401495695114\n",
            "epoch: 1982, train_error(A): 0.08658469468355179, test_error(B): 0.12594208121299744, B-A: 0.03935738652944565\n",
            "epoch: 1984, train_error(A): 0.08662155270576477, test_error(B): 0.12380120158195496, B-A: 0.037179648876190186\n",
            "epoch: 1986, train_error(A): 0.08660093694925308, test_error(B): 0.12415031343698502, B-A: 0.037549376487731934\n",
            "epoch: 1988, train_error(A): 0.08656167984008789, test_error(B): 0.12624096870422363, B-A: 0.03967928886413574\n",
            "epoch: 1990, train_error(A): 0.08657485991716385, test_error(B): 0.1280197948217392, B-A: 0.04144493490457535\n",
            "epoch: 1992, train_error(A): 0.08656802028417587, test_error(B): 0.12807774543762207, B-A: 0.0415097251534462\n",
            "epoch: 1994, train_error(A): 0.08654031157493591, test_error(B): 0.12670090794563293, B-A: 0.04016059637069702\n",
            "epoch: 1996, train_error(A): 0.0865389034152031, test_error(B): 0.12527193129062653, B-A: 0.03873302787542343\n",
            "epoch: 1998, train_error(A): 0.0865384191274643, test_error(B): 0.12486163526773453, B-A: 0.03832321614027023\n",
            "epoch: 2000, train_error(A): 0.08652085810899734, test_error(B): 0.12550394237041473, B-A: 0.03898308426141739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhsQRDZYOxuo",
        "colab_type": "code",
        "outputId": "cb9efbfe-c107-4489-beb0-c501daf90e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 하이퍼파라미터 출력\n",
        "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
        "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
        " \n",
        "print(',seq_length:', seq_length, end='')\n",
        "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
        "print(',forget_bias:', forget_bias, end='')\n",
        "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
        "print(',keep_prob:', keep_prob, end='')\n",
        " \n",
        "print(',epoch_num:', epoch_num, end='')\n",
        "print(',learning_rate:', learning_rate, end='')\n",
        " \n",
        "print(',train_error:', train_error_summary[-1], end='')\n",
        "print(',test_error:', test_error_summary[-1], end='')\n",
        "print(',min_test_error:', np.min(test_error_summary))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_data_column_cnt: 11,output_data_column_cnt: 1,seq_length: 7,rnn_cell_hidden_dim: 12,forget_bias: 1,num_stacked_layers: 4,keep_prob: 1.0,epoch_num: 2000,learning_rate: 0.001,train_error: 0.08652086,test_error: 0.12550394,min_test_error: 0.106002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfFDfVFOxus",
        "colab_type": "code",
        "outputId": "1d01ba51-906d-4a27-fe0a-f3e7fbcdb4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "# 결과 그래프 출력\n",
        "plt.figure(1)\n",
        "plt.plot(train_error_summary, 'gold')\n",
        "plt.plot(test_error_summary, 'b')\n",
        "plt.xlabel('Epoch(x100)')\n",
        "plt.ylabel('Root Mean Square Error')\n",
        " \n",
        "plt.figure(2)\n",
        "plt.plot(testY, 'r')\n",
        "plt.plot(test_predict, 'b')\n",
        "plt.xlabel('Time Period')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvJkTcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-yCUwDrRt5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBf8ry2lRug4",
        "colab_type": "code",
        "outputId": "24d512af-fbf3-4dbd-94af-f2217f4423c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "error1 = mean_absolute_percentage_error(testY, test_predict)\n",
        "print(\"MAPE :\",error1,\"%\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE : 21.095383044374984 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKSIUE7XKD3G",
        "colab_type": "code",
        "outputId": "dd597be0-27d1-40ac-8708-9c997c98a49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "testY"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50901335],\n",
              "       [0.43360396],\n",
              "       [0.33796615],\n",
              "       [0.39521123],\n",
              "       [0.5017201 ],\n",
              "       [0.5377735 ],\n",
              "       [0.35269024]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8yGnXcAOxuy",
        "colab_type": "code",
        "outputId": "159f3125-02d8-4966-a844-ce6238173632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
        "recent_data = np.array([x[len(x)-seq_length : ]])\n",
        "print(\"recent_data.shape:\", recent_data.shape)\n",
        "print(\"recent_data:\", recent_data)\n",
        " \n",
        "# 내일 방문자를 예측\n",
        "test_predict1 = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        " \n",
        "print(\"test_predict\", test_predict1[0])\n",
        "test_predict1 = reverse_min_max_scaling(visitor, test_predict) # 금액데이터 역정규화한다\n",
        "print(\"visitors\", test_predict1[0]) # 예측한 visitor를 출력한다"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recent_data.shape: (1, 7, 11)\n",
            "recent_data: [[[0.27148785 0.25251926 0.30349733 0.10491998 0.13633669 0.11025489\n",
            "   0.11677534 0.10491998 0.11084766 0.10491998 0.50901335]\n",
            "  [0.2649674  0.25429757 0.28630705 0.10491998 0.13278008 0.10966212\n",
            "   0.12270302 0.10491998 0.11084766 0.10491998 0.43360396]\n",
            "  [0.25726141 0.25311203 0.2649674  0.33313574 0.14641375 0.10788382\n",
            "   0.12863071 0.10491998 0.11084766 0.10491998 0.33796615]\n",
            "  [0.26141079 0.25133373 0.2797866  0.17308832 0.13040901 0.10788382\n",
            "   0.13455839 0.10491998 0.11084766 0.10491998 0.39521123]\n",
            "  [0.26911678 0.24836989 0.29519858 0.3301719  0.12803794 0.10906935\n",
            "   0.14048607 0.11084766 0.10491998 0.10491998 0.5017201 ]\n",
            "  [0.25963248 0.25074096 0.28275044 0.21754594 0.14048607 0.11025489\n",
            "   0.14641375 0.11084766 0.10491998 0.10491998 0.5377735 ]\n",
            "  [0.27030231 0.24422051 0.30171903 0.10491998 0.14167161 0.11084766\n",
            "   0.11084766 0.10491998 0.11084766 0.10491998 0.35269024]]]\n",
            "test_predict [0.347582]\n",
            "visitors [1694.3478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUxRj2UyujUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}