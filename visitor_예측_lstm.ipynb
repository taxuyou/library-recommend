{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "visitor_예측_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taxuyou/library-recommend-and-timeseries-predict/blob/master/visitor_%EC%98%88%EC%B8%A1_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_WUk368Oxtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2hZnGv6Oxts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardization\n",
        "def data_standardization(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.mean()) / x_np.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9DlduZOxtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
        "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
        "# Min-Max scaling\n",
        "def min_max_scaling(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
        " \n",
        "# 정규화된 값을 원래의 값으로 되돌린다\n",
        "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
        "def reverse_min_max_scaling(org_x, x):\n",
        "    org_x_np = np.asarray(org_x)\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TbAY-pwzpcq",
        "colab": {}
      },
      "source": [
        "# 하이퍼파라미터\n",
        "input_data_column_cnt = 4  # 입력데이터의 컬럼 개수(Variable 개수)\n",
        "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
        " \n",
        "seq_length = 1           # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
        "rnn_cell_hidden_dim = 12   # 각 셀의 (hidden)출력 크기\n",
        "forget_bias = 1          # 망각편향(기본값 1.0)\n",
        "num_stacked_layers = 4     # stacked LSTM layers 개수\n",
        "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
        " \n",
        "epoch_num = 2000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
        "learning_rate = 0.01       # 학습률"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU7YchG0Oxt4",
        "colab_type": "code",
        "outputId": "ef37f045-1a43-4308-88b8-f6ca9e2d5400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# 데이터를 로딩한다.\n",
        "file_name = 'test.csv' # 파일\n",
        "encoding = 'euc-kr' # 문자 인코딩\n",
        "names = ['days','holiday','workingday','visitors']\n",
        "raw_dataframe = pd.read_csv(file_name, names=names, encoding=encoding) #판다스이용 csv파일 로딩\n",
        "raw_dataframe.info() # 데이터 정보 출력\n",
        " \n",
        "#raw_dataframe.drop('date', axis=1, inplace=True) # 시간열을 제거하고 dataframe 재생성하지 않기\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 840 entries, 0 to 839\n",
            "Data columns (total 4 columns):\n",
            "days          840 non-null object\n",
            "holiday       840 non-null object\n",
            "workingday    840 non-null object\n",
            "visitors      840 non-null object\n",
            "dtypes: object(4)\n",
            "memory usage: 26.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcRIU6SygcI",
        "colab_type": "code",
        "outputId": "fe89985e-1b12-467d-d1cf-7630f6fd66d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_info = raw_dataframe.values[1:].astype(np.float) #  문자열을 부동소수점형으로 변환한다\n",
        "print(\"data_info.shape: \", data_info.shape)\n",
        "print(\"data_info[0]: \", data_info[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_info.shape:  (839, 4)\n",
            "data_info[0]:  [7.000e+00 1.000e+00 0.000e+00 2.221e+03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCFxy3Y8sgYN",
        "colab_type": "code",
        "outputId": "98619b12-7d4c-46ab-a227-7d981dafc9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "data_info"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.000e+00, 1.000e+00, 0.000e+00, 2.221e+03],\n",
              "       [1.000e+00, 0.000e+00, 1.000e+00, 2.447e+03],\n",
              "       [2.000e+00, 0.000e+00, 1.000e+00, 2.963e+03],\n",
              "       ...,\n",
              "       [6.000e+00, 1.000e+00, 0.000e+00, 3.647e+03],\n",
              "       [7.000e+00, 1.000e+00, 0.000e+00, 3.909e+03],\n",
              "       [1.000e+00, 0.000e+00, 1.000e+00, 2.564e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd3c95sOxuA",
        "colab_type": "code",
        "outputId": "9081917b-5e30-44e6-8247-875214a82520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 데이터들을 정규화한다\n",
        "# ['days','holiday','workingday','visitors']에서 'workingday'까지 취함\n",
        "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
        "day = data_info[:,:3]\n",
        "norm_day = min_max_scaling(day) # 가격형태 데이터 정규화 처리\n",
        "print(\"day.shape: \", day.shape)\n",
        "print(\"day[0]: \", day[0])\n",
        "print(\"norm_day[0]: \", norm_day[0])\n",
        "print(\"=\"*100) # 화면상 구분용"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day.shape:  (839, 3)\n",
            "day[0]:  [7. 1. 0.]\n",
            "norm_day[0]:  [0.99999999 0.14285714 0.        ]\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInLXQzHOxuF",
        "colab_type": "code",
        "outputId": "69327ed8-0791-4815-837f-5b59520b6d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# 방문자 데이터를 정규화한다\n",
        "# ['days','holiday','workingday','visitors']에서 마지막 'visitors'만 취함\n",
        "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
        "visitor = data_info[:,-1:]\n",
        "norm_visitor = min_max_scaling(visitor) # 거래량형태 데이터 정규화 처리\n",
        "print(\"visitor.shape: \", visitor.shape)\n",
        "print(\"vitisor[0]: \", visitor[0])\n",
        "print(\"norm_visitor[0]: \", norm_visitor[0])\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
        "x = np.concatenate((norm_day, norm_visitor), axis=1) # axis=1, 세로로 합친다\n",
        "print(\"x.shape: \", x.shape)\n",
        "print(\"x[0]: \", x[0])    # x의 첫 값\n",
        "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
        "print(\"=\"*100) # 화면상 구분용\n",
        " \n",
        "y = x[:, [3]] # 타켓은 방문자다\n",
        "print(\"y[0]: \",y[0])     # y의 첫 값\n",
        "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
        " \n",
        " \n",
        "dataX = [] # 입력으로 사용될 Sequence Data\n",
        "dataY = [] # 출력(타켓)으로 사용\n",
        " \n",
        "for i in range(0, len(y) - seq_length):\n",
        "    _x = x[i : i+seq_length]\n",
        "    _y = y[i + seq_length] # 다음 나타날 방문자수(정답)\n",
        "    if i is 0:\n",
        "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
        "    dataX.append(_x) # dataX 리스트에 추가\n",
        "    dataY.append(_y) # dataY 리스트에 추가"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "visitor.shape:  (839, 1)\n",
            "vitisor[0]:  [2221.]\n",
            "norm_visitor[0]:  [0.27098079]\n",
            "====================================================================================================\n",
            "x.shape:  (839, 4)\n",
            "x[0]:  [0.99999999 0.14285714 0.         0.27098079]\n",
            "x[-1]:  [0.14285714 0.         0.14285714 0.32052578]\n",
            "====================================================================================================\n",
            "y[0]:  [0.27098079]\n",
            "y[-1]:  [0.32052578]\n",
            "[[0.99999999 0.14285714 0.         0.27098079]] -> [0.3036256]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXFGhBzOxuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습용/테스트용 데이터 생성\n",
        "# 전체 70%를 학습용 데이터로 사용\n",
        "train_size = int(len(dataY) * 0.97)\n",
        "# 나머지(30%)를 테스트용 데이터로 사용\n",
        "test_size = len(dataY) - train_size\n",
        " \n",
        "# 데이터를 잘라 학습용 데이터 생성\n",
        "trainX = np.array(dataX[0:train_size])\n",
        "trainY = np.array(dataY[0:train_size])\n",
        " \n",
        "# 데이터를 잘라 테스트용 데이터 생성\n",
        "testX = np.array(dataX[train_size:len(dataX)])\n",
        "testY = np.array(dataY[train_size:len(dataY)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGfwx-RnOO6Z",
        "colab_type": "code",
        "outputId": "47750a7e-1a76-4d98-d435-71d13b4b1f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVC5TGyOxuM",
        "colab_type": "code",
        "outputId": "f724f627-4d08-498a-e281-99cbd09e6fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 텐서플로우 플레이스홀더 생성\n",
        "# 입력 X, 출력 Y를 생성한다\n",
        "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
        "print(\"X: \", X)\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"Y: \", Y)\n",
        " \n",
        "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
        "targets = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"targets: \", targets)\n",
        " \n",
        "predictions = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"predictions: \", predictions)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  Tensor(\"Placeholder:0\", shape=(?, 1, 4), dtype=float32)\n",
            "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
            "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
            "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsh5_GgAOxuQ",
        "colab_type": "code",
        "outputId": "174edfc4-2416-4df1-b2af-74c9f9b3c593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# 모델(LSTM 네트워크) 생성\n",
        "def lstm_cell():\n",
        "    # LSTM셀을 생성\n",
        "    # num_units: 각 Cell 출력 크기\n",
        "    # forget_bias:  to the biases of the forget gate \n",
        "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
        "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
        "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
        "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
        "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    if keep_prob < 1.0:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "    return cell\n",
        " \n",
        "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
        "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
        "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-14-668a829a3f10>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-14-668a829a3f10>:16: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QGqL_YOxuW",
        "colab_type": "code",
        "outputId": "0a20d6c9-ac07-48db-bf5a-c0eb13b3c3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
        "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "print(\"hypothesis: \", hypothesis)\n",
        " \n",
        "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
        "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
        "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
        " \n",
        " \n",
        "# 손실함수로 평균제곱오차를 사용한다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "# 최적화함수로 AdamOptimizer를 사용한다\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
        " \n",
        "train = optimizer.minimize(loss)\n",
        " \n",
        "# RMSE(Root Mean Square Error)\n",
        "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
        "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
        "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
        " \n",
        " \n",
        "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
        "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
        "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
        " \n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-a2b6404f5de1>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 1, 12), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "afe5af9c-1f2c-4983-899d-b2c10d6d2237",
        "id": "kx6tvlt03lvu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 학습한다\n",
        "start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
        "print('학습을 시작합니다...')\n",
        "for epoch in range(epoch_num):\n",
        "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
        "    if ((epoch+1) % 2 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
        "        # 학습용데이터로 rmse오차를 구한다\n",
        "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
        "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
        "        train_error_summary.append(train_error)\n",
        " \n",
        "        # 테스트용데이터로 rmse오차를 구한다\n",
        "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
        "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
        "        test_error_summary.append(test_error)\n",
        "        \n",
        "        # 현재 오류를 출력한다\n",
        "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
        "        \n",
        "end_time = datetime.datetime.now() # 종료시간을 기록한다\n",
        "elapsed_time = end_time - start_time # 경과시간을 구한다\n",
        "print('elapsed_time:',elapsed_time)\n",
        "print('elapsed_time per epoch:',elapsed_time/epoch_num)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습을 시작합니다...\n",
            "epoch: 2, train_error(A): 0.2924589514732361, test_error(B): 0.30617982149124146, B-A: 0.013720870018005371\n",
            "epoch: 4, train_error(A): 0.25153034925460815, test_error(B): 0.26340967416763306, B-A: 0.011879324913024902\n",
            "epoch: 6, train_error(A): 0.209596186876297, test_error(B): 0.21851445734500885, B-A: 0.008918270468711853\n",
            "epoch: 8, train_error(A): 0.1697748601436615, test_error(B): 0.17355257272720337, B-A: 0.00377771258354187\n",
            "epoch: 10, train_error(A): 0.1401933878660202, test_error(B): 0.1349807232618332, B-A: -0.005212664604187012\n",
            "epoch: 12, train_error(A): 0.13433705270290375, test_error(B): 0.1175268366932869, B-A: -0.016810216009616852\n",
            "epoch: 14, train_error(A): 0.1495383083820343, test_error(B): 0.12619397044181824, B-A: -0.023344337940216064\n",
            "epoch: 16, train_error(A): 0.15864859521389008, test_error(B): 0.13390636444091797, B-A: -0.024742230772972107\n",
            "epoch: 18, train_error(A): 0.15510348975658417, test_error(B): 0.13084518909454346, B-A: -0.02425830066204071\n",
            "epoch: 20, train_error(A): 0.14621296525001526, test_error(B): 0.12368941307067871, B-A: -0.022523552179336548\n",
            "epoch: 22, train_error(A): 0.13836844265460968, test_error(B): 0.11872207373380661, B-A: -0.01964636892080307\n",
            "epoch: 24, train_error(A): 0.13421882688999176, test_error(B): 0.11805375665426254, B-A: -0.016165070235729218\n",
            "epoch: 26, train_error(A): 0.13340911269187927, test_error(B): 0.12052294611930847, B-A: -0.0128861665725708\n",
            "epoch: 28, train_error(A): 0.13438110053539276, test_error(B): 0.1240314245223999, B-A: -0.010349676012992859\n",
            "epoch: 30, train_error(A): 0.13571381568908691, test_error(B): 0.12700697779655457, B-A: -0.008706837892532349\n",
            "epoch: 32, train_error(A): 0.13658057153224945, test_error(B): 0.1286836713552475, B-A: -0.007896900177001953\n",
            "epoch: 34, train_error(A): 0.13670477271080017, test_error(B): 0.12890948355197906, B-A: -0.007795289158821106\n",
            "epoch: 36, train_error(A): 0.13618125021457672, test_error(B): 0.12791191041469574, B-A: -0.008269339799880981\n",
            "epoch: 38, train_error(A): 0.1353013664484024, test_error(B): 0.126118466258049, B-A: -0.009182900190353394\n",
            "epoch: 40, train_error(A): 0.13440440595149994, test_error(B): 0.12401747703552246, B-A: -0.010386928915977478\n",
            "epoch: 42, train_error(A): 0.1337575614452362, test_error(B): 0.12204065918922424, B-A: -0.011716902256011963\n",
            "epoch: 44, train_error(A): 0.13347791135311127, test_error(B): 0.12047275900840759, B-A: -0.013005152344703674\n",
            "epoch: 46, train_error(A): 0.13351792097091675, test_error(B): 0.11941247433423996, B-A: -0.014105446636676788\n",
            "epoch: 48, train_error(A): 0.13371875882148743, test_error(B): 0.11880307644605637, B-A: -0.01491568237543106\n",
            "epoch: 50, train_error(A): 0.1339031457901001, test_error(B): 0.11851571500301361, B-A: -0.015387430787086487\n",
            "epoch: 52, train_error(A): 0.13395826518535614, test_error(B): 0.11843668669462204, B-A: -0.0155215784907341\n",
            "epoch: 54, train_error(A): 0.13386929035186768, test_error(B): 0.11851104348897934, B-A: -0.015358246862888336\n",
            "epoch: 56, train_error(A): 0.13369709253311157, test_error(B): 0.11873085051774979, B-A: -0.014966242015361786\n",
            "epoch: 58, train_error(A): 0.1335257589817047, test_error(B): 0.11909282207489014, B-A: -0.014432936906814575\n",
            "epoch: 60, train_error(A): 0.13341450691223145, test_error(B): 0.11956234276294708, B-A: -0.013852164149284363\n",
            "epoch: 62, train_error(A): 0.13337688148021698, test_error(B): 0.12006600946187973, B-A: -0.01331087201833725\n",
            "epoch: 64, train_error(A): 0.13338850438594818, test_error(B): 0.12051123380661011, B-A: -0.012877270579338074\n",
            "epoch: 66, train_error(A): 0.13341040909290314, test_error(B): 0.12081660330295563, B-A: -0.01259380578994751\n",
            "epoch: 68, train_error(A): 0.13341152667999268, test_error(B): 0.12093604356050491, B-A: -0.012475483119487762\n",
            "epoch: 70, train_error(A): 0.13338035345077515, test_error(B): 0.12086769193410873, B-A: -0.012512661516666412\n",
            "epoch: 72, train_error(A): 0.1333237737417221, test_error(B): 0.12064766138792038, B-A: -0.012676112353801727\n",
            "epoch: 74, train_error(A): 0.13325786590576172, test_error(B): 0.12033412605524063, B-A: -0.012923739850521088\n",
            "epoch: 76, train_error(A): 0.13319680094718933, test_error(B): 0.1199890673160553, B-A: -0.013207733631134033\n",
            "epoch: 78, train_error(A): 0.13314533233642578, test_error(B): 0.11966310441493988, B-A: -0.013482227921485901\n",
            "epoch: 80, train_error(A): 0.13309812545776367, test_error(B): 0.11938832700252533, B-A: -0.013709798455238342\n",
            "epoch: 82, train_error(A): 0.13304442167282104, test_error(B): 0.11917828768491745, B-A: -0.013866133987903595\n",
            "epoch: 84, train_error(A): 0.13297389447689056, test_error(B): 0.11903198808431625, B-A: -0.01394190639257431\n",
            "epoch: 86, train_error(A): 0.13288050889968872, test_error(B): 0.11893802136182785, B-A: -0.01394248753786087\n",
            "epoch: 88, train_error(A): 0.132762148976326, test_error(B): 0.11887704581022263, B-A: -0.013885103166103363\n",
            "epoch: 90, train_error(A): 0.13261757791042328, test_error(B): 0.11882280558347702, B-A: -0.013794772326946259\n",
            "epoch: 92, train_error(A): 0.13244277238845825, test_error(B): 0.11874314397573471, B-A: -0.013699628412723541\n",
            "epoch: 94, train_error(A): 0.13222873210906982, test_error(B): 0.11860251426696777, B-A: -0.01362621784210205\n",
            "epoch: 96, train_error(A): 0.131961390376091, test_error(B): 0.11836585402488708, B-A: -0.013595536351203918\n",
            "epoch: 98, train_error(A): 0.13162225484848022, test_error(B): 0.11800175905227661, B-A: -0.013620495796203613\n",
            "epoch: 100, train_error(A): 0.1311899870634079, test_error(B): 0.11748348921537399, B-A: -0.013706497848033905\n",
            "epoch: 102, train_error(A): 0.13064050674438477, test_error(B): 0.1167878806591034, B-A: -0.013852626085281372\n",
            "epoch: 104, train_error(A): 0.1299450844526291, test_error(B): 0.11588931828737259, B-A: -0.0140557661652565\n",
            "epoch: 106, train_error(A): 0.12907198071479797, test_error(B): 0.11475633084774017, B-A: -0.0143156498670578\n",
            "epoch: 108, train_error(A): 0.12798543274402618, test_error(B): 0.1133459284901619, B-A: -0.014639504253864288\n",
            "epoch: 110, train_error(A): 0.12664099037647247, test_error(B): 0.11159540712833405, B-A: -0.015045583248138428\n",
            "epoch: 112, train_error(A): 0.12499433010816574, test_error(B): 0.10943924635648727, B-A: -0.015555083751678467\n",
            "epoch: 114, train_error(A): 0.12303758412599564, test_error(B): 0.1068621352314949, B-A: -0.016175448894500732\n",
            "epoch: 116, train_error(A): 0.12083956599235535, test_error(B): 0.1039518415927887, B-A: -0.01688772439956665\n",
            "epoch: 118, train_error(A): 0.11857035011053085, test_error(B): 0.10092369467020035, B-A: -0.017646655440330505\n",
            "epoch: 120, train_error(A): 0.11649300158023834, test_error(B): 0.09813059866428375, B-A: -0.01836240291595459\n",
            "epoch: 122, train_error(A): 0.11489036679267883, test_error(B): 0.0960191860795021, B-A: -0.018871180713176727\n",
            "epoch: 124, train_error(A): 0.11390641331672668, test_error(B): 0.09487152844667435, B-A: -0.019034884870052338\n",
            "epoch: 126, train_error(A): 0.11342868208885193, test_error(B): 0.09456158429384232, B-A: -0.018867097795009613\n",
            "epoch: 128, train_error(A): 0.11316650360822678, test_error(B): 0.09476697444915771, B-A: -0.01839952915906906\n",
            "epoch: 130, train_error(A): 0.11284337937831879, test_error(B): 0.09513847529888153, B-A: -0.017704904079437256\n",
            "epoch: 132, train_error(A): 0.11235085874795914, test_error(B): 0.09540742635726929, B-A: -0.01694343239068985\n",
            "epoch: 134, train_error(A): 0.11176420003175735, test_error(B): 0.09544715285301208, B-A: -0.01631704717874527\n",
            "epoch: 136, train_error(A): 0.11120984703302383, test_error(B): 0.09528428316116333, B-A: -0.015925563871860504\n",
            "epoch: 138, train_error(A): 0.11073237657546997, test_error(B): 0.09494706988334656, B-A: -0.015785306692123413\n",
            "epoch: 140, train_error(A): 0.11030872911214828, test_error(B): 0.09447424858808517, B-A: -0.01583448052406311\n",
            "epoch: 142, train_error(A): 0.1099436804652214, test_error(B): 0.09393105655908585, B-A: -0.01601262390613556\n",
            "epoch: 144, train_error(A): 0.10966911166906357, test_error(B): 0.09341835230588913, B-A: -0.01625075936317444\n",
            "epoch: 146, train_error(A): 0.10947667807340622, test_error(B): 0.09298346191644669, B-A: -0.016493216156959534\n",
            "epoch: 148, train_error(A): 0.10931065678596497, test_error(B): 0.09269192069768906, B-A: -0.01661873608827591\n",
            "epoch: 150, train_error(A): 0.10913333296775818, test_error(B): 0.0925275981426239, B-A: -0.016605734825134277\n",
            "epoch: 152, train_error(A): 0.10895096510648727, test_error(B): 0.09251943975687027, B-A: -0.016431525349617004\n",
            "epoch: 154, train_error(A): 0.10877715051174164, test_error(B): 0.09264664351940155, B-A: -0.016130506992340088\n",
            "epoch: 156, train_error(A): 0.10861234366893768, test_error(B): 0.09286079555749893, B-A: -0.01575154811143875\n",
            "epoch: 158, train_error(A): 0.10846216231584549, test_error(B): 0.09309075027704239, B-A: -0.0153714120388031\n",
            "epoch: 160, train_error(A): 0.10832761973142624, test_error(B): 0.09326352924108505, B-A: -0.015064090490341187\n",
            "epoch: 162, train_error(A): 0.10819486528635025, test_error(B): 0.09331103414297104, B-A: -0.014883831143379211\n",
            "epoch: 164, train_error(A): 0.10805294662714005, test_error(B): 0.09319962561130524, B-A: -0.014853321015834808\n",
            "epoch: 166, train_error(A): 0.10790644586086273, test_error(B): 0.09296058863401413, B-A: -0.014945857226848602\n",
            "epoch: 168, train_error(A): 0.1077631264925003, test_error(B): 0.09264826029539108, B-A: -0.015114866197109222\n",
            "epoch: 170, train_error(A): 0.10762354731559753, test_error(B): 0.09232228994369507, B-A: -0.015301257371902466\n",
            "epoch: 172, train_error(A): 0.10748544335365295, test_error(B): 0.09201222658157349, B-A: -0.015473216772079468\n",
            "epoch: 174, train_error(A): 0.10734803229570389, test_error(B): 0.09174656867980957, B-A: -0.015601463615894318\n",
            "epoch: 176, train_error(A): 0.10720840096473694, test_error(B): 0.09152751415967941, B-A: -0.015680886805057526\n",
            "epoch: 178, train_error(A): 0.1070631891489029, test_error(B): 0.09134853631258011, B-A: -0.015714652836322784\n",
            "epoch: 180, train_error(A): 0.10691313445568085, test_error(B): 0.09120277315378189, B-A: -0.015710361301898956\n",
            "epoch: 182, train_error(A): 0.10676062107086182, test_error(B): 0.09108151495456696, B-A: -0.01567910611629486\n",
            "epoch: 184, train_error(A): 0.10660579800605774, test_error(B): 0.09097899496555328, B-A: -0.015626803040504456\n",
            "epoch: 186, train_error(A): 0.10644715279340744, test_error(B): 0.09087318181991577, B-A: -0.015573970973491669\n",
            "epoch: 188, train_error(A): 0.10628353804349899, test_error(B): 0.09075663983821869, B-A: -0.015526898205280304\n",
            "epoch: 190, train_error(A): 0.10611367970705032, test_error(B): 0.0906115472316742, B-A: -0.01550213247537613\n",
            "epoch: 192, train_error(A): 0.10593671351671219, test_error(B): 0.09044546633958817, B-A: -0.015491247177124023\n",
            "epoch: 194, train_error(A): 0.10575281083583832, test_error(B): 0.09026280045509338, B-A: -0.015490010380744934\n",
            "epoch: 196, train_error(A): 0.10556237399578094, test_error(B): 0.09008143097162247, B-A: -0.015480943024158478\n",
            "epoch: 198, train_error(A): 0.10536523163318634, test_error(B): 0.0899105817079544, B-A: -0.015454649925231934\n",
            "epoch: 200, train_error(A): 0.10516109317541122, test_error(B): 0.08975756913423538, B-A: -0.015403524041175842\n",
            "epoch: 202, train_error(A): 0.10495012253522873, test_error(B): 0.0896218791604042, B-A: -0.015328243374824524\n",
            "epoch: 204, train_error(A): 0.10473261028528214, test_error(B): 0.08950047194957733, B-A: -0.015232138335704803\n",
            "epoch: 206, train_error(A): 0.10450921952724457, test_error(B): 0.08938878029584885, B-A: -0.015120439231395721\n",
            "epoch: 208, train_error(A): 0.10428088158369064, test_error(B): 0.08928393572568893, B-A: -0.014996945858001709\n",
            "epoch: 210, train_error(A): 0.10404840111732483, test_error(B): 0.08918079733848572, B-A: -0.014867603778839111\n",
            "epoch: 212, train_error(A): 0.10381250083446503, test_error(B): 0.0890776738524437, B-A: -0.014734826982021332\n",
            "epoch: 214, train_error(A): 0.10357414931058884, test_error(B): 0.0889735296368599, B-A: -0.014600619673728943\n",
            "epoch: 216, train_error(A): 0.103334441781044, test_error(B): 0.08887265622615814, B-A: -0.014461785554885864\n",
            "epoch: 218, train_error(A): 0.10309449583292007, test_error(B): 0.08877673745155334, B-A: -0.01431775838136673\n",
            "epoch: 220, train_error(A): 0.102855384349823, test_error(B): 0.08869427442550659, B-A: -0.014161109924316406\n",
            "epoch: 222, train_error(A): 0.10261775553226471, test_error(B): 0.0886257067322731, B-A: -0.013992048799991608\n",
            "epoch: 224, train_error(A): 0.10238245129585266, test_error(B): 0.08857689797878265, B-A: -0.013805553317070007\n",
            "epoch: 226, train_error(A): 0.10215044766664505, test_error(B): 0.08854419738054276, B-A: -0.013606250286102295\n",
            "epoch: 228, train_error(A): 0.10192245990037918, test_error(B): 0.0885285809636116, B-A: -0.013393878936767578\n",
            "epoch: 230, train_error(A): 0.10169859975576401, test_error(B): 0.08853108435869217, B-A: -0.013167515397071838\n",
            "epoch: 232, train_error(A): 0.1014779806137085, test_error(B): 0.08854475617408752, B-A: -0.012933224439620972\n",
            "epoch: 234, train_error(A): 0.10125900059938431, test_error(B): 0.088567353785038, B-A: -0.012691646814346313\n",
            "epoch: 236, train_error(A): 0.10104051977396011, test_error(B): 0.088594950735569, B-A: -0.012445569038391113\n",
            "epoch: 238, train_error(A): 0.1008216142654419, test_error(B): 0.08862020075321198, B-A: -0.01220141351222992\n",
            "epoch: 240, train_error(A): 0.10060060024261475, test_error(B): 0.088643379509449, B-A: -0.011957220733165741\n",
            "epoch: 242, train_error(A): 0.10037602484226227, test_error(B): 0.08866439759731293, B-A: -0.01171162724494934\n",
            "epoch: 244, train_error(A): 0.10014567524194717, test_error(B): 0.08868008852005005, B-A: -0.011465586721897125\n",
            "epoch: 246, train_error(A): 0.0999075397849083, test_error(B): 0.08868730068206787, B-A: -0.011220239102840424\n",
            "epoch: 248, train_error(A): 0.09965960681438446, test_error(B): 0.08868055790662766, B-A: -0.010979048907756805\n",
            "epoch: 250, train_error(A): 0.09939730912446976, test_error(B): 0.08865047246217728, B-A: -0.01074683666229248\n",
            "epoch: 252, train_error(A): 0.09911496192216873, test_error(B): 0.08858314156532288, B-A: -0.010531820356845856\n",
            "epoch: 254, train_error(A): 0.09880602359771729, test_error(B): 0.08847139775753021, B-A: -0.010334625840187073\n",
            "epoch: 256, train_error(A): 0.0984611064195633, test_error(B): 0.0883326530456543, B-A: -0.010128453373908997\n",
            "epoch: 258, train_error(A): 0.09808487445116043, test_error(B): 0.0881982296705246, B-A: -0.009886644780635834\n",
            "epoch: 260, train_error(A): 0.09761498868465424, test_error(B): 0.0876590833067894, B-A: -0.009955905377864838\n",
            "epoch: 262, train_error(A): 0.09714063256978989, test_error(B): 0.087385393679142, B-A: -0.009755238890647888\n",
            "epoch: 264, train_error(A): 0.0965564176440239, test_error(B): 0.0877455323934555, B-A: -0.00881088525056839\n",
            "epoch: 266, train_error(A): 0.09587016701698303, test_error(B): 0.08746093511581421, B-A: -0.008409231901168823\n",
            "epoch: 268, train_error(A): 0.09498360008001328, test_error(B): 0.08606944233179092, B-A: -0.008914157748222351\n",
            "epoch: 270, train_error(A): 0.09404736012220383, test_error(B): 0.08548165112733841, B-A: -0.008565708994865417\n",
            "epoch: 272, train_error(A): 0.09291904419660568, test_error(B): 0.08590791374444962, B-A: -0.007011130452156067\n",
            "epoch: 274, train_error(A): 0.09146244078874588, test_error(B): 0.08490028977394104, B-A: -0.00656215101480484\n",
            "epoch: 276, train_error(A): 0.0898236483335495, test_error(B): 0.08343135565519333, B-A: -0.006392292678356171\n",
            "epoch: 278, train_error(A): 0.08768293261528015, test_error(B): 0.08273962140083313, B-A: -0.0049433112144470215\n",
            "epoch: 280, train_error(A): 0.08499332517385483, test_error(B): 0.08076824247837067, B-A: -0.004225082695484161\n",
            "epoch: 282, train_error(A): 0.08137832581996918, test_error(B): 0.07896999269723892, B-A: -0.002408333122730255\n",
            "epoch: 284, train_error(A): 0.07664288580417633, test_error(B): 0.07536160200834274, B-A: -0.0012812837958335876\n",
            "epoch: 286, train_error(A): 0.0708707720041275, test_error(B): 0.07355039566755295, B-A: 0.0026796236634254456\n",
            "epoch: 288, train_error(A): 0.06660224497318268, test_error(B): 0.07560250908136368, B-A: 0.009000264108181\n",
            "epoch: 290, train_error(A): 0.06219758093357086, test_error(B): 0.07157622277736664, B-A: 0.009378641843795776\n",
            "epoch: 292, train_error(A): 0.06025252491235733, test_error(B): 0.0685640200972557, B-A: 0.008311495184898376\n",
            "epoch: 294, train_error(A): 0.05911124870181084, test_error(B): 0.07584235817193985, B-A: 0.016731109470129013\n",
            "epoch: 296, train_error(A): 0.05906623974442482, test_error(B): 0.07306123524904251, B-A: 0.013994995504617691\n",
            "epoch: 298, train_error(A): 0.0597086064517498, test_error(B): 0.07497286051511765, B-A: 0.015264254063367844\n",
            "epoch: 300, train_error(A): 0.05984509363770485, test_error(B): 0.0783068984746933, B-A: 0.01846180483698845\n",
            "epoch: 302, train_error(A): 0.05945206433534622, test_error(B): 0.07852794975042343, B-A: 0.01907588541507721\n",
            "epoch: 304, train_error(A): 0.0584091953933239, test_error(B): 0.07489029318094254, B-A: 0.016481097787618637\n",
            "epoch: 306, train_error(A): 0.05774926766753197, test_error(B): 0.0723470151424408, B-A: 0.014597747474908829\n",
            "epoch: 308, train_error(A): 0.0574340745806694, test_error(B): 0.07399854063987732, B-A: 0.016564466059207916\n",
            "epoch: 310, train_error(A): 0.05738991126418114, test_error(B): 0.07171642035245895, B-A: 0.014326509088277817\n",
            "epoch: 312, train_error(A): 0.05745501071214676, test_error(B): 0.07156763225793839, B-A: 0.014112621545791626\n",
            "epoch: 314, train_error(A): 0.05744662508368492, test_error(B): 0.07193191349506378, B-A: 0.01448528841137886\n",
            "epoch: 316, train_error(A): 0.057322800159454346, test_error(B): 0.07043715566396713, B-A: 0.013114355504512787\n",
            "epoch: 318, train_error(A): 0.05712562054395676, test_error(B): 0.07221212238073349, B-A: 0.015086501836776733\n",
            "epoch: 320, train_error(A): 0.056921396404504776, test_error(B): 0.07081526517868042, B-A: 0.013893868774175644\n",
            "epoch: 322, train_error(A): 0.056779853999614716, test_error(B): 0.07245391607284546, B-A: 0.015674062073230743\n",
            "epoch: 324, train_error(A): 0.056744396686553955, test_error(B): 0.0728081464767456, B-A: 0.01606374979019165\n",
            "epoch: 326, train_error(A): 0.05677979066967964, test_error(B): 0.07237693667411804, B-A: 0.0155971460044384\n",
            "epoch: 328, train_error(A): 0.056787602603435516, test_error(B): 0.0738590657711029, B-A: 0.01707146316766739\n",
            "epoch: 330, train_error(A): 0.05674225464463234, test_error(B): 0.07300344854593277, B-A: 0.01626119390130043\n",
            "epoch: 332, train_error(A): 0.056686438620090485, test_error(B): 0.07265347987413406, B-A: 0.01596704125404358\n",
            "epoch: 334, train_error(A): 0.056622546166181564, test_error(B): 0.07322147488594055, B-A: 0.016598928719758987\n",
            "epoch: 336, train_error(A): 0.056559786200523376, test_error(B): 0.0723230391740799, B-A: 0.01576325297355652\n",
            "epoch: 338, train_error(A): 0.05652745068073273, test_error(B): 0.07222436368465424, B-A: 0.01569691300392151\n",
            "epoch: 340, train_error(A): 0.05651543661952019, test_error(B): 0.07253709435462952, B-A: 0.01602165773510933\n",
            "epoch: 342, train_error(A): 0.05649852007627487, test_error(B): 0.07189559936523438, B-A: 0.015397079288959503\n",
            "epoch: 344, train_error(A): 0.0564752034842968, test_error(B): 0.07204844802618027, B-A: 0.015573244541883469\n",
            "epoch: 346, train_error(A): 0.05645071342587471, test_error(B): 0.07226327061653137, B-A: 0.015812557190656662\n",
            "epoch: 348, train_error(A): 0.056422699242830276, test_error(B): 0.07189824432134628, B-A: 0.015475545078516006\n",
            "epoch: 350, train_error(A): 0.0563926175236702, test_error(B): 0.0723809078335762, B-A: 0.015988290309906006\n",
            "epoch: 352, train_error(A): 0.056368548423051834, test_error(B): 0.07254435122013092, B-A: 0.016175802797079086\n",
            "epoch: 354, train_error(A): 0.056349825114011765, test_error(B): 0.07237986475229263, B-A: 0.01603003963828087\n",
            "epoch: 356, train_error(A): 0.056330639868974686, test_error(B): 0.07278749346733093, B-A: 0.016456853598356247\n",
            "epoch: 358, train_error(A): 0.056313253939151764, test_error(B): 0.07278716564178467, B-A: 0.016473911702632904\n",
            "epoch: 360, train_error(A): 0.05629700794816017, test_error(B): 0.07260288298130035, B-A: 0.016305875033140182\n",
            "epoch: 362, train_error(A): 0.056279152631759644, test_error(B): 0.07280169427394867, B-A: 0.016522541642189026\n",
            "epoch: 364, train_error(A): 0.05626205727458, test_error(B): 0.07278989255428314, B-A: 0.01652783527970314\n",
            "epoch: 366, train_error(A): 0.05624554678797722, test_error(B): 0.07262305170297623, B-A: 0.016377504914999008\n",
            "epoch: 368, train_error(A): 0.056229978799819946, test_error(B): 0.0726722925901413, B-A: 0.01644231379032135\n",
            "epoch: 370, train_error(A): 0.05621655657887459, test_error(B): 0.07269077748060226, B-A: 0.016474220901727676\n",
            "epoch: 372, train_error(A): 0.056203439831733704, test_error(B): 0.07255982607603073, B-A: 0.016356386244297028\n",
            "epoch: 374, train_error(A): 0.05619035288691521, test_error(B): 0.07257229834794998, B-A: 0.016381945461034775\n",
            "epoch: 376, train_error(A): 0.056177571415901184, test_error(B): 0.07268425822257996, B-A: 0.016506686806678772\n",
            "epoch: 378, train_error(A): 0.05616467818617821, test_error(B): 0.07264015078544617, B-A: 0.01647547259926796\n",
            "epoch: 380, train_error(A): 0.05615222454071045, test_error(B): 0.07265469431877136, B-A: 0.016502469778060913\n",
            "epoch: 382, train_error(A): 0.056140001863241196, test_error(B): 0.07278135418891907, B-A: 0.01664135232567787\n",
            "epoch: 384, train_error(A): 0.056128062307834625, test_error(B): 0.07277043908834457, B-A: 0.01664237678050995\n",
            "epoch: 386, train_error(A): 0.056116655468940735, test_error(B): 0.07275296747684479, B-A: 0.016636312007904053\n",
            "epoch: 388, train_error(A): 0.05610533431172371, test_error(B): 0.07283641397953033, B-A: 0.016731079667806625\n",
            "epoch: 390, train_error(A): 0.056094177067279816, test_error(B): 0.07285531610250473, B-A: 0.016761139035224915\n",
            "epoch: 392, train_error(A): 0.05608310550451279, test_error(B): 0.07282009720802307, B-A: 0.016736991703510284\n",
            "epoch: 394, train_error(A): 0.056072186678647995, test_error(B): 0.07283099740743637, B-A: 0.016758810728788376\n",
            "epoch: 396, train_error(A): 0.05606148764491081, test_error(B): 0.07285140454769135, B-A: 0.016789916902780533\n",
            "epoch: 398, train_error(A): 0.056050918996334076, test_error(B): 0.07283078879117966, B-A: 0.01677986979484558\n",
            "epoch: 400, train_error(A): 0.056040581315755844, test_error(B): 0.07280997186899185, B-A: 0.016769390553236008\n",
            "epoch: 402, train_error(A): 0.05603037774562836, test_error(B): 0.07283501327037811, B-A: 0.016804635524749756\n",
            "epoch: 404, train_error(A): 0.05602032318711281, test_error(B): 0.0728561133146286, B-A: 0.016835790127515793\n",
            "epoch: 406, train_error(A): 0.05601035803556442, test_error(B): 0.07284358143806458, B-A: 0.016833223402500153\n",
            "epoch: 408, train_error(A): 0.05600053817033768, test_error(B): 0.07285280525684357, B-A: 0.01685226708650589\n",
            "epoch: 410, train_error(A): 0.05599083751440048, test_error(B): 0.07288850098848343, B-A: 0.016897663474082947\n",
            "epoch: 412, train_error(A): 0.05598125606775284, test_error(B): 0.07290259748697281, B-A: 0.01692134141921997\n",
            "epoch: 414, train_error(A): 0.05597180128097534, test_error(B): 0.07290449738502502, B-A: 0.016932696104049683\n",
            "epoch: 416, train_error(A): 0.0559624508023262, test_error(B): 0.07292067259550095, B-A: 0.016958221793174744\n",
            "epoch: 418, train_error(A): 0.055953189730644226, test_error(B): 0.07294154167175293, B-A: 0.016988351941108704\n",
            "epoch: 420, train_error(A): 0.055944010615348816, test_error(B): 0.07294926047325134, B-A: 0.017005249857902527\n",
            "epoch: 422, train_error(A): 0.05593490973114967, test_error(B): 0.07294722646474838, B-A: 0.01701231673359871\n",
            "epoch: 424, train_error(A): 0.0559258833527565, test_error(B): 0.07295341789722443, B-A: 0.017027534544467926\n",
            "epoch: 426, train_error(A): 0.0559169240295887, test_error(B): 0.07296827435493469, B-A: 0.017051350325345993\n",
            "epoch: 428, train_error(A): 0.05590803176164627, test_error(B): 0.07297543436288834, B-A: 0.017067402601242065\n",
            "epoch: 430, train_error(A): 0.05589919537305832, test_error(B): 0.07297592610120773, B-A: 0.017076730728149414\n",
            "epoch: 432, train_error(A): 0.05589042231440544, test_error(B): 0.07298336923122406, B-A: 0.01709294691681862\n",
            "epoch: 434, train_error(A): 0.05588170140981674, test_error(B): 0.07299710065126419, B-A: 0.01711539924144745\n",
            "epoch: 436, train_error(A): 0.05587304010987282, test_error(B): 0.07300891727209091, B-A: 0.017135877162218094\n",
            "epoch: 438, train_error(A): 0.05586443468928337, test_error(B): 0.07301689684391022, B-A: 0.017152462154626846\n",
            "epoch: 440, train_error(A): 0.055855873972177505, test_error(B): 0.07302482426166534, B-A: 0.01716895028948784\n",
            "epoch: 442, train_error(A): 0.05584735423326492, test_error(B): 0.0730365514755249, B-A: 0.01718919724225998\n",
            "epoch: 444, train_error(A): 0.055838871747255325, test_error(B): 0.07304932177066803, B-A: 0.017210450023412704\n",
            "epoch: 446, train_error(A): 0.05583043023943901, test_error(B): 0.07305809110403061, B-A: 0.0172276608645916\n",
            "epoch: 448, train_error(A): 0.05582201108336449, test_error(B): 0.07306449115276337, B-A: 0.01724248006939888\n",
            "epoch: 450, train_error(A): 0.055813632905483246, test_error(B): 0.07307236641645432, B-A: 0.01725873351097107\n",
            "epoch: 452, train_error(A): 0.05580528825521469, test_error(B): 0.07308167964220047, B-A: 0.01727639138698578\n",
            "epoch: 454, train_error(A): 0.05579697713255882, test_error(B): 0.07308981567621231, B-A: 0.017292838543653488\n",
            "epoch: 456, train_error(A): 0.05578869581222534, test_error(B): 0.07309505343437195, B-A: 0.017306357622146606\n",
            "epoch: 458, train_error(A): 0.05578045919537544, test_error(B): 0.07309745997190475, B-A: 0.017317000776529312\n",
            "epoch: 460, train_error(A): 0.055772241204977036, test_error(B): 0.07309908419847488, B-A: 0.01732684299349785\n",
            "epoch: 462, train_error(A): 0.055764034390449524, test_error(B): 0.07310168445110321, B-A: 0.017337650060653687\n",
            "epoch: 464, train_error(A): 0.05575583130121231, test_error(B): 0.07310508191585541, B-A: 0.017349250614643097\n",
            "epoch: 466, train_error(A): 0.055747635662555695, test_error(B): 0.073108971118927, B-A: 0.017361335456371307\n",
            "epoch: 468, train_error(A): 0.05573943257331848, test_error(B): 0.07311344146728516, B-A: 0.017374008893966675\n",
            "epoch: 470, train_error(A): 0.05573121830821037, test_error(B): 0.0731184333562851, B-A: 0.017387215048074722\n",
            "epoch: 472, train_error(A): 0.05572301521897316, test_error(B): 0.07312360405921936, B-A: 0.0174005888402462\n",
            "epoch: 474, train_error(A): 0.055714789777994156, test_error(B): 0.07312855869531631, B-A: 0.01741376891732216\n",
            "epoch: 476, train_error(A): 0.05570657178759575, test_error(B): 0.07313269376754761, B-A: 0.01742612197995186\n",
            "epoch: 478, train_error(A): 0.05569835007190704, test_error(B): 0.07313743978738785, B-A: 0.017439089715480804\n",
            "epoch: 480, train_error(A): 0.05569013953208923, test_error(B): 0.07314145565032959, B-A: 0.017451316118240356\n",
            "epoch: 482, train_error(A): 0.05568194016814232, test_error(B): 0.07314562052488327, B-A: 0.01746368035674095\n",
            "epoch: 484, train_error(A): 0.055673748254776, test_error(B): 0.07315263152122498, B-A: 0.017478883266448975\n",
            "epoch: 486, train_error(A): 0.05566556379199028, test_error(B): 0.07315953820943832, B-A: 0.017493974417448044\n",
            "epoch: 488, train_error(A): 0.05565739423036575, test_error(B): 0.07316583395004272, B-A: 0.01750843971967697\n",
            "epoch: 490, train_error(A): 0.055649224668741226, test_error(B): 0.07317133992910385, B-A: 0.017522115260362625\n",
            "epoch: 492, train_error(A): 0.055641058832407, test_error(B): 0.07317671924829483, B-A: 0.017535660415887833\n",
            "epoch: 494, train_error(A): 0.05563288927078247, test_error(B): 0.07318250089883804, B-A: 0.017549611628055573\n",
            "epoch: 496, train_error(A): 0.055624693632125854, test_error(B): 0.07318839430809021, B-A: 0.017563700675964355\n",
            "epoch: 498, train_error(A): 0.055616460740566254, test_error(B): 0.0731930136680603, B-A: 0.01757655292749405\n",
            "epoch: 500, train_error(A): 0.055608201771974564, test_error(B): 0.07319553196430206, B-A: 0.0175873301923275\n",
            "epoch: 502, train_error(A): 0.055599913001060486, test_error(B): 0.07319620996713638, B-A: 0.017596296966075897\n",
            "epoch: 504, train_error(A): 0.0555916428565979, test_error(B): 0.07319586724042892, B-A: 0.017604224383831024\n",
            "epoch: 506, train_error(A): 0.055583395063877106, test_error(B): 0.07319515198469162, B-A: 0.017611756920814514\n",
            "epoch: 508, train_error(A): 0.055575188249349594, test_error(B): 0.07319429516792297, B-A: 0.01761910691857338\n",
            "epoch: 510, train_error(A): 0.055567048490047455, test_error(B): 0.07319364696741104, B-A: 0.017626598477363586\n",
            "epoch: 512, train_error(A): 0.055559009313583374, test_error(B): 0.07319346070289612, B-A: 0.017634451389312744\n",
            "epoch: 514, train_error(A): 0.05555109679698944, test_error(B): 0.07319425046443939, B-A: 0.01764315366744995\n",
            "epoch: 516, train_error(A): 0.055543333292007446, test_error(B): 0.07319682091474533, B-A: 0.017653487622737885\n",
            "epoch: 518, train_error(A): 0.055535752326250076, test_error(B): 0.07320281863212585, B-A: 0.017667066305875778\n",
            "epoch: 520, train_error(A): 0.055528365075588226, test_error(B): 0.07321519404649734, B-A: 0.01768682897090912\n",
            "epoch: 522, train_error(A): 0.05552119389176369, test_error(B): 0.0732402428984642, B-A: 0.017719049006700516\n",
            "epoch: 524, train_error(A): 0.055514466017484665, test_error(B): 0.07329156249761581, B-A: 0.01777709648013115\n",
            "epoch: 526, train_error(A): 0.055509161204099655, test_error(B): 0.07339905202388763, B-A: 0.01788989081978798\n",
            "epoch: 528, train_error(A): 0.055510085076093674, test_error(B): 0.0736360177397728, B-A: 0.018125932663679123\n",
            "epoch: 530, train_error(A): 0.05553937703371048, test_error(B): 0.07416024804115295, B-A: 0.018620871007442474\n",
            "epoch: 532, train_error(A): 0.055671922862529755, test_error(B): 0.07517670094966888, B-A: 0.01950477808713913\n",
            "epoch: 534, train_error(A): 0.055818166583776474, test_error(B): 0.07587692141532898, B-A: 0.020058754831552505\n",
            "epoch: 536, train_error(A): 0.055535826832056046, test_error(B): 0.07408814132213593, B-A: 0.01855231449007988\n",
            "epoch: 538, train_error(A): 0.05557551980018616, test_error(B): 0.07176481187343597, B-A: 0.016189292073249817\n",
            "epoch: 540, train_error(A): 0.055580854415893555, test_error(B): 0.07190585881471634, B-A: 0.016325004398822784\n",
            "epoch: 542, train_error(A): 0.05547913908958435, test_error(B): 0.07374487072229385, B-A: 0.018265731632709503\n",
            "epoch: 544, train_error(A): 0.05554814636707306, test_error(B): 0.0744016170501709, B-A: 0.01885347068309784\n",
            "epoch: 546, train_error(A): 0.055450476706027985, test_error(B): 0.07304114103317261, B-A: 0.017590664327144623\n",
            "epoch: 548, train_error(A): 0.0555095449090004, test_error(B): 0.07218693941831589, B-A: 0.01667739450931549\n",
            "epoch: 550, train_error(A): 0.055436212569475174, test_error(B): 0.07317336648702621, B-A: 0.01773715391755104\n",
            "epoch: 552, train_error(A): 0.055473215878009796, test_error(B): 0.07419195771217346, B-A: 0.018718741834163666\n",
            "epoch: 554, train_error(A): 0.05542569234967232, test_error(B): 0.0734729990363121, B-A: 0.018047306686639786\n",
            "epoch: 556, train_error(A): 0.05544701963663101, test_error(B): 0.07254794985055923, B-A: 0.017100930213928223\n",
            "epoch: 558, train_error(A): 0.05541687086224556, test_error(B): 0.07303699851036072, B-A: 0.017620127648115158\n",
            "epoch: 560, train_error(A): 0.05542220547795296, test_error(B): 0.07379625737667084, B-A: 0.01837405189871788\n",
            "epoch: 562, train_error(A): 0.055407941341400146, test_error(B): 0.07352887094020844, B-A: 0.01812092959880829\n",
            "epoch: 564, train_error(A): 0.055404119193553925, test_error(B): 0.07291944324970245, B-A: 0.01751532405614853\n",
            "epoch: 566, train_error(A): 0.055397432297468185, test_error(B): 0.0729755163192749, B-A: 0.017578084021806717\n",
            "epoch: 568, train_error(A): 0.05538928881287575, test_error(B): 0.07346687465906143, B-A: 0.018077585846185684\n",
            "epoch: 570, train_error(A): 0.055386438965797424, test_error(B): 0.07359573245048523, B-A: 0.018209293484687805\n",
            "epoch: 572, train_error(A): 0.055376384407281876, test_error(B): 0.07322034239768982, B-A: 0.017843957990407944\n",
            "epoch: 574, train_error(A): 0.055375322699546814, test_error(B): 0.07301004230976105, B-A: 0.017634719610214233\n",
            "epoch: 576, train_error(A): 0.055365294218063354, test_error(B): 0.07330352813005447, B-A: 0.01793823391199112\n",
            "epoch: 578, train_error(A): 0.05536333844065666, test_error(B): 0.07357687503099442, B-A: 0.018213536590337753\n",
            "epoch: 580, train_error(A): 0.055355630815029144, test_error(B): 0.07342779636383057, B-A: 0.018072165548801422\n",
            "epoch: 582, train_error(A): 0.05535130575299263, test_error(B): 0.07318361848592758, B-A: 0.017832312732934952\n",
            "epoch: 584, train_error(A): 0.055346209555864334, test_error(B): 0.07320872694253922, B-A: 0.01786251738667488\n",
            "epoch: 586, train_error(A): 0.055340077728033066, test_error(B): 0.07339685410261154, B-A: 0.018056776374578476\n",
            "epoch: 588, train_error(A): 0.05533615127205849, test_error(B): 0.07348273694515228, B-A: 0.018146585673093796\n",
            "epoch: 590, train_error(A): 0.055330000817775726, test_error(B): 0.0733884647488594, B-A: 0.01805846393108368\n",
            "epoch: 592, train_error(A): 0.05532556027173996, test_error(B): 0.07326029241085052, B-A: 0.017934732139110565\n",
            "epoch: 594, train_error(A): 0.05532044172286987, test_error(B): 0.073275126516819, B-A: 0.017954684793949127\n",
            "epoch: 596, train_error(A): 0.055315155535936356, test_error(B): 0.07340692728757858, B-A: 0.018091771751642227\n",
            "epoch: 598, train_error(A): 0.055310651659965515, test_error(B): 0.07347505539655685, B-A: 0.01816440373659134\n",
            "epoch: 600, train_error(A): 0.055305350571870804, test_error(B): 0.07341766357421875, B-A: 0.018112313002347946\n",
            "epoch: 602, train_error(A): 0.055300552397966385, test_error(B): 0.07334448397159576, B-A: 0.01804393157362938\n",
            "epoch: 604, train_error(A): 0.05529576912522316, test_error(B): 0.07334315031766891, B-A: 0.018047381192445755\n",
            "epoch: 606, train_error(A): 0.05529065802693367, test_error(B): 0.07340041548013687, B-A: 0.0181097574532032\n",
            "epoch: 608, train_error(A): 0.055285897105932236, test_error(B): 0.07345845550298691, B-A: 0.018172558397054672\n",
            "epoch: 610, train_error(A): 0.055281005799770355, test_error(B): 0.07346790283918381, B-A: 0.018186897039413452\n",
            "epoch: 612, train_error(A): 0.055275995284318924, test_error(B): 0.0734296441078186, B-A: 0.01815364882349968\n",
            "epoch: 614, train_error(A): 0.055271148681640625, test_error(B): 0.07339620590209961, B-A: 0.018125057220458984\n",
            "epoch: 616, train_error(A): 0.055266182869672775, test_error(B): 0.07340613752603531, B-A: 0.018139954656362534\n",
            "epoch: 618, train_error(A): 0.05526112765073776, test_error(B): 0.07344404608011246, B-A: 0.018182918429374695\n",
            "epoch: 620, train_error(A): 0.05525611340999603, test_error(B): 0.07347588241100311, B-A: 0.01821976900100708\n",
            "epoch: 622, train_error(A): 0.05525101721286774, test_error(B): 0.07348647713661194, B-A: 0.0182354599237442\n",
            "epoch: 624, train_error(A): 0.0552457794547081, test_error(B): 0.07347777485847473, B-A: 0.018231995403766632\n",
            "epoch: 626, train_error(A): 0.055240485817193985, test_error(B): 0.07346144318580627, B-A: 0.01822095736861229\n",
            "epoch: 628, train_error(A): 0.0552351139485836, test_error(B): 0.07345489412546158, B-A: 0.018219780176877975\n",
            "epoch: 630, train_error(A): 0.055229589343070984, test_error(B): 0.07346545159816742, B-A: 0.018235862255096436\n",
            "epoch: 632, train_error(A): 0.05522394925355911, test_error(B): 0.07348347455263138, B-A: 0.018259525299072266\n",
            "epoch: 634, train_error(A): 0.05521821230649948, test_error(B): 0.07349745184183121, B-A: 0.018279239535331726\n",
            "epoch: 636, train_error(A): 0.055212412029504776, test_error(B): 0.0735030248761177, B-A: 0.01829061284661293\n",
            "epoch: 638, train_error(A): 0.055206604301929474, test_error(B): 0.07350078970193863, B-A: 0.018294185400009155\n",
            "epoch: 640, train_error(A): 0.05520081892609596, test_error(B): 0.07349275797605515, B-A: 0.018291939049959183\n",
            "epoch: 642, train_error(A): 0.055195070803165436, test_error(B): 0.07348413020372391, B-A: 0.01828905940055847\n",
            "epoch: 644, train_error(A): 0.05518939718604088, test_error(B): 0.07347975671291351, B-A: 0.018290359526872635\n",
            "epoch: 646, train_error(A): 0.055183831602334976, test_error(B): 0.07347917556762695, B-A: 0.018295343965291977\n",
            "epoch: 648, train_error(A): 0.055178429931402206, test_error(B): 0.07348039001226425, B-A: 0.018301960080862045\n",
            "epoch: 650, train_error(A): 0.05517321452498436, test_error(B): 0.07348362356424332, B-A: 0.018310409039258957\n",
            "epoch: 652, train_error(A): 0.05516817420721054, test_error(B): 0.07348865270614624, B-A: 0.0183204784989357\n",
            "epoch: 654, train_error(A): 0.05516325682401657, test_error(B): 0.07349352538585663, B-A: 0.018330268561840057\n",
            "epoch: 656, train_error(A): 0.05515844002366066, test_error(B): 0.07349766045808792, B-A: 0.01833922043442726\n",
            "epoch: 658, train_error(A): 0.055153682827949524, test_error(B): 0.07350185513496399, B-A: 0.018348172307014465\n",
            "epoch: 660, train_error(A): 0.055148959159851074, test_error(B): 0.0735064223408699, B-A: 0.01835746318101883\n",
            "epoch: 662, train_error(A): 0.05514425039291382, test_error(B): 0.07351124286651611, B-A: 0.018366992473602295\n",
            "epoch: 664, train_error(A): 0.05513956770300865, test_error(B): 0.07351646572351456, B-A: 0.018376898020505905\n",
            "epoch: 666, train_error(A): 0.055134911090135574, test_error(B): 0.07352267950773239, B-A: 0.018387768417596817\n",
            "epoch: 668, train_error(A): 0.05513029173016548, test_error(B): 0.07353067398071289, B-A: 0.01840038225054741\n",
            "epoch: 670, train_error(A): 0.05512571334838867, test_error(B): 0.07354012876749039, B-A: 0.018414415419101715\n",
            "epoch: 672, train_error(A): 0.05512116104364395, test_error(B): 0.07355110347270966, B-A: 0.018429942429065704\n",
            "epoch: 674, train_error(A): 0.055116672068834305, test_error(B): 0.07356525212526321, B-A: 0.01844858005642891\n",
            "epoch: 676, train_error(A): 0.05511223524808884, test_error(B): 0.07358546555042267, B-A: 0.018473230302333832\n",
            "epoch: 678, train_error(A): 0.05510793253779411, test_error(B): 0.07361570000648499, B-A: 0.018507767468690872\n",
            "epoch: 680, train_error(A): 0.055103909224271774, test_error(B): 0.07366450130939484, B-A: 0.018560592085123062\n",
            "epoch: 682, train_error(A): 0.05510077252984047, test_error(B): 0.07374967634677887, B-A: 0.0186489038169384\n",
            "epoch: 684, train_error(A): 0.055100612342357635, test_error(B): 0.07390597462654114, B-A: 0.018805362284183502\n",
            "epoch: 686, train_error(A): 0.05511008948087692, test_error(B): 0.07418748736381531, B-A: 0.019077397882938385\n",
            "epoch: 688, train_error(A): 0.05514824762940407, test_error(B): 0.07467373460531235, B-A: 0.01952548697590828\n",
            "epoch: 690, train_error(A): 0.05525313690304756, test_error(B): 0.07541995495557785, B-A: 0.02016681805253029\n",
            "epoch: 692, train_error(A): 0.055374082177877426, test_error(B): 0.07599297910928726, B-A: 0.020618896931409836\n",
            "epoch: 694, train_error(A): 0.055221911519765854, test_error(B): 0.07514491677284241, B-A: 0.019923005253076553\n",
            "epoch: 696, train_error(A): 0.05508047342300415, test_error(B): 0.07310427725315094, B-A: 0.01802380383014679\n",
            "epoch: 698, train_error(A): 0.05521079897880554, test_error(B): 0.07212074100971222, B-A: 0.016909942030906677\n",
            "epoch: 700, train_error(A): 0.05509550869464874, test_error(B): 0.07282024621963501, B-A: 0.017724737524986267\n",
            "epoch: 702, train_error(A): 0.0550977922976017, test_error(B): 0.07430053502321243, B-A: 0.019202742725610733\n",
            "epoch: 704, train_error(A): 0.0551246777176857, test_error(B): 0.07471606135368347, B-A: 0.019591383635997772\n",
            "epoch: 706, train_error(A): 0.055050432682037354, test_error(B): 0.07368198037147522, B-A: 0.018631547689437866\n",
            "epoch: 708, train_error(A): 0.05509575083851814, test_error(B): 0.07272990047931671, B-A: 0.01763414964079857\n",
            "epoch: 710, train_error(A): 0.055061642080545425, test_error(B): 0.07309623807668686, B-A: 0.018034595996141434\n",
            "epoch: 712, train_error(A): 0.05504796653985977, test_error(B): 0.07410085946321487, B-A: 0.019052892923355103\n",
            "epoch: 714, train_error(A): 0.05506365746259689, test_error(B): 0.0743512287735939, B-A: 0.01928757131099701\n",
            "epoch: 716, train_error(A): 0.05503081530332565, test_error(B): 0.07370921224355698, B-A: 0.018678396940231323\n",
            "epoch: 718, train_error(A): 0.05504322797060013, test_error(B): 0.07311755418777466, B-A: 0.01807432621717453\n",
            "epoch: 720, train_error(A): 0.05503141134977341, test_error(B): 0.07321716099977493, B-A: 0.018185749650001526\n",
            "epoch: 722, train_error(A): 0.055021073669195175, test_error(B): 0.07380129396915436, B-A: 0.018780220299959183\n",
            "epoch: 724, train_error(A): 0.05502566695213318, test_error(B): 0.0740848183631897, B-A: 0.01905915141105652\n",
            "epoch: 726, train_error(A): 0.05501128360629082, test_error(B): 0.07375696301460266, B-A: 0.018745679408311844\n",
            "epoch: 728, train_error(A): 0.05501206964254379, test_error(B): 0.07335371524095535, B-A: 0.01834164559841156\n",
            "epoch: 730, train_error(A): 0.055007241666316986, test_error(B): 0.07341164350509644, B-A: 0.01840440183877945\n",
            "epoch: 732, train_error(A): 0.054999228566884995, test_error(B): 0.07374906539916992, B-A: 0.018749836832284927\n",
            "epoch: 734, train_error(A): 0.05499916896224022, test_error(B): 0.07393418997526169, B-A: 0.01893502101302147\n",
            "epoch: 736, train_error(A): 0.054992374032735825, test_error(B): 0.07382498681545258, B-A: 0.01883261278271675\n",
            "epoch: 738, train_error(A): 0.05498795211315155, test_error(B): 0.07358074188232422, B-A: 0.01859278976917267\n",
            "epoch: 740, train_error(A): 0.05498567968606949, test_error(B): 0.07347387820482254, B-A: 0.018488198518753052\n",
            "epoch: 742, train_error(A): 0.05497968941926956, test_error(B): 0.07360871881246567, B-A: 0.018629029393196106\n",
            "epoch: 744, train_error(A): 0.05497616156935692, test_error(B): 0.07379854470491409, B-A: 0.018822383135557175\n",
            "epoch: 746, train_error(A): 0.054972726851701736, test_error(B): 0.07382935285568237, B-A: 0.018856626003980637\n",
            "epoch: 748, train_error(A): 0.054967623203992844, test_error(B): 0.07371864467859268, B-A: 0.018751021474599838\n",
            "epoch: 750, train_error(A): 0.05496402457356453, test_error(B): 0.07361074537038803, B-A: 0.0186467207968235\n",
            "epoch: 752, train_error(A): 0.05496024712920189, test_error(B): 0.0735943540930748, B-A: 0.01863410696387291\n",
            "epoch: 754, train_error(A): 0.0549556165933609, test_error(B): 0.07367155700922012, B-A: 0.018715940415859222\n",
            "epoch: 756, train_error(A): 0.0549517385661602, test_error(B): 0.07377034425735474, B-A: 0.018818605691194534\n",
            "epoch: 758, train_error(A): 0.05494789779186249, test_error(B): 0.07380024343729019, B-A: 0.018852345645427704\n",
            "epoch: 760, train_error(A): 0.0549435056746006, test_error(B): 0.07375016808509827, B-A: 0.018806662410497665\n",
            "epoch: 762, train_error(A): 0.0549393929541111, test_error(B): 0.073685422539711, B-A: 0.0187460295855999\n",
            "epoch: 764, train_error(A): 0.05493546649813652, test_error(B): 0.07365813106298447, B-A: 0.018722664564847946\n",
            "epoch: 766, train_error(A): 0.054931238293647766, test_error(B): 0.07367482781410217, B-A: 0.018743589520454407\n",
            "epoch: 768, train_error(A): 0.05492698401212692, test_error(B): 0.07371968775987625, B-A: 0.01879270374774933\n",
            "epoch: 770, train_error(A): 0.05492289736866951, test_error(B): 0.0737624391913414, B-A: 0.01883954182267189\n",
            "epoch: 772, train_error(A): 0.05491875484585762, test_error(B): 0.07377468794584274, B-A: 0.018855933099985123\n",
            "epoch: 774, train_error(A): 0.054914478212594986, test_error(B): 0.07375747710466385, B-A: 0.018842998892068863\n",
            "epoch: 776, train_error(A): 0.054910220205783844, test_error(B): 0.07373326271772385, B-A: 0.018823042511940002\n",
            "epoch: 778, train_error(A): 0.05490601062774658, test_error(B): 0.07371751219034195, B-A: 0.018811501562595367\n",
            "epoch: 780, train_error(A): 0.05490175262093544, test_error(B): 0.07371493428945541, B-A: 0.018813181668519974\n",
            "epoch: 782, train_error(A): 0.05489744246006012, test_error(B): 0.07372689992189407, B-A: 0.018829457461833954\n",
            "epoch: 784, train_error(A): 0.0548931285738945, test_error(B): 0.07374803721904755, B-A: 0.018854908645153046\n",
            "epoch: 786, train_error(A): 0.05488883703947067, test_error(B): 0.07376696169376373, B-A: 0.01887812465429306\n",
            "epoch: 788, train_error(A): 0.05488455295562744, test_error(B): 0.07377751916646957, B-A: 0.018892966210842133\n",
            "epoch: 790, train_error(A): 0.05488024279475212, test_error(B): 0.07378146797418594, B-A: 0.018901225179433823\n",
            "epoch: 792, train_error(A): 0.05487590655684471, test_error(B): 0.07378063350915909, B-A: 0.018904726952314377\n",
            "epoch: 794, train_error(A): 0.054871562868356705, test_error(B): 0.07377593219280243, B-A: 0.018904369324445724\n",
            "epoch: 796, train_error(A): 0.0548672117292881, test_error(B): 0.07377063482999802, B-A: 0.018903423100709915\n",
            "epoch: 798, train_error(A): 0.0548628531396389, test_error(B): 0.07376807183027267, B-A: 0.018905218690633774\n",
            "epoch: 800, train_error(A): 0.054858479648828506, test_error(B): 0.07376810163259506, B-A: 0.018909621983766556\n",
            "epoch: 802, train_error(A): 0.054854072630405426, test_error(B): 0.07376926392316818, B-A: 0.018915191292762756\n",
            "epoch: 804, train_error(A): 0.05484964698553085, test_error(B): 0.07377158850431442, B-A: 0.01892194151878357\n",
            "epoch: 806, train_error(A): 0.05484519526362419, test_error(B): 0.07377510517835617, B-A: 0.01892990991473198\n",
            "epoch: 808, train_error(A): 0.05484071746468544, test_error(B): 0.07377860695123672, B-A: 0.018937889486551285\n",
            "epoch: 810, train_error(A): 0.0548362098634243, test_error(B): 0.0737810730934143, B-A: 0.018944863229990005\n",
            "epoch: 812, train_error(A): 0.05483167991042137, test_error(B): 0.0737827941775322, B-A: 0.018951114267110825\n",
            "epoch: 814, train_error(A): 0.054827116429805756, test_error(B): 0.07378365844488144, B-A: 0.018956542015075684\n",
            "epoch: 816, train_error(A): 0.05482253059744835, test_error(B): 0.0737825334072113, B-A: 0.018960002809762955\n",
            "epoch: 818, train_error(A): 0.05481792613863945, test_error(B): 0.07377807796001434, B-A: 0.018960151821374893\n",
            "epoch: 820, train_error(A): 0.05481332167983055, test_error(B): 0.07376864552497864, B-A: 0.018955323845148087\n",
            "epoch: 822, train_error(A): 0.054808761924505234, test_error(B): 0.07375078648328781, B-A: 0.018942024558782578\n",
            "epoch: 824, train_error(A): 0.05480439215898514, test_error(B): 0.07371831685304642, B-A: 0.01891392469406128\n",
            "epoch: 826, train_error(A): 0.0548006109893322, test_error(B): 0.07365970313549042, B-A: 0.01885909214615822\n",
            "epoch: 828, train_error(A): 0.054798685014247894, test_error(B): 0.07355385273694992, B-A: 0.018755167722702026\n",
            "epoch: 830, train_error(A): 0.05480262264609337, test_error(B): 0.07336296886205673, B-A: 0.018560346215963364\n",
            "epoch: 832, train_error(A): 0.05482517555356026, test_error(B): 0.07302241027355194, B-A: 0.018197234719991684\n",
            "epoch: 834, train_error(A): 0.05490696430206299, test_error(B): 0.07242391258478165, B-A: 0.01751694828271866\n",
            "epoch: 836, train_error(A): 0.055126629769802094, test_error(B): 0.07155437022447586, B-A: 0.016427740454673767\n",
            "epoch: 838, train_error(A): 0.05528149753808975, test_error(B): 0.07113267481327057, B-A: 0.015851177275180817\n",
            "epoch: 840, train_error(A): 0.05484411120414734, test_error(B): 0.07276538759469986, B-A: 0.01792127639055252\n",
            "epoch: 842, train_error(A): 0.05490358546376228, test_error(B): 0.07532112300395966, B-A: 0.020417537540197372\n",
            "epoch: 844, train_error(A): 0.054926030337810516, test_error(B): 0.0753493458032608, B-A: 0.020423315465450287\n",
            "epoch: 846, train_error(A): 0.05477446690201759, test_error(B): 0.0732114240527153, B-A: 0.018436957150697708\n",
            "epoch: 848, train_error(A): 0.054889414459466934, test_error(B): 0.07241028547286987, B-A: 0.01752087101340294\n",
            "epoch: 850, train_error(A): 0.0547432042658329, test_error(B): 0.0737711638212204, B-A: 0.019027959555387497\n",
            "epoch: 852, train_error(A): 0.05483061820268631, test_error(B): 0.07517589628696442, B-A: 0.020345278084278107\n",
            "epoch: 854, train_error(A): 0.054747506976127625, test_error(B): 0.07445875555276871, B-A: 0.019711248576641083\n",
            "epoch: 856, train_error(A): 0.05477336421608925, test_error(B): 0.07305952906608582, B-A: 0.018286164849996567\n",
            "epoch: 858, train_error(A): 0.05474952235817909, test_error(B): 0.07327639311552048, B-A: 0.018526870757341385\n",
            "epoch: 860, train_error(A): 0.05473288148641586, test_error(B): 0.07442329823970795, B-A: 0.019690416753292084\n",
            "epoch: 862, train_error(A): 0.05474064126610756, test_error(B): 0.07451336830854416, B-A: 0.0197727270424366\n",
            "epoch: 864, train_error(A): 0.05471131578087807, test_error(B): 0.0736316442489624, B-A: 0.018920328468084335\n",
            "epoch: 866, train_error(A): 0.05472555011510849, test_error(B): 0.07332649827003479, B-A: 0.0186009481549263\n",
            "epoch: 868, train_error(A): 0.054698459804058075, test_error(B): 0.073908731341362, B-A: 0.019210271537303925\n",
            "epoch: 870, train_error(A): 0.05470852181315422, test_error(B): 0.07440730929374695, B-A: 0.019698787480592728\n",
            "epoch: 872, train_error(A): 0.054689742624759674, test_error(B): 0.0740884318947792, B-A: 0.01939868927001953\n",
            "epoch: 874, train_error(A): 0.054691776633262634, test_error(B): 0.07359012961387634, B-A: 0.01889835298061371\n",
            "epoch: 876, train_error(A): 0.05468199774622917, test_error(B): 0.07372219860553741, B-A: 0.019040200859308243\n",
            "epoch: 878, train_error(A): 0.05467650294303894, test_error(B): 0.0741686224937439, B-A: 0.019492119550704956\n",
            "epoch: 880, train_error(A): 0.05467325076460838, test_error(B): 0.07419969141483307, B-A: 0.019526440650224686\n",
            "epoch: 882, train_error(A): 0.054664112627506256, test_error(B): 0.0738733783364296, B-A: 0.01920926570892334\n",
            "epoch: 884, train_error(A): 0.05466264486312866, test_error(B): 0.07372575253248215, B-A: 0.019063107669353485\n",
            "epoch: 886, train_error(A): 0.054654043167829514, test_error(B): 0.07390371710062027, B-A: 0.019249673932790756\n",
            "epoch: 888, train_error(A): 0.05465076118707657, test_error(B): 0.07413063943386078, B-A: 0.01947987824678421\n",
            "epoch: 890, train_error(A): 0.05464490130543709, test_error(B): 0.0741100087761879, B-A: 0.01946510747075081\n",
            "epoch: 892, train_error(A): 0.054639142006635666, test_error(B): 0.07390818744897842, B-A: 0.019269045442342758\n",
            "epoch: 894, train_error(A): 0.05463508889079094, test_error(B): 0.07383354008197784, B-A: 0.019198451191186905\n",
            "epoch: 896, train_error(A): 0.054628655314445496, test_error(B): 0.0739663690328598, B-A: 0.019337713718414307\n",
            "epoch: 898, train_error(A): 0.05462416633963585, test_error(B): 0.07409179955720901, B-A: 0.019467633217573166\n",
            "epoch: 900, train_error(A): 0.054618723690509796, test_error(B): 0.07406724989414215, B-A: 0.019448526203632355\n",
            "epoch: 902, train_error(A): 0.05461307242512703, test_error(B): 0.0739685446023941, B-A: 0.019355472177267075\n",
            "epoch: 904, train_error(A): 0.05460825935006142, test_error(B): 0.07392100989818573, B-A: 0.019312750548124313\n",
            "epoch: 906, train_error(A): 0.05460255965590477, test_error(B): 0.07397088408470154, B-A: 0.019368324428796768\n",
            "epoch: 908, train_error(A): 0.054597340524196625, test_error(B): 0.07406134903430939, B-A: 0.019464008510112762\n",
            "epoch: 910, train_error(A): 0.05459222570061684, test_error(B): 0.07409051060676575, B-A: 0.01949828490614891\n",
            "epoch: 912, train_error(A): 0.054586783051490784, test_error(B): 0.07404136657714844, B-A: 0.019454583525657654\n",
            "epoch: 914, train_error(A): 0.05458177998661995, test_error(B): 0.07399533689022064, B-A: 0.019413556903600693\n",
            "epoch: 916, train_error(A): 0.05457676202058792, test_error(B): 0.07400505244731903, B-A: 0.01942829042673111\n",
            "epoch: 918, train_error(A): 0.054571669548749924, test_error(B): 0.07404812425374985, B-A: 0.019476454704999924\n",
            "epoch: 920, train_error(A): 0.05456684157252312, test_error(B): 0.07408525049686432, B-A: 0.019518408924341202\n",
            "epoch: 922, train_error(A): 0.05456195026636124, test_error(B): 0.07409132272005081, B-A: 0.019529372453689575\n",
            "epoch: 924, train_error(A): 0.05455699935555458, test_error(B): 0.07406605780124664, B-A: 0.019509058445692062\n",
            "epoch: 926, train_error(A): 0.054552145302295685, test_error(B): 0.07404159754514694, B-A: 0.019489452242851257\n",
            "epoch: 928, train_error(A): 0.05454721301794052, test_error(B): 0.074046790599823, B-A: 0.019499577581882477\n",
            "epoch: 930, train_error(A): 0.054542213678359985, test_error(B): 0.07407234609127045, B-A: 0.01953013241291046\n",
            "epoch: 932, train_error(A): 0.05453725531697273, test_error(B): 0.07409366220235825, B-A: 0.019556406885385513\n",
            "epoch: 934, train_error(A): 0.05453229695558548, test_error(B): 0.07410210371017456, B-A: 0.01956980675458908\n",
            "epoch: 936, train_error(A): 0.054527293890714645, test_error(B): 0.07409818470478058, B-A: 0.019570890814065933\n",
            "epoch: 938, train_error(A): 0.05452228710055351, test_error(B): 0.07408700883388519, B-A: 0.01956472173333168\n",
            "epoch: 940, train_error(A): 0.054517269134521484, test_error(B): 0.07408107072114944, B-A: 0.01956380158662796\n",
            "epoch: 942, train_error(A): 0.054512202739715576, test_error(B): 0.07408830523490906, B-A: 0.01957610249519348\n",
            "epoch: 944, train_error(A): 0.05450711026787758, test_error(B): 0.07410291582345963, B-A: 0.019595805555582047\n",
            "epoch: 946, train_error(A): 0.05450201779603958, test_error(B): 0.07411695271730423, B-A: 0.01961493492126465\n",
            "epoch: 948, train_error(A): 0.05449695512652397, test_error(B): 0.07412897050380707, B-A: 0.019632015377283096\n",
            "epoch: 950, train_error(A): 0.054491929709911346, test_error(B): 0.07413648813962936, B-A: 0.019644558429718018\n",
            "epoch: 952, train_error(A): 0.0544869489967823, test_error(B): 0.07413855195045471, B-A: 0.01965160295367241\n",
            "epoch: 954, train_error(A): 0.054482024163007736, test_error(B): 0.07413886487483978, B-A: 0.019656840711832047\n",
            "epoch: 956, train_error(A): 0.054477132856845856, test_error(B): 0.07414042204618454, B-A: 0.019663289189338684\n",
            "epoch: 958, train_error(A): 0.05447227880358696, test_error(B): 0.07414364069700241, B-A: 0.01967136189341545\n",
            "epoch: 960, train_error(A): 0.054467491805553436, test_error(B): 0.07414814084768295, B-A: 0.019680649042129517\n",
            "epoch: 962, train_error(A): 0.05446278676390648, test_error(B): 0.07415413111448288, B-A: 0.0196913443505764\n",
            "epoch: 964, train_error(A): 0.05445815250277519, test_error(B): 0.07416193932294846, B-A: 0.019703786820173264\n",
            "epoch: 966, train_error(A): 0.05445356294512749, test_error(B): 0.07417017221450806, B-A: 0.01971660926938057\n",
            "epoch: 968, train_error(A): 0.05444899946451187, test_error(B): 0.07417749613523483, B-A: 0.01972849667072296\n",
            "epoch: 970, train_error(A): 0.05444445088505745, test_error(B): 0.07418442517518997, B-A: 0.019739974290132523\n",
            "epoch: 972, train_error(A): 0.05443992838263512, test_error(B): 0.07419143617153168, B-A: 0.01975150778889656\n",
            "epoch: 974, train_error(A): 0.054435424506664276, test_error(B): 0.07419764995574951, B-A: 0.019762225449085236\n",
            "epoch: 976, train_error(A): 0.054430924355983734, test_error(B): 0.07420327514410019, B-A: 0.019772350788116455\n",
            "epoch: 978, train_error(A): 0.054426439106464386, test_error(B): 0.07420925796031952, B-A: 0.019782818853855133\n",
            "epoch: 980, train_error(A): 0.05442197620868683, test_error(B): 0.07421568036079407, B-A: 0.01979370415210724\n",
            "epoch: 982, train_error(A): 0.05441753566265106, test_error(B): 0.07422235608100891, B-A: 0.01980482041835785\n",
            "epoch: 984, train_error(A): 0.05441310256719589, test_error(B): 0.07422954589128494, B-A: 0.01981644332408905\n",
            "epoch: 986, train_error(A): 0.05440869554877281, test_error(B): 0.07423805445432663, B-A: 0.019829358905553818\n",
            "epoch: 988, train_error(A): 0.05440431088209152, test_error(B): 0.0742487758398056, B-A: 0.01984446495771408\n",
            "epoch: 990, train_error(A): 0.05439995601773262, test_error(B): 0.07426288723945618, B-A: 0.019862931221723557\n",
            "epoch: 992, train_error(A): 0.054395660758018494, test_error(B): 0.07428281754255295, B-A: 0.019887156784534454\n",
            "epoch: 994, train_error(A): 0.0543915256857872, test_error(B): 0.07431355118751526, B-A: 0.019922025501728058\n",
            "epoch: 996, train_error(A): 0.054387837648391724, test_error(B): 0.07436413317918777, B-A: 0.01997629553079605\n",
            "epoch: 998, train_error(A): 0.054385554045438766, test_error(B): 0.07445118576288223, B-A: 0.020065631717443466\n",
            "epoch: 1000, train_error(A): 0.05438787490129471, test_error(B): 0.0746077373623848, B-A: 0.020219862461090088\n",
            "epoch: 1002, train_error(A): 0.054405614733695984, test_error(B): 0.07489559054374695, B-A: 0.020489975810050964\n",
            "epoch: 1004, train_error(A): 0.0544738806784153, test_error(B): 0.075432687997818, B-A: 0.020958807319402695\n",
            "epoch: 1006, train_error(A): 0.05465743690729141, test_error(B): 0.07626847922801971, B-A: 0.021611042320728302\n",
            "epoch: 1008, train_error(A): 0.05481560155749321, test_error(B): 0.07684055715799332, B-A: 0.022024955600500107\n",
            "epoch: 1010, train_error(A): 0.05449914559721947, test_error(B): 0.0757066011428833, B-A: 0.021207455545663834\n",
            "epoch: 1012, train_error(A): 0.05440346896648407, test_error(B): 0.07344953715801239, B-A: 0.01904606819152832\n",
            "epoch: 1014, train_error(A): 0.05456939712166786, test_error(B): 0.07250455766916275, B-A: 0.01793516054749489\n",
            "epoch: 1016, train_error(A): 0.05436543747782707, test_error(B): 0.07380899041891098, B-A: 0.019443552941083908\n",
            "epoch: 1018, train_error(A): 0.05443637818098068, test_error(B): 0.07541008293628693, B-A: 0.020973704755306244\n",
            "epoch: 1020, train_error(A): 0.05441618710756302, test_error(B): 0.07529803365468979, B-A: 0.02088184654712677\n",
            "epoch: 1022, train_error(A): 0.05434482544660568, test_error(B): 0.07405630499124527, B-A: 0.019711479544639587\n",
            "epoch: 1024, train_error(A): 0.05440623685717583, test_error(B): 0.07335148006677628, B-A: 0.01894524320960045\n",
            "epoch: 1026, train_error(A): 0.05433041229844093, test_error(B): 0.07403163611888885, B-A: 0.019701223820447922\n",
            "epoch: 1028, train_error(A): 0.054360806941986084, test_error(B): 0.07510598748922348, B-A: 0.020745180547237396\n",
            "epoch: 1030, train_error(A): 0.05433911085128784, test_error(B): 0.0748610720038414, B-A: 0.02052196115255356\n",
            "epoch: 1032, train_error(A): 0.05432332679629326, test_error(B): 0.07388810813426971, B-A: 0.019564781337976456\n",
            "epoch: 1034, train_error(A): 0.05433579906821251, test_error(B): 0.0737842544913292, B-A: 0.019448455423116684\n",
            "epoch: 1036, train_error(A): 0.054307274520397186, test_error(B): 0.07436815649271011, B-A: 0.020060881972312927\n",
            "epoch: 1038, train_error(A): 0.054318878799676895, test_error(B): 0.07477658241987228, B-A: 0.02045770362019539\n",
            "epoch: 1040, train_error(A): 0.05430367588996887, test_error(B): 0.07462106645107269, B-A: 0.02031739056110382\n",
            "epoch: 1042, train_error(A): 0.054300080984830856, test_error(B): 0.07415946573019028, B-A: 0.01985938474535942\n",
            "epoch: 1044, train_error(A): 0.05430026724934578, test_error(B): 0.07401028275489807, B-A: 0.019710015505552292\n",
            "epoch: 1046, train_error(A): 0.0542876310646534, test_error(B): 0.0743677020072937, B-A: 0.020080070942640305\n",
            "epoch: 1048, train_error(A): 0.054289549589157104, test_error(B): 0.07468656450510025, B-A: 0.020397014915943146\n",
            "epoch: 1050, train_error(A): 0.0542822927236557, test_error(B): 0.0745752677321434, B-A: 0.0202929750084877\n",
            "epoch: 1052, train_error(A): 0.05427710711956024, test_error(B): 0.07427442818880081, B-A: 0.01999732106924057\n",
            "epoch: 1054, train_error(A): 0.0542760007083416, test_error(B): 0.07420136779546738, B-A: 0.019925367087125778\n",
            "epoch: 1056, train_error(A): 0.054268885403871536, test_error(B): 0.07435600459575653, B-A: 0.020087119191884995\n",
            "epoch: 1058, train_error(A): 0.05426599457859993, test_error(B): 0.07452896982431412, B-A: 0.020262975245714188\n",
            "epoch: 1060, train_error(A): 0.05426286160945892, test_error(B): 0.07458481192588806, B-A: 0.020321950316429138\n",
            "epoch: 1062, train_error(A): 0.05425727367401123, test_error(B): 0.07448187470436096, B-A: 0.02022460103034973\n",
            "epoch: 1064, train_error(A): 0.05425428971648216, test_error(B): 0.07432866096496582, B-A: 0.020074371248483658\n",
            "epoch: 1066, train_error(A): 0.05425072833895683, test_error(B): 0.07432785630226135, B-A: 0.02007712796330452\n",
            "epoch: 1068, train_error(A): 0.05424601584672928, test_error(B): 0.07443908601999283, B-A: 0.02019307017326355\n",
            "epoch: 1070, train_error(A): 0.05424262955784798, test_error(B): 0.07451546937227249, B-A: 0.020272839814424515\n",
            "epoch: 1072, train_error(A): 0.0542391762137413, test_error(B): 0.0745355635881424, B-A: 0.020296387374401093\n",
            "epoch: 1074, train_error(A): 0.054234910756349564, test_error(B): 0.07450711727142334, B-A: 0.020272206515073776\n",
            "epoch: 1076, train_error(A): 0.054231174290180206, test_error(B): 0.07444185018539429, B-A: 0.02021067589521408\n",
            "epoch: 1078, train_error(A): 0.05422778055071831, test_error(B): 0.07440172135829926, B-A: 0.020173940807580948\n",
            "epoch: 1080, train_error(A): 0.05422396957874298, test_error(B): 0.07442241162061691, B-A: 0.020198442041873932\n",
            "epoch: 1082, train_error(A): 0.0542200468480587, test_error(B): 0.07447420060634613, B-A: 0.02025415375828743\n",
            "epoch: 1084, train_error(A): 0.054216381162405014, test_error(B): 0.0745108500123024, B-A: 0.020294468849897385\n",
            "epoch: 1086, train_error(A): 0.05421283841133118, test_error(B): 0.07453180104494095, B-A: 0.02031896263360977\n",
            "epoch: 1088, train_error(A): 0.0542091503739357, test_error(B): 0.07454447448253632, B-A: 0.020335324108600616\n",
            "epoch: 1090, train_error(A): 0.05420537292957306, test_error(B): 0.07453184574842453, B-A: 0.02032647281885147\n",
            "epoch: 1092, train_error(A): 0.054201655089855194, test_error(B): 0.0745069682598114, B-A: 0.020305313169956207\n",
            "epoch: 1094, train_error(A): 0.0541980154812336, test_error(B): 0.07449370622634888, B-A: 0.02029569074511528\n",
            "epoch: 1096, train_error(A): 0.05419442057609558, test_error(B): 0.07448800653219223, B-A: 0.02029358595609665\n",
            "epoch: 1098, train_error(A): 0.05419082194566727, test_error(B): 0.0744839757680893, B-A: 0.020293153822422028\n",
            "epoch: 1100, train_error(A): 0.05418719723820686, test_error(B): 0.07448270171880722, B-A: 0.020295504480600357\n",
            "epoch: 1102, train_error(A): 0.05418356880545616, test_error(B): 0.07448767870664597, B-A: 0.020304109901189804\n",
            "epoch: 1104, train_error(A): 0.054179947823286057, test_error(B): 0.07449348270893097, B-A: 0.020313534885644913\n",
            "epoch: 1106, train_error(A): 0.054176364094018936, test_error(B): 0.07449187338352203, B-A: 0.020315509289503098\n",
            "epoch: 1108, train_error(A): 0.054172832518815994, test_error(B): 0.0744868814945221, B-A: 0.0203140489757061\n",
            "epoch: 1110, train_error(A): 0.05416939780116081, test_error(B): 0.07447859644889832, B-A: 0.020309198647737503\n",
            "epoch: 1112, train_error(A): 0.05416618287563324, test_error(B): 0.07445870339870453, B-A: 0.02029252052307129\n",
            "epoch: 1114, train_error(A): 0.05416344478726387, test_error(B): 0.07441938668489456, B-A: 0.02025594189763069\n",
            "epoch: 1116, train_error(A): 0.054161932319402695, test_error(B): 0.0743512213230133, B-A: 0.02018928900361061\n",
            "epoch: 1118, train_error(A): 0.054163653403520584, test_error(B): 0.07423871755599976, B-A: 0.020075064152479172\n",
            "epoch: 1120, train_error(A): 0.0541745126247406, test_error(B): 0.07404617965221405, B-A: 0.01987166702747345\n",
            "epoch: 1122, train_error(A): 0.05421041324734688, test_error(B): 0.07372196018695831, B-A: 0.019511546939611435\n",
            "epoch: 1124, train_error(A): 0.054302699863910675, test_error(B): 0.07322873175144196, B-A: 0.01892603188753128\n",
            "epoch: 1126, train_error(A): 0.05444103479385376, test_error(B): 0.07270701974630356, B-A: 0.0182659849524498\n",
            "epoch: 1128, train_error(A): 0.05441334843635559, test_error(B): 0.07269394397735596, B-A: 0.018280595541000366\n",
            "epoch: 1130, train_error(A): 0.0541703887283802, test_error(B): 0.07383044809103012, B-A: 0.019660059362649918\n",
            "epoch: 1132, train_error(A): 0.05418727546930313, test_error(B): 0.07540247589349747, B-A: 0.021215200424194336\n",
            "epoch: 1134, train_error(A): 0.05428297072649002, test_error(B): 0.07596254348754883, B-A: 0.021679572761058807\n",
            "epoch: 1136, train_error(A): 0.05416492000222206, test_error(B): 0.07522742450237274, B-A: 0.02106250450015068\n",
            "epoch: 1138, train_error(A): 0.05414123088121414, test_error(B): 0.07414315640926361, B-A: 0.02000192552804947\n",
            "epoch: 1140, train_error(A): 0.05420391634106636, test_error(B): 0.07356423139572144, B-A: 0.019360315054655075\n",
            "epoch: 1142, train_error(A): 0.054145168513059616, test_error(B): 0.07392020523548126, B-A: 0.019775036722421646\n",
            "epoch: 1144, train_error(A): 0.054120469838380814, test_error(B): 0.07487054914236069, B-A: 0.020750079303979874\n",
            "epoch: 1146, train_error(A): 0.054156601428985596, test_error(B): 0.07539726048707962, B-A: 0.021240659058094025\n",
            "epoch: 1148, train_error(A): 0.05412658303976059, test_error(B): 0.07506053894758224, B-A: 0.020933955907821655\n",
            "epoch: 1150, train_error(A): 0.054106127470731735, test_error(B): 0.07439223676919937, B-A: 0.020286109298467636\n",
            "epoch: 1152, train_error(A): 0.05412427335977554, test_error(B): 0.07406428456306458, B-A: 0.019940011203289032\n",
            "epoch: 1154, train_error(A): 0.054111678153276443, test_error(B): 0.07420660555362701, B-A: 0.02009492740035057\n",
            "epoch: 1156, train_error(A): 0.054095298051834106, test_error(B): 0.07462015002965927, B-A: 0.020524851977825165\n",
            "epoch: 1158, train_error(A): 0.05410238355398178, test_error(B): 0.07498276233673096, B-A: 0.020880378782749176\n",
            "epoch: 1160, train_error(A): 0.054099150002002716, test_error(B): 0.0749962329864502, B-A: 0.02089708298444748\n",
            "epoch: 1162, train_error(A): 0.05408661067485809, test_error(B): 0.07469767332077026, B-A: 0.02061106264591217\n",
            "epoch: 1164, train_error(A): 0.05408545210957527, test_error(B): 0.07441350072622299, B-A: 0.02032804861664772\n",
            "epoch: 1166, train_error(A): 0.05408674478530884, test_error(B): 0.07432373613119125, B-A: 0.020236991345882416\n",
            "epoch: 1168, train_error(A): 0.05408033728599548, test_error(B): 0.07441047579050064, B-A: 0.020330138504505157\n",
            "epoch: 1170, train_error(A): 0.05407366156578064, test_error(B): 0.07458264380693436, B-A: 0.020508982241153717\n",
            "epoch: 1172, train_error(A): 0.054071780294179916, test_error(B): 0.07476907968521118, B-A: 0.020697299391031265\n",
            "epoch: 1174, train_error(A): 0.054070837795734406, test_error(B): 0.07487320899963379, B-A: 0.020802371203899384\n",
            "epoch: 1176, train_error(A): 0.05406716465950012, test_error(B): 0.07484143227338791, B-A: 0.020774267613887787\n",
            "epoch: 1178, train_error(A): 0.05406216159462929, test_error(B): 0.07474926859140396, B-A: 0.020687106996774673\n",
            "epoch: 1180, train_error(A): 0.054058197885751724, test_error(B): 0.07466087490320206, B-A: 0.020602677017450333\n",
            "epoch: 1182, train_error(A): 0.054055649787187576, test_error(B): 0.07457626610994339, B-A: 0.020520616322755814\n",
            "epoch: 1184, train_error(A): 0.054053474217653275, test_error(B): 0.07451440393924713, B-A: 0.020460929721593857\n",
            "epoch: 1186, train_error(A): 0.054050907492637634, test_error(B): 0.07450000941753387, B-A: 0.02044910192489624\n",
            "epoch: 1188, train_error(A): 0.05404786020517349, test_error(B): 0.07451758533716202, B-A: 0.020469725131988525\n",
            "epoch: 1190, train_error(A): 0.054044581949710846, test_error(B): 0.07453019917011261, B-A: 0.020485617220401764\n",
            "epoch: 1192, train_error(A): 0.0540412962436676, test_error(B): 0.07453572750091553, B-A: 0.020494431257247925\n",
            "epoch: 1194, train_error(A): 0.05403812602162361, test_error(B): 0.07454879581928253, B-A: 0.02051066979765892\n",
            "epoch: 1196, train_error(A): 0.05403514206409454, test_error(B): 0.07455538213253021, B-A: 0.02052024006843567\n",
            "epoch: 1198, train_error(A): 0.05403243377804756, test_error(B): 0.0745423436164856, B-A: 0.020509909838438034\n",
            "epoch: 1200, train_error(A): 0.05403018742799759, test_error(B): 0.07451075315475464, B-A: 0.02048056572675705\n",
            "epoch: 1202, train_error(A): 0.05402900278568268, test_error(B): 0.07445662468671799, B-A: 0.02042762190103531\n",
            "epoch: 1204, train_error(A): 0.054030440747737885, test_error(B): 0.07435908913612366, B-A: 0.020328648388385773\n",
            "epoch: 1206, train_error(A): 0.054038338363170624, test_error(B): 0.07419227808713913, B-A: 0.020153939723968506\n",
            "epoch: 1208, train_error(A): 0.0540616437792778, test_error(B): 0.07393251359462738, B-A: 0.01987086981534958\n",
            "epoch: 1210, train_error(A): 0.05411788076162338, test_error(B): 0.07355087250471115, B-A: 0.01943299174308777\n",
            "epoch: 1212, train_error(A): 0.054216284304857254, test_error(B): 0.07308054715394974, B-A: 0.018864262849092484\n",
            "epoch: 1214, train_error(A): 0.054274361580610275, test_error(B): 0.07282321155071259, B-A: 0.01854884997010231\n",
            "epoch: 1216, train_error(A): 0.054142244160175323, test_error(B): 0.0733007863163948, B-A: 0.019158542156219482\n",
            "epoch: 1218, train_error(A): 0.05400577560067177, test_error(B): 0.0745241567492485, B-A: 0.020518381148576736\n",
            "epoch: 1220, train_error(A): 0.054067373275756836, test_error(B): 0.0756116583943367, B-A: 0.021544285118579865\n",
            "epoch: 1222, train_error(A): 0.05411316081881523, test_error(B): 0.07591337710618973, B-A: 0.021800216287374496\n",
            "epoch: 1224, train_error(A): 0.0540291853249073, test_error(B): 0.07539500296115875, B-A: 0.02136581763625145\n",
            "epoch: 1226, train_error(A): 0.053996916860342026, test_error(B): 0.07450486719608307, B-A: 0.020507950335741043\n",
            "epoch: 1228, train_error(A): 0.054042089730501175, test_error(B): 0.07382255792617798, B-A: 0.019780468195676804\n",
            "epoch: 1230, train_error(A): 0.054033562541007996, test_error(B): 0.07383584976196289, B-A: 0.019802287220954895\n",
            "epoch: 1232, train_error(A): 0.053988296538591385, test_error(B): 0.0744398981332779, B-A: 0.020451601594686508\n",
            "epoch: 1234, train_error(A): 0.05399318411946297, test_error(B): 0.07506664842367172, B-A: 0.021073464304208755\n",
            "epoch: 1236, train_error(A): 0.054009098559617996, test_error(B): 0.0753084272146225, B-A: 0.0212993286550045\n",
            "epoch: 1238, train_error(A): 0.05399039387702942, test_error(B): 0.07512463629245758, B-A: 0.02113424241542816\n",
            "epoch: 1240, train_error(A): 0.05397428572177887, test_error(B): 0.07470893859863281, B-A: 0.020734652876853943\n",
            "epoch: 1242, train_error(A): 0.053981419652700424, test_error(B): 0.07432182133197784, B-A: 0.02034040167927742\n",
            "epoch: 1244, train_error(A): 0.053983185440301895, test_error(B): 0.07421902567148209, B-A: 0.02023584023118019\n",
            "epoch: 1246, train_error(A): 0.053970612585544586, test_error(B): 0.07443220168352127, B-A: 0.020461589097976685\n",
            "epoch: 1248, train_error(A): 0.053963735699653625, test_error(B): 0.0747307687997818, B-A: 0.020767033100128174\n",
            "epoch: 1250, train_error(A): 0.05396576598286629, test_error(B): 0.07494174689054489, B-A: 0.020975980907678604\n",
            "epoch: 1252, train_error(A): 0.05396550893783569, test_error(B): 0.07500999420881271, B-A: 0.02104448527097702\n",
            "epoch: 1254, train_error(A): 0.053959477692842484, test_error(B): 0.07494279742240906, B-A: 0.020983319729566574\n",
            "epoch: 1256, train_error(A): 0.053953368216753006, test_error(B): 0.07477189600467682, B-A: 0.020818527787923813\n",
            "epoch: 1258, train_error(A): 0.053950827568769455, test_error(B): 0.07460014522075653, B-A: 0.020649317651987076\n",
            "epoch: 1260, train_error(A): 0.05395004153251648, test_error(B): 0.07451032847166061, B-A: 0.020560286939144135\n",
            "epoch: 1262, train_error(A): 0.05394821986556053, test_error(B): 0.07448713481426239, B-A: 0.02053891494870186\n",
            "epoch: 1264, train_error(A): 0.05394473671913147, test_error(B): 0.07450550049543381, B-A: 0.020560763776302338\n",
            "epoch: 1266, train_error(A): 0.05394074320793152, test_error(B): 0.07456669956445694, B-A: 0.02062595635652542\n",
            "epoch: 1268, train_error(A): 0.05393726006150246, test_error(B): 0.07465445250272751, B-A: 0.020717192441225052\n",
            "epoch: 1270, train_error(A): 0.05393456295132637, test_error(B): 0.07472843676805496, B-A: 0.020793873816728592\n",
            "epoch: 1272, train_error(A): 0.05393234267830849, test_error(B): 0.07477875053882599, B-A: 0.020846407860517502\n",
            "epoch: 1274, train_error(A): 0.05393029376864433, test_error(B): 0.07482284307479858, B-A: 0.02089254930615425\n",
            "epoch: 1276, train_error(A): 0.053928352892398834, test_error(B): 0.07486195117235184, B-A: 0.020933598279953003\n",
            "epoch: 1278, train_error(A): 0.05392662063241005, test_error(B): 0.07489538192749023, B-A: 0.020968761295080185\n",
            "epoch: 1280, train_error(A): 0.053925368934869766, test_error(B): 0.07493796199560165, B-A: 0.021012593060731888\n",
            "epoch: 1282, train_error(A): 0.05392519384622574, test_error(B): 0.07500577718019485, B-A: 0.021080583333969116\n",
            "epoch: 1284, train_error(A): 0.053927358239889145, test_error(B): 0.07510960102081299, B-A: 0.021182242780923843\n",
            "epoch: 1286, train_error(A): 0.05393463745713234, test_error(B): 0.0752633735537529, B-A: 0.02132873609662056\n",
            "epoch: 1288, train_error(A): 0.05395202338695526, test_error(B): 0.0754820853471756, B-A: 0.021530061960220337\n",
            "epoch: 1290, train_error(A): 0.05398587882518768, test_error(B): 0.07576663047075272, B-A: 0.021780751645565033\n",
            "epoch: 1292, train_error(A): 0.05403510853648186, test_error(B): 0.07607580721378326, B-A: 0.022040698677301407\n",
            "epoch: 1294, train_error(A): 0.05406652018427849, test_error(B): 0.07624892890453339, B-A: 0.022182408720254898\n",
            "epoch: 1296, train_error(A): 0.054022595286369324, test_error(B): 0.07601959258317947, B-A: 0.02199699729681015\n",
            "epoch: 1298, train_error(A): 0.053930655121803284, test_error(B): 0.07534533739089966, B-A: 0.021414682269096375\n",
            "epoch: 1300, train_error(A): 0.053897012025117874, test_error(B): 0.07456538081169128, B-A: 0.02066836878657341\n",
            "epoch: 1302, train_error(A): 0.0539296455681324, test_error(B): 0.0739765614271164, B-A: 0.020046915858983994\n",
            "epoch: 1304, train_error(A): 0.05395839363336563, test_error(B): 0.07370816916227341, B-A: 0.019749775528907776\n",
            "epoch: 1306, train_error(A): 0.05393977090716362, test_error(B): 0.0738186314702034, B-A: 0.01987886056303978\n",
            "epoch: 1308, train_error(A): 0.0538996122777462, test_error(B): 0.0742192491889, B-A: 0.020319636911153793\n",
            "epoch: 1310, train_error(A): 0.05388304591178894, test_error(B): 0.07469544559717178, B-A: 0.020812399685382843\n",
            "epoch: 1312, train_error(A): 0.053892359137535095, test_error(B): 0.07510130852460861, B-A: 0.021208949387073517\n",
            "epoch: 1314, train_error(A): 0.053902775049209595, test_error(B): 0.07531438022851944, B-A: 0.021411605179309845\n",
            "epoch: 1316, train_error(A): 0.0538981668651104, test_error(B): 0.07530433684587479, B-A: 0.02140616998076439\n",
            "epoch: 1318, train_error(A): 0.05388319119811058, test_error(B): 0.07511957734823227, B-A: 0.02123638615012169\n",
            "epoch: 1320, train_error(A): 0.05387109890580177, test_error(B): 0.07484763860702515, B-A: 0.020976539701223373\n",
            "epoch: 1322, train_error(A): 0.05386802554130554, test_error(B): 0.0745781883597374, B-A: 0.020710162818431854\n",
            "epoch: 1324, train_error(A): 0.053870219737291336, test_error(B): 0.07438221573829651, B-A: 0.020511996001005173\n",
            "epoch: 1326, train_error(A): 0.05387164652347565, test_error(B): 0.07429316639900208, B-A: 0.020421519875526428\n",
            "epoch: 1328, train_error(A): 0.05386969447135925, test_error(B): 0.07428760081529617, B-A: 0.02041790634393692\n",
            "epoch: 1330, train_error(A): 0.05386503413319588, test_error(B): 0.07432857900857925, B-A: 0.020463544875383377\n",
            "epoch: 1332, train_error(A): 0.0538594014942646, test_error(B): 0.07439594715833664, B-A: 0.020536545664072037\n",
            "epoch: 1334, train_error(A): 0.05385414510965347, test_error(B): 0.0744757279753685, B-A: 0.020621582865715027\n",
            "epoch: 1336, train_error(A): 0.05384979769587517, test_error(B): 0.07455118000507355, B-A: 0.02070138230919838\n",
            "epoch: 1338, train_error(A): 0.053846217691898346, test_error(B): 0.07460857927799225, B-A: 0.020762361586093903\n",
            "epoch: 1340, train_error(A): 0.05384313687682152, test_error(B): 0.0746520534157753, B-A: 0.02080891653895378\n",
            "epoch: 1342, train_error(A): 0.05384030565619469, test_error(B): 0.07468784600496292, B-A: 0.020847540348768234\n",
            "epoch: 1344, train_error(A): 0.05383758246898651, test_error(B): 0.0747160017490387, B-A: 0.020878419280052185\n",
            "epoch: 1346, train_error(A): 0.053834933787584305, test_error(B): 0.07473933696746826, B-A: 0.020904403179883957\n",
            "epoch: 1348, train_error(A): 0.05383238568902016, test_error(B): 0.07476560771465302, B-A: 0.02093322202563286\n",
            "epoch: 1350, train_error(A): 0.05383007973432541, test_error(B): 0.07480654865503311, B-A: 0.020976468920707703\n",
            "epoch: 1352, train_error(A): 0.053828466683626175, test_error(B): 0.07487191259860992, B-A: 0.02104344591498375\n",
            "epoch: 1354, train_error(A): 0.05382881686091423, test_error(B): 0.07497833669185638, B-A: 0.021149519830942154\n",
            "epoch: 1356, train_error(A): 0.05383484065532684, test_error(B): 0.0751623585820198, B-A: 0.021327517926692963\n",
            "epoch: 1358, train_error(A): 0.05385762080550194, test_error(B): 0.075491763651371, B-A: 0.021634142845869064\n",
            "epoch: 1360, train_error(A): 0.053927142173051834, test_error(B): 0.0760616734623909, B-A: 0.022134531289339066\n",
            "epoch: 1362, train_error(A): 0.05408554524183273, test_error(B): 0.07682666182518005, B-A: 0.02274111658334732\n",
            "epoch: 1364, train_error(A): 0.05422372743487358, test_error(B): 0.07722687721252441, B-A: 0.023003149777650833\n",
            "epoch: 1366, train_error(A): 0.054004520177841187, test_error(B): 0.07631032168865204, B-A: 0.022305801510810852\n",
            "epoch: 1368, train_error(A): 0.053810808807611465, test_error(B): 0.07446625828742981, B-A: 0.020655449479818344\n",
            "epoch: 1370, train_error(A): 0.05396883189678192, test_error(B): 0.07309927046298981, B-A: 0.019130438566207886\n",
            "epoch: 1372, train_error(A): 0.05394234508275986, test_error(B): 0.07314342260360718, B-A: 0.01920107752084732\n",
            "epoch: 1374, train_error(A): 0.053798116743564606, test_error(B): 0.07454835623502731, B-A: 0.020750239491462708\n",
            "epoch: 1376, train_error(A): 0.05387376621365547, test_error(B): 0.07589822262525558, B-A: 0.022024456411600113\n",
            "epoch: 1378, train_error(A): 0.053875960409641266, test_error(B): 0.07589984685182571, B-A: 0.022023886442184448\n",
            "epoch: 1380, train_error(A): 0.05379071459174156, test_error(B): 0.07471221685409546, B-A: 0.020921502262353897\n",
            "epoch: 1382, train_error(A): 0.05382968857884407, test_error(B): 0.07372578233480453, B-A: 0.019896093755960464\n",
            "epoch: 1384, train_error(A): 0.05382738262414932, test_error(B): 0.07377734035253525, B-A: 0.019949957728385925\n",
            "epoch: 1386, train_error(A): 0.053781092166900635, test_error(B): 0.0745864063501358, B-A: 0.02080531418323517\n",
            "epoch: 1388, train_error(A): 0.053803104907274246, test_error(B): 0.0753326490521431, B-A: 0.02152954414486885\n",
            "epoch: 1390, train_error(A): 0.05379730463027954, test_error(B): 0.07530832290649414, B-A: 0.0215110182762146\n",
            "epoch: 1392, train_error(A): 0.05377247929573059, test_error(B): 0.07465072721242905, B-A: 0.020878247916698456\n",
            "epoch: 1394, train_error(A): 0.05378391221165657, test_error(B): 0.07411634176969528, B-A: 0.02033242955803871\n",
            "epoch: 1396, train_error(A): 0.053778477013111115, test_error(B): 0.07416340708732605, B-A: 0.020384930074214935\n",
            "epoch: 1398, train_error(A): 0.05376391485333443, test_error(B): 0.07462437450885773, B-A: 0.0208604596555233\n",
            "epoch: 1400, train_error(A): 0.05376829952001572, test_error(B): 0.07499843090772629, B-A: 0.02123013138771057\n",
            "epoch: 1402, train_error(A): 0.05376587435603142, test_error(B): 0.07500995695590973, B-A: 0.02124408259987831\n",
            "epoch: 1404, train_error(A): 0.05375572293996811, test_error(B): 0.07473728805780411, B-A: 0.020981565117836\n",
            "epoch: 1406, train_error(A): 0.053754694759845734, test_error(B): 0.07443200796842575, B-A: 0.020677313208580017\n",
            "epoch: 1408, train_error(A): 0.0537542924284935, test_error(B): 0.07433170080184937, B-A: 0.020577408373355865\n",
            "epoch: 1410, train_error(A): 0.05374780669808388, test_error(B): 0.0744672566652298, B-A: 0.02071944996714592\n",
            "epoch: 1412, train_error(A): 0.05374358221888542, test_error(B): 0.07469463348388672, B-A: 0.020951051265001297\n",
            "epoch: 1414, train_error(A): 0.053742606192827225, test_error(B): 0.07483751326799393, B-A: 0.021094907075166702\n",
            "epoch: 1416, train_error(A): 0.0537392795085907, test_error(B): 0.07482478767633438, B-A: 0.021085508167743683\n",
            "epoch: 1418, train_error(A): 0.05373437702655792, test_error(B): 0.07470738142728806, B-A: 0.020973004400730133\n",
            "epoch: 1420, train_error(A): 0.053731102496385574, test_error(B): 0.07456967234611511, B-A: 0.020838569849729538\n",
            "epoch: 1422, train_error(A): 0.053728800266981125, test_error(B): 0.07448653131723404, B-A: 0.020757731050252914\n",
            "epoch: 1424, train_error(A): 0.05372554063796997, test_error(B): 0.07448278367519379, B-A: 0.020757243037223816\n",
            "epoch: 1426, train_error(A): 0.053721457719802856, test_error(B): 0.07454125583171844, B-A: 0.02081979811191559\n",
            "epoch: 1428, train_error(A): 0.05371770262718201, test_error(B): 0.07462697476148605, B-A: 0.020909272134304047\n",
            "epoch: 1430, train_error(A): 0.05371454358100891, test_error(B): 0.07469750195741653, B-A: 0.020982958376407623\n",
            "epoch: 1432, train_error(A): 0.0537114180624485, test_error(B): 0.07473108172416687, B-A: 0.02101966366171837\n",
            "epoch: 1434, train_error(A): 0.053707972168922424, test_error(B): 0.07472724467515945, B-A: 0.02101927250623703\n",
            "epoch: 1436, train_error(A): 0.05370431765913963, test_error(B): 0.07469933480024338, B-A: 0.020995017141103745\n",
            "epoch: 1438, train_error(A): 0.05370073765516281, test_error(B): 0.07465994358062744, B-A: 0.02095920592546463\n",
            "epoch: 1440, train_error(A): 0.05369733273983002, test_error(B): 0.07461919635534286, B-A: 0.020921863615512848\n",
            "epoch: 1442, train_error(A): 0.05369406193494797, test_error(B): 0.07458953559398651, B-A: 0.020895473659038544\n",
            "epoch: 1444, train_error(A): 0.0536908358335495, test_error(B): 0.07457134872674942, B-A: 0.02088051289319992\n",
            "epoch: 1446, train_error(A): 0.05368759483098984, test_error(B): 0.0745593011379242, B-A: 0.020871706306934357\n",
            "epoch: 1448, train_error(A): 0.053684305399656296, test_error(B): 0.07455082982778549, B-A: 0.020866524428129196\n",
            "epoch: 1450, train_error(A): 0.05368100106716156, test_error(B): 0.07454666495323181, B-A: 0.02086566388607025\n",
            "epoch: 1452, train_error(A): 0.05367767810821533, test_error(B): 0.07454591989517212, B-A: 0.020868241786956787\n",
            "epoch: 1454, train_error(A): 0.05367436632514, test_error(B): 0.07454335689544678, B-A: 0.020868990570306778\n",
            "epoch: 1456, train_error(A): 0.05367109552025795, test_error(B): 0.07453645020723343, B-A: 0.02086535468697548\n",
            "epoch: 1458, train_error(A): 0.053667884320020676, test_error(B): 0.07452201098203659, B-A: 0.020854126662015915\n",
            "epoch: 1460, train_error(A): 0.05366480350494385, test_error(B): 0.07449651509523392, B-A: 0.02083171159029007\n",
            "epoch: 1462, train_error(A): 0.05366203188896179, test_error(B): 0.07445540279150009, B-A: 0.0207933709025383\n",
            "epoch: 1464, train_error(A): 0.05365995690226555, test_error(B): 0.07439011335372925, B-A: 0.0207301564514637\n",
            "epoch: 1466, train_error(A): 0.05365957319736481, test_error(B): 0.07428693026304245, B-A: 0.020627357065677643\n",
            "epoch: 1468, train_error(A): 0.05366336554288864, test_error(B): 0.07412238419055939, B-A: 0.020459018647670746\n",
            "epoch: 1470, train_error(A): 0.05367748811841011, test_error(B): 0.07386082410812378, B-A: 0.02018333598971367\n",
            "epoch: 1472, train_error(A): 0.053717732429504395, test_error(B): 0.07344634085893631, B-A: 0.019728608429431915\n",
            "epoch: 1474, train_error(A): 0.05381647124886513, test_error(B): 0.0728367418050766, B-A: 0.01902027055621147\n",
            "epoch: 1476, train_error(A): 0.05397028103470802, test_error(B): 0.07220195233821869, B-A: 0.018231671303510666\n",
            "epoch: 1478, train_error(A): 0.05393799766898155, test_error(B): 0.0723293125629425, B-A: 0.018391314893960953\n",
            "epoch: 1480, train_error(A): 0.05368400737643242, test_error(B): 0.07364621013402939, B-A: 0.01996220275759697\n",
            "epoch: 1482, train_error(A): 0.05366469547152519, test_error(B): 0.07535192370414734, B-A: 0.021687228232622147\n",
            "epoch: 1484, train_error(A): 0.053781360387802124, test_error(B): 0.0763104036450386, B-A: 0.02252904325723648\n",
            "epoch: 1486, train_error(A): 0.053708866238594055, test_error(B): 0.0759751945734024, B-A: 0.02226632833480835\n",
            "epoch: 1488, train_error(A): 0.05361877754330635, test_error(B): 0.07470802962779999, B-A: 0.021089252084493637\n",
            "epoch: 1490, train_error(A): 0.053669605404138565, test_error(B): 0.0735597014427185, B-A: 0.01989009603857994\n",
            "epoch: 1492, train_error(A): 0.0536775216460228, test_error(B): 0.07341958582401276, B-A: 0.01974206417798996\n",
            "epoch: 1494, train_error(A): 0.05361349508166313, test_error(B): 0.07425402849912643, B-A: 0.020640533417463303\n",
            "epoch: 1496, train_error(A): 0.053623538464307785, test_error(B): 0.07520800083875656, B-A: 0.021584462374448776\n",
            "epoch: 1498, train_error(A): 0.053640905767679214, test_error(B): 0.07546398043632507, B-A: 0.02182307466864586\n",
            "epoch: 1500, train_error(A): 0.05360689386725426, test_error(B): 0.0750090554356575, B-A: 0.021402161568403244\n",
            "epoch: 1502, train_error(A): 0.05359959974884987, test_error(B): 0.07435440272092819, B-A: 0.020754802972078323\n",
            "epoch: 1504, train_error(A): 0.053612176328897476, test_error(B): 0.0739918202161789, B-A: 0.020379643887281418\n",
            "epoch: 1506, train_error(A): 0.05359674617648125, test_error(B): 0.07416095584630966, B-A: 0.020564209669828415\n",
            "epoch: 1508, train_error(A): 0.05358519405126572, test_error(B): 0.07467692345380783, B-A: 0.021091729402542114\n",
            "epoch: 1510, train_error(A): 0.05359140783548355, test_error(B): 0.07506650686264038, B-A: 0.02147509902715683\n",
            "epoch: 1512, train_error(A): 0.05358671396970749, test_error(B): 0.07503598928451538, B-A: 0.021449275314807892\n",
            "epoch: 1514, train_error(A): 0.0535752959549427, test_error(B): 0.07471194863319397, B-A: 0.021136652678251266\n",
            "epoch: 1516, train_error(A): 0.0535733699798584, test_error(B): 0.07440686970949173, B-A: 0.02083349972963333\n",
            "epoch: 1518, train_error(A): 0.05357365310192108, test_error(B): 0.0742838978767395, B-A: 0.02071024477481842\n",
            "epoch: 1520, train_error(A): 0.053567320108413696, test_error(B): 0.07437199354171753, B-A: 0.020804673433303833\n",
            "epoch: 1522, train_error(A): 0.05356106162071228, test_error(B): 0.07459227740764618, B-A: 0.0210312157869339\n",
            "epoch: 1524, train_error(A): 0.053559210151433945, test_error(B): 0.07479860633611679, B-A: 0.021239396184682846\n",
            "epoch: 1526, train_error(A): 0.0535571351647377, test_error(B): 0.07486990839242935, B-A: 0.02131277322769165\n",
            "epoch: 1528, train_error(A): 0.053552351891994476, test_error(B): 0.07479573041200638, B-A: 0.021243378520011902\n",
            "epoch: 1530, train_error(A): 0.05354749783873558, test_error(B): 0.07465755194425583, B-A: 0.02111005410552025\n",
            "epoch: 1532, train_error(A): 0.05354435741901398, test_error(B): 0.07453154772520065, B-A: 0.020987190306186676\n",
            "epoch: 1534, train_error(A): 0.05354179069399834, test_error(B): 0.07446597516536713, B-A: 0.02092418447136879\n",
            "epoch: 1536, train_error(A): 0.05353835970163345, test_error(B): 0.07446672767400742, B-A: 0.020928367972373962\n",
            "epoch: 1538, train_error(A): 0.05353425443172455, test_error(B): 0.07451430708169937, B-A: 0.020980052649974823\n",
            "epoch: 1540, train_error(A): 0.053530268371105194, test_error(B): 0.07458655536174774, B-A: 0.021056286990642548\n",
            "epoch: 1542, train_error(A): 0.053526751697063446, test_error(B): 0.07465797662734985, B-A: 0.021131224930286407\n",
            "epoch: 1544, train_error(A): 0.053523533046245575, test_error(B): 0.07470907270908356, B-A: 0.021185539662837982\n",
            "epoch: 1546, train_error(A): 0.05352029949426651, test_error(B): 0.07473156601190567, B-A: 0.02121126651763916\n",
            "epoch: 1548, train_error(A): 0.053516894578933716, test_error(B): 0.07473835349082947, B-A: 0.021221458911895752\n",
            "epoch: 1550, train_error(A): 0.05351335182785988, test_error(B): 0.07473859190940857, B-A: 0.02122524008154869\n",
            "epoch: 1552, train_error(A): 0.05350976064801216, test_error(B): 0.07473144680261612, B-A: 0.021221686154603958\n",
            "epoch: 1554, train_error(A): 0.05350617691874504, test_error(B): 0.07472141087055206, B-A: 0.021215233951807022\n",
            "epoch: 1556, train_error(A): 0.053502630442380905, test_error(B): 0.07471577823162079, B-A: 0.021213147789239883\n",
            "epoch: 1558, train_error(A): 0.05349912866950035, test_error(B): 0.07471913844347, B-A: 0.02122000977396965\n",
            "epoch: 1560, train_error(A): 0.053495705127716064, test_error(B): 0.074730783700943, B-A: 0.02123507857322693\n",
            "epoch: 1562, train_error(A): 0.05349242314696312, test_error(B): 0.07475554943084717, B-A: 0.02126312628388405\n",
            "epoch: 1564, train_error(A): 0.053489480167627335, test_error(B): 0.07480106502771378, B-A: 0.02131158486008644\n",
            "epoch: 1566, train_error(A): 0.053487379103899, test_error(B): 0.07487786561250687, B-A: 0.021390486508607864\n",
            "epoch: 1568, train_error(A): 0.05348749831318855, test_error(B): 0.07500731199979782, B-A: 0.021519813686609268\n",
            "epoch: 1570, train_error(A): 0.05349354445934296, test_error(B): 0.07522334903478622, B-A: 0.021729804575443268\n",
            "epoch: 1572, train_error(A): 0.05351576581597328, test_error(B): 0.07558464258909225, B-A: 0.022068876773118973\n",
            "epoch: 1574, train_error(A): 0.0535830520093441, test_error(B): 0.07619752734899521, B-A: 0.022614475339651108\n",
            "epoch: 1576, train_error(A): 0.05374050885438919, test_error(B): 0.07707956433296204, B-A: 0.023339055478572845\n",
            "epoch: 1578, train_error(A): 0.053861767053604126, test_error(B): 0.0774717628955841, B-A: 0.02360999584197998\n",
            "epoch: 1580, train_error(A): 0.053649526089429855, test_error(B): 0.07633509486913681, B-A: 0.022685568779706955\n",
            "epoch: 1582, train_error(A): 0.053462523967027664, test_error(B): 0.07436533272266388, B-A: 0.020902808755636215\n",
            "epoch: 1584, train_error(A): 0.05361131578683853, test_error(B): 0.0730985477566719, B-A: 0.019487231969833374\n",
            "epoch: 1586, train_error(A): 0.053627245128154755, test_error(B): 0.07291503995656967, B-A: 0.019287794828414917\n",
            "epoch: 1588, train_error(A): 0.05347369611263275, test_error(B): 0.07391542941331863, B-A: 0.020441733300685883\n",
            "epoch: 1590, train_error(A): 0.05347747355699539, test_error(B): 0.07542955130338669, B-A: 0.021952077746391296\n",
            "epoch: 1592, train_error(A): 0.053535640239715576, test_error(B): 0.07604673504829407, B-A: 0.02251109480857849\n",
            "epoch: 1594, train_error(A): 0.05346109718084335, test_error(B): 0.07524816691875458, B-A: 0.021787069737911224\n",
            "epoch: 1596, train_error(A): 0.0534462034702301, test_error(B): 0.074090376496315, B-A: 0.0206441730260849\n",
            "epoch: 1598, train_error(A): 0.053482696413993835, test_error(B): 0.07367478311061859, B-A: 0.020192086696624756\n",
            "epoch: 1600, train_error(A): 0.05344884470105171, test_error(B): 0.07406279444694519, B-A: 0.02061394974589348\n",
            "epoch: 1602, train_error(A): 0.053425271064043045, test_error(B): 0.07482593506574631, B-A: 0.021400664001703262\n",
            "epoch: 1604, train_error(A): 0.05344567820429802, test_error(B): 0.07532932609319687, B-A: 0.02188364788889885\n",
            "epoch: 1606, train_error(A): 0.05343204364180565, test_error(B): 0.07522154599428177, B-A: 0.02178950235247612\n",
            "epoch: 1608, train_error(A): 0.05341291055083275, test_error(B): 0.07466307282447815, B-A: 0.0212501622736454\n",
            "epoch: 1610, train_error(A): 0.05341920629143715, test_error(B): 0.07416848093271255, B-A: 0.020749274641275406\n",
            "epoch: 1612, train_error(A): 0.053419407457113266, test_error(B): 0.07410037517547607, B-A: 0.020680967718362808\n",
            "epoch: 1614, train_error(A): 0.05340474471449852, test_error(B): 0.07439161837100983, B-A: 0.020986873656511307\n",
            "epoch: 1616, train_error(A): 0.053398553282022476, test_error(B): 0.07478433847427368, B-A: 0.021385785192251205\n",
            "epoch: 1618, train_error(A): 0.053400248289108276, test_error(B): 0.07499950379133224, B-A: 0.02159925550222397\n",
            "epoch: 1620, train_error(A): 0.05339612066745758, test_error(B): 0.07499231398105621, B-A: 0.021596193313598633\n",
            "epoch: 1622, train_error(A): 0.05338757485151291, test_error(B): 0.07482411712408066, B-A: 0.02143654227256775\n",
            "epoch: 1624, train_error(A): 0.05338286980986595, test_error(B): 0.07459376752376556, B-A: 0.021210897713899612\n",
            "epoch: 1626, train_error(A): 0.053381502628326416, test_error(B): 0.07441587001085281, B-A: 0.021034367382526398\n",
            "epoch: 1628, train_error(A): 0.05337873846292496, test_error(B): 0.07435747236013412, B-A: 0.020978733897209167\n",
            "epoch: 1630, train_error(A): 0.05337345972657204, test_error(B): 0.07442276179790497, B-A: 0.02104930207133293\n",
            "epoch: 1632, train_error(A): 0.05336781591176987, test_error(B): 0.07453479617834091, B-A: 0.021166980266571045\n",
            "epoch: 1634, train_error(A): 0.053363148123025894, test_error(B): 0.07464760541915894, B-A: 0.02128445729613304\n",
            "epoch: 1636, train_error(A): 0.05335962772369385, test_error(B): 0.07474202662706375, B-A: 0.021382398903369904\n",
            "epoch: 1638, train_error(A): 0.05335650593042374, test_error(B): 0.0748230442404747, B-A: 0.021466538310050964\n",
            "epoch: 1640, train_error(A): 0.05335355922579765, test_error(B): 0.0748816654086113, B-A: 0.021528106182813644\n",
            "epoch: 1642, train_error(A): 0.053350672125816345, test_error(B): 0.07491936534643173, B-A: 0.021568693220615387\n",
            "epoch: 1644, train_error(A): 0.05334809795022011, test_error(B): 0.07496436685323715, B-A: 0.021616268903017044\n",
            "epoch: 1646, train_error(A): 0.05334637686610222, test_error(B): 0.0750344768166542, B-A: 0.021688099950551987\n",
            "epoch: 1648, train_error(A): 0.05334652587771416, test_error(B): 0.0751434713602066, B-A: 0.021796945482492447\n",
            "epoch: 1650, train_error(A): 0.05335063487291336, test_error(B): 0.07530052959918976, B-A: 0.021949894726276398\n",
            "epoch: 1652, train_error(A): 0.053363315761089325, test_error(B): 0.0755387619137764, B-A: 0.022175446152687073\n",
            "epoch: 1654, train_error(A): 0.05339282006025314, test_error(B): 0.07588252425193787, B-A: 0.022489704191684723\n",
            "epoch: 1656, train_error(A): 0.053451623767614365, test_error(B): 0.07635201513767242, B-A: 0.02290039137005806\n",
            "epoch: 1658, train_error(A): 0.05354050174355507, test_error(B): 0.07686369866132736, B-A: 0.023323196917772293\n",
            "epoch: 1660, train_error(A): 0.05358674377202988, test_error(B): 0.07705392688512802, B-A: 0.023467183113098145\n",
            "epoch: 1662, train_error(A): 0.053475379943847656, test_error(B): 0.0764424279332161, B-A: 0.02296704798936844\n",
            "epoch: 1664, train_error(A): 0.05332009494304657, test_error(B): 0.07513892650604248, B-A: 0.02181883156299591\n",
            "epoch: 1666, train_error(A): 0.05333111435174942, test_error(B): 0.07389947772026062, B-A: 0.0205683633685112\n",
            "epoch: 1668, train_error(A): 0.053417906165122986, test_error(B): 0.07316163927316666, B-A: 0.01974373310804367\n",
            "epoch: 1670, train_error(A): 0.05341348052024841, test_error(B): 0.07307961583137512, B-A: 0.01966613531112671\n",
            "epoch: 1672, train_error(A): 0.05332016944885254, test_error(B): 0.07376285642385483, B-A: 0.02044268697500229\n",
            "epoch: 1674, train_error(A): 0.053288545459508896, test_error(B): 0.07484392076730728, B-A: 0.021555375307798386\n",
            "epoch: 1676, train_error(A): 0.05332803353667259, test_error(B): 0.0756252110004425, B-A: 0.022297177463769913\n",
            "epoch: 1678, train_error(A): 0.05333273485302925, test_error(B): 0.0757390633225441, B-A: 0.022406328469514847\n",
            "epoch: 1680, train_error(A): 0.053291600197553635, test_error(B): 0.0752880871295929, B-A: 0.02199648693203926\n",
            "epoch: 1682, train_error(A): 0.053268373012542725, test_error(B): 0.07459252327680588, B-A: 0.021324150264263153\n",
            "epoch: 1684, train_error(A): 0.05327969044446945, test_error(B): 0.07404185831546783, B-A: 0.020762167870998383\n",
            "epoch: 1686, train_error(A): 0.05328674986958504, test_error(B): 0.07384149730205536, B-A: 0.02055474743247032\n",
            "epoch: 1688, train_error(A): 0.05327167734503746, test_error(B): 0.07401574403047562, B-A: 0.020744066685438156\n",
            "epoch: 1690, train_error(A): 0.053253982216119766, test_error(B): 0.07438460737466812, B-A: 0.021130625158548355\n",
            "epoch: 1692, train_error(A): 0.05324839800596237, test_error(B): 0.07476373761892319, B-A: 0.021515339612960815\n",
            "epoch: 1694, train_error(A): 0.05325077101588249, test_error(B): 0.07502468675374985, B-A: 0.021773915737867355\n",
            "epoch: 1696, train_error(A): 0.05325140431523323, test_error(B): 0.07513372600078583, B-A: 0.021882321685552597\n",
            "epoch: 1698, train_error(A): 0.05324652045965195, test_error(B): 0.07512468844652176, B-A: 0.021878167986869812\n",
            "epoch: 1700, train_error(A): 0.05323826149106026, test_error(B): 0.0750347226858139, B-A: 0.021796461194753647\n",
            "epoch: 1702, train_error(A): 0.05322977900505066, test_error(B): 0.07489679008722305, B-A: 0.021667011082172394\n",
            "epoch: 1704, train_error(A): 0.05322300270199776, test_error(B): 0.07474755495786667, B-A: 0.021524552255868912\n",
            "epoch: 1706, train_error(A): 0.0532180480659008, test_error(B): 0.07462676614522934, B-A: 0.021408718079328537\n",
            "epoch: 1708, train_error(A): 0.05321424454450607, test_error(B): 0.074532151222229, B-A: 0.02131790667772293\n",
            "epoch: 1710, train_error(A): 0.05321109667420387, test_error(B): 0.07444509863853455, B-A: 0.021234001964330673\n",
            "epoch: 1712, train_error(A): 0.05320863798260689, test_error(B): 0.07435194402933121, B-A: 0.02114330604672432\n",
            "epoch: 1714, train_error(A): 0.053207751363515854, test_error(B): 0.07423979789018631, B-A: 0.021032046526670456\n",
            "epoch: 1716, train_error(A): 0.05321094021201134, test_error(B): 0.07407575845718384, B-A: 0.0208648182451725\n",
            "epoch: 1718, train_error(A): 0.05322568863630295, test_error(B): 0.07379048317670822, B-A: 0.020564794540405273\n",
            "epoch: 1720, train_error(A): 0.05327461287379265, test_error(B): 0.0732794776558876, B-A: 0.020004864782094955\n",
            "epoch: 1722, train_error(A): 0.0534062385559082, test_error(B): 0.07248658686876297, B-A: 0.019080348312854767\n",
            "epoch: 1724, train_error(A): 0.05364098772406578, test_error(B): 0.07160335034132004, B-A: 0.017962362617254257\n",
            "epoch: 1726, train_error(A): 0.05363045632839203, test_error(B): 0.07165031880140305, B-A: 0.018019862473011017\n",
            "epoch: 1728, train_error(A): 0.053247105330228806, test_error(B): 0.07348959147930145, B-A: 0.020242486149072647\n",
            "epoch: 1730, train_error(A): 0.0532379113137722, test_error(B): 0.07585366070270538, B-A: 0.022615749388933182\n",
            "epoch: 1732, train_error(A): 0.05342588573694229, test_error(B): 0.07702809572219849, B-A: 0.023602209985256195\n",
            "epoch: 1734, train_error(A): 0.05329722538590431, test_error(B): 0.07640945911407471, B-A: 0.023112233728170395\n",
            "epoch: 1736, train_error(A): 0.05316423252224922, test_error(B): 0.07454654574394226, B-A: 0.02138231322169304\n",
            "epoch: 1738, train_error(A): 0.05326193571090698, test_error(B): 0.07306741178035736, B-A: 0.01980547606945038\n",
            "epoch: 1740, train_error(A): 0.053231801837682724, test_error(B): 0.07324714958667755, B-A: 0.020015347748994827\n",
            "epoch: 1742, train_error(A): 0.05314851179718971, test_error(B): 0.07467128336429596, B-A: 0.021522771567106247\n",
            "epoch: 1744, train_error(A): 0.053199004381895065, test_error(B): 0.07580211758613586, B-A: 0.0226031132042408\n",
            "epoch: 1746, train_error(A): 0.053191617131233215, test_error(B): 0.07568198442459106, B-A: 0.02249036729335785\n",
            "epoch: 1748, train_error(A): 0.05313803255558014, test_error(B): 0.0747121125459671, B-A: 0.021574079990386963\n",
            "epoch: 1750, train_error(A): 0.0531575009226799, test_error(B): 0.07390447705984116, B-A: 0.020746976137161255\n",
            "epoch: 1752, train_error(A): 0.05316006764769554, test_error(B): 0.07383608818054199, B-A: 0.02067602053284645\n",
            "epoch: 1754, train_error(A): 0.05312736704945564, test_error(B): 0.0743609294295311, B-A: 0.021233562380075455\n",
            "epoch: 1756, train_error(A): 0.05312870070338249, test_error(B): 0.07502491027116776, B-A: 0.021896209567785263\n",
            "epoch: 1758, train_error(A): 0.053135860711336136, test_error(B): 0.07531730830669403, B-A: 0.022181447595357895\n",
            "epoch: 1760, train_error(A): 0.053119808435440063, test_error(B): 0.075063057243824, B-A: 0.02194324880838394\n",
            "epoch: 1762, train_error(A): 0.053108904510736465, test_error(B): 0.0745624303817749, B-A: 0.021453525871038437\n",
            "epoch: 1764, train_error(A): 0.05311250686645508, test_error(B): 0.07422558963298798, B-A: 0.021113082766532898\n",
            "epoch: 1766, train_error(A): 0.053109973669052124, test_error(B): 0.07421736419200897, B-A: 0.021107390522956848\n",
            "epoch: 1768, train_error(A): 0.05309942737221718, test_error(B): 0.07441946864128113, B-A: 0.02132004126906395\n",
            "epoch: 1770, train_error(A): 0.053092557936906815, test_error(B): 0.07469954341650009, B-A: 0.021606985479593277\n",
            "epoch: 1772, train_error(A): 0.05309147760272026, test_error(B): 0.0749235674738884, B-A: 0.021832089871168137\n",
            "epoch: 1774, train_error(A): 0.05308952555060387, test_error(B): 0.0750151127576828, B-A: 0.021925587207078934\n",
            "epoch: 1776, train_error(A): 0.053084246814250946, test_error(B): 0.07496727257966995, B-A: 0.021883025765419006\n",
            "epoch: 1778, train_error(A): 0.05307764932513237, test_error(B): 0.07484080642461777, B-A: 0.021763157099485397\n",
            "epoch: 1780, train_error(A): 0.053072456270456314, test_error(B): 0.07470249384641647, B-A: 0.02163003757596016\n",
            "epoch: 1782, train_error(A): 0.05306883156299591, test_error(B): 0.07458550482988358, B-A: 0.021516673266887665\n",
            "epoch: 1784, train_error(A): 0.053065989166498184, test_error(B): 0.07449746876955032, B-A: 0.02143147960305214\n",
            "epoch: 1786, train_error(A): 0.05306317284703255, test_error(B): 0.07443209737539291, B-A: 0.021368924528360367\n",
            "epoch: 1788, train_error(A): 0.05306028574705124, test_error(B): 0.07438210397958755, B-A: 0.021321818232536316\n",
            "epoch: 1790, train_error(A): 0.053057651966810226, test_error(B): 0.07433553785085678, B-A: 0.021277885884046555\n",
            "epoch: 1792, train_error(A): 0.05305594205856323, test_error(B): 0.0742766484618187, B-A: 0.021220706403255463\n",
            "epoch: 1794, train_error(A): 0.05305636674165726, test_error(B): 0.07417486608028412, B-A: 0.02111849933862686\n",
            "epoch: 1796, train_error(A): 0.05306128039956093, test_error(B): 0.0740080252289772, B-A: 0.020946744829416275\n",
            "epoch: 1798, train_error(A): 0.05307573080062866, test_error(B): 0.07375524193048477, B-A: 0.02067951112985611\n",
            "epoch: 1800, train_error(A): 0.05311015248298645, test_error(B): 0.07338870316743851, B-A: 0.020278550684452057\n",
            "epoch: 1802, train_error(A): 0.05318348482251167, test_error(B): 0.07287188619375229, B-A: 0.019688401371240616\n",
            "epoch: 1804, train_error(A): 0.05330660194158554, test_error(B): 0.07225991785526276, B-A: 0.018953315913677216\n",
            "epoch: 1806, train_error(A): 0.053382404148578644, test_error(B): 0.0719488263130188, B-A: 0.018566422164440155\n",
            "epoch: 1808, train_error(A): 0.0532284751534462, test_error(B): 0.07258991152048111, B-A: 0.019361436367034912\n",
            "epoch: 1810, train_error(A): 0.05302853882312775, test_error(B): 0.07421212643384933, B-A: 0.021183587610721588\n",
            "epoch: 1812, train_error(A): 0.05306169390678406, test_error(B): 0.0758276879787445, B-A: 0.02276599407196045\n",
            "epoch: 1814, train_error(A): 0.053170498460531235, test_error(B): 0.07663087546825409, B-A: 0.023460377007722855\n",
            "epoch: 1816, train_error(A): 0.05313611030578613, test_error(B): 0.07641012966632843, B-A: 0.023274019360542297\n",
            "epoch: 1818, train_error(A): 0.053016722202301025, test_error(B): 0.07525380700826645, B-A: 0.022237084805965424\n",
            "epoch: 1820, train_error(A): 0.05302176997065544, test_error(B): 0.07393986731767654, B-A: 0.020918097347021103\n",
            "epoch: 1822, train_error(A): 0.053082969039678574, test_error(B): 0.07333555817604065, B-A: 0.020252589136362076\n",
            "epoch: 1824, train_error(A): 0.053049877285957336, test_error(B): 0.0735975056886673, B-A: 0.02054762840270996\n",
            "epoch: 1826, train_error(A): 0.05299005284905434, test_error(B): 0.0744207575917244, B-A: 0.02143070474267006\n",
            "epoch: 1828, train_error(A): 0.05299508944153786, test_error(B): 0.07527007907629013, B-A: 0.022274989634752274\n",
            "epoch: 1830, train_error(A): 0.053018487989902496, test_error(B): 0.07567126303911209, B-A: 0.022652775049209595\n",
            "epoch: 1832, train_error(A): 0.053002744913101196, test_error(B): 0.07554446160793304, B-A: 0.022541716694831848\n",
            "epoch: 1834, train_error(A): 0.05297407880425453, test_error(B): 0.07504966855049133, B-A: 0.0220755897462368\n",
            "epoch: 1836, train_error(A): 0.052969545125961304, test_error(B): 0.07449453324079514, B-A: 0.021524988114833832\n",
            "epoch: 1838, train_error(A): 0.05297882854938507, test_error(B): 0.0741536095738411, B-A: 0.021174781024456024\n",
            "epoch: 1840, train_error(A): 0.05297819897532463, test_error(B): 0.0741197019815445, B-A: 0.021141503006219864\n",
            "epoch: 1842, train_error(A): 0.05296540632843971, test_error(B): 0.07430817186832428, B-A: 0.021342765539884567\n",
            "epoch: 1844, train_error(A): 0.0529525987803936, test_error(B): 0.07459847629070282, B-A: 0.02164587751030922\n",
            "epoch: 1846, train_error(A): 0.05294744670391083, test_error(B): 0.07488252222537994, B-A: 0.021935075521469116\n",
            "epoch: 1848, train_error(A): 0.05294768512248993, test_error(B): 0.07511020451784134, B-A: 0.02216251939535141\n",
            "epoch: 1850, train_error(A): 0.05294889584183693, test_error(B): 0.07526377588510513, B-A: 0.022314880043268204\n",
            "epoch: 1852, train_error(A): 0.05294906347990036, test_error(B): 0.07535571604967117, B-A: 0.022406652569770813\n",
            "epoch: 1854, train_error(A): 0.052948229014873505, test_error(B): 0.07541652023792267, B-A: 0.022468291223049164\n",
            "epoch: 1856, train_error(A): 0.05294791981577873, test_error(B): 0.07548673450946808, B-A: 0.022538814693689346\n",
            "epoch: 1858, train_error(A): 0.05295097455382347, test_error(B): 0.07560017704963684, B-A: 0.02264920249581337\n",
            "epoch: 1860, train_error(A): 0.05296177789568901, test_error(B): 0.07579067349433899, B-A: 0.02282889559864998\n",
            "epoch: 1862, train_error(A): 0.05298788100481033, test_error(B): 0.07608605921268463, B-A: 0.023098178207874298\n",
            "epoch: 1864, train_error(A): 0.053040917962789536, test_error(B): 0.0765041932463646, B-A: 0.023463275283575058\n",
            "epoch: 1866, train_error(A): 0.0531248077750206, test_error(B): 0.07699164748191833, B-A: 0.023866839706897736\n",
            "epoch: 1868, train_error(A): 0.05319955572485924, test_error(B): 0.07734359800815582, B-A: 0.024144042283296585\n",
            "epoch: 1870, train_error(A): 0.053160250186920166, test_error(B): 0.07717035710811615, B-A: 0.024010106921195984\n",
            "epoch: 1872, train_error(A): 0.05298665910959244, test_error(B): 0.0761941522359848, B-A: 0.023207493126392365\n",
            "epoch: 1874, train_error(A): 0.05289220064878464, test_error(B): 0.07482466846704483, B-A: 0.021932467818260193\n",
            "epoch: 1876, train_error(A): 0.05295546352863312, test_error(B): 0.07372714579105377, B-A: 0.020771682262420654\n",
            "epoch: 1878, train_error(A): 0.05302770063281059, test_error(B): 0.07315226644277573, B-A: 0.020124565809965134\n",
            "epoch: 1880, train_error(A): 0.052989210933446884, test_error(B): 0.07328376919031143, B-A: 0.020294558256864548\n",
            "epoch: 1882, train_error(A): 0.05289498716592789, test_error(B): 0.07419013977050781, B-A: 0.021295152604579926\n",
            "epoch: 1884, train_error(A): 0.05288371443748474, test_error(B): 0.07534907758235931, B-A: 0.022465363144874573\n",
            "epoch: 1886, train_error(A): 0.05293048545718193, test_error(B): 0.07606589794158936, B-A: 0.023135412484407425\n",
            "epoch: 1888, train_error(A): 0.05294004827737808, test_error(B): 0.07614453136920929, B-A: 0.023204483091831207\n",
            "epoch: 1890, train_error(A): 0.05289677903056145, test_error(B): 0.07568656653165817, B-A: 0.022789787501096725\n",
            "epoch: 1892, train_error(A): 0.05286047235131264, test_error(B): 0.07499010860919952, B-A: 0.022129636257886887\n",
            "epoch: 1894, train_error(A): 0.05286739766597748, test_error(B): 0.07439922541379929, B-A: 0.021531827747821808\n",
            "epoch: 1896, train_error(A): 0.05288645625114441, test_error(B): 0.07406426966190338, B-A: 0.021177813410758972\n",
            "epoch: 1898, train_error(A): 0.05288545787334442, test_error(B): 0.07400660961866379, B-A: 0.021121151745319366\n",
            "epoch: 1900, train_error(A): 0.05286442115902901, test_error(B): 0.07422969490289688, B-A: 0.021365273743867874\n",
            "epoch: 1902, train_error(A): 0.05284465476870537, test_error(B): 0.0746317133307457, B-A: 0.02178705856204033\n",
            "epoch: 1904, train_error(A): 0.052838269621133804, test_error(B): 0.07502785325050354, B-A: 0.022189583629369736\n",
            "epoch: 1906, train_error(A): 0.0528409518301487, test_error(B): 0.07531280070543289, B-A: 0.022471848875284195\n",
            "epoch: 1908, train_error(A): 0.05284631624817848, test_error(B): 0.07549216598272324, B-A: 0.022645849734544754\n",
            "epoch: 1910, train_error(A): 0.052849940955638885, test_error(B): 0.0756123960018158, B-A: 0.02276245504617691\n",
            "epoch: 1912, train_error(A): 0.052851367741823196, test_error(B): 0.07570149004459381, B-A: 0.022850122302770615\n",
            "epoch: 1914, train_error(A): 0.05285174027085304, test_error(B): 0.07576169073581696, B-A: 0.022909950464963913\n",
            "epoch: 1916, train_error(A): 0.05285223200917244, test_error(B): 0.07580850273370743, B-A: 0.02295627072453499\n",
            "epoch: 1918, train_error(A): 0.05285442993044853, test_error(B): 0.07587526738643646, B-A: 0.02302083745598793\n",
            "epoch: 1920, train_error(A): 0.05286017432808876, test_error(B): 0.07598727196455002, B-A: 0.023127097636461258\n",
            "epoch: 1922, train_error(A): 0.052871931344270706, test_error(B): 0.07614190131425858, B-A: 0.02326996996998787\n",
            "epoch: 1924, train_error(A): 0.05289077013731003, test_error(B): 0.07632184773683548, B-A: 0.02343107759952545\n",
            "epoch: 1926, train_error(A): 0.05291437730193138, test_error(B): 0.07650883495807648, B-A: 0.023594457656145096\n",
            "epoch: 1928, train_error(A): 0.052935414016246796, test_error(B): 0.07667028158903122, B-A: 0.023734867572784424\n",
            "epoch: 1930, train_error(A): 0.05293869599699974, test_error(B): 0.0767202228307724, B-A: 0.02378152683377266\n",
            "epoch: 1932, train_error(A): 0.052908413112163544, test_error(B): 0.07654614001512527, B-A: 0.02363772690296173\n",
            "epoch: 1934, train_error(A): 0.05284931883215904, test_error(B): 0.07609850913286209, B-A: 0.02324919030070305\n",
            "epoch: 1936, train_error(A): 0.05279675871133804, test_error(B): 0.07547874748706818, B-A: 0.022681988775730133\n",
            "epoch: 1938, train_error(A): 0.05277886614203453, test_error(B): 0.07487869262695312, B-A: 0.022099826484918594\n",
            "epoch: 1940, train_error(A): 0.05278893932700157, test_error(B): 0.07439205050468445, B-A: 0.021603111177682877\n",
            "epoch: 1942, train_error(A): 0.05280967429280281, test_error(B): 0.07402248680591583, B-A: 0.021212812513113022\n",
            "epoch: 1944, train_error(A): 0.05282839015126228, test_error(B): 0.07377377897500992, B-A: 0.020945388823747635\n",
            "epoch: 1946, train_error(A): 0.05283735319972038, test_error(B): 0.0736575722694397, B-A: 0.020820219069719315\n",
            "epoch: 1948, train_error(A): 0.05283473804593086, test_error(B): 0.07365651428699493, B-A: 0.02082177624106407\n",
            "epoch: 1950, train_error(A): 0.05282250791788101, test_error(B): 0.07374352961778641, B-A: 0.020921021699905396\n",
            "epoch: 1952, train_error(A): 0.05280430242419243, test_error(B): 0.07389922440052032, B-A: 0.021094921976327896\n",
            "epoch: 1954, train_error(A): 0.0527847558259964, test_error(B): 0.07409574091434479, B-A: 0.02131098508834839\n",
            "epoch: 1956, train_error(A): 0.052768029272556305, test_error(B): 0.07428999990224838, B-A: 0.021521970629692078\n",
            "epoch: 1958, train_error(A): 0.05275553837418556, test_error(B): 0.0744544193148613, B-A: 0.021698880940675735\n",
            "epoch: 1960, train_error(A): 0.05274702608585358, test_error(B): 0.07457607239484787, B-A: 0.021829046308994293\n",
            "epoch: 1962, train_error(A): 0.052741214632987976, test_error(B): 0.07465267926454544, B-A: 0.021911464631557465\n",
            "epoch: 1964, train_error(A): 0.05273709073662758, test_error(B): 0.0746820941567421, B-A: 0.021945003420114517\n",
            "epoch: 1966, train_error(A): 0.05273449048399925, test_error(B): 0.07465344667434692, B-A: 0.02191895619034767\n",
            "epoch: 1968, train_error(A): 0.052734456956386566, test_error(B): 0.0745496153831482, B-A: 0.021815158426761627\n",
            "epoch: 1970, train_error(A): 0.05274099484086037, test_error(B): 0.07433713227510452, B-A: 0.021596137434244156\n",
            "epoch: 1972, train_error(A): 0.05276673659682274, test_error(B): 0.07394656538963318, B-A: 0.02117982879281044\n",
            "epoch: 1974, train_error(A): 0.052854642271995544, test_error(B): 0.07321465015411377, B-A: 0.020360007882118225\n",
            "epoch: 1976, train_error(A): 0.0531228631734848, test_error(B): 0.07195496559143066, B-A: 0.018832102417945862\n",
            "epoch: 1978, train_error(A): 0.05361786112189293, test_error(B): 0.07058229297399521, B-A: 0.01696443185210228\n",
            "epoch: 1980, train_error(A): 0.053321722894907, test_error(B): 0.07136537879705429, B-A: 0.018043655902147293\n",
            "epoch: 1982, train_error(A): 0.052755795419216156, test_error(B): 0.07517534494400024, B-A: 0.022419549524784088\n",
            "epoch: 1984, train_error(A): 0.05307096615433693, test_error(B): 0.07793769240379333, B-A: 0.024866726249456406\n",
            "epoch: 1986, train_error(A): 0.05304132029414177, test_error(B): 0.07741931825876236, B-A: 0.02437799796462059\n",
            "epoch: 1988, train_error(A): 0.05272320657968521, test_error(B): 0.07436289638280869, B-A: 0.021639689803123474\n",
            "epoch: 1990, train_error(A): 0.05292748659849167, test_error(B): 0.07276012003421783, B-A: 0.019832633435726166\n",
            "epoch: 1992, train_error(A): 0.05274743586778641, test_error(B): 0.07423704862594604, B-A: 0.021489612758159637\n",
            "epoch: 1994, train_error(A): 0.052775319665670395, test_error(B): 0.07629191875457764, B-A: 0.023516599088907242\n",
            "epoch: 1996, train_error(A): 0.05279802903532982, test_error(B): 0.07628560811281204, B-A: 0.023487579077482224\n",
            "epoch: 1998, train_error(A): 0.05269041657447815, test_error(B): 0.07467171549797058, B-A: 0.02198129892349243\n",
            "epoch: 2000, train_error(A): 0.052768971771001816, test_error(B): 0.07368013262748718, B-A: 0.020911160856485367\n",
            "elapsed_time: 0:00:12.407388\n",
            "elapsed_time per epoch: 0:00:00.006204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhsQRDZYOxuo",
        "colab_type": "code",
        "outputId": "9feb6762-cfa7-408a-d84f-b3cfdf71ec74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 하이퍼파라미터 출력\n",
        "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
        "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
        " \n",
        "print(',seq_length:', seq_length, end='')\n",
        "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
        "print(',forget_bias:', forget_bias, end='')\n",
        "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
        "print(',keep_prob:', keep_prob, end='')\n",
        " \n",
        "print(',epoch_num:', epoch_num, end='')\n",
        "print(',learning_rate:', learning_rate, end='')\n",
        " \n",
        "print(',train_error:', train_error_summary[-1], end='')\n",
        "print(',test_error:', test_error_summary[-1], end='')\n",
        "print(',min_test_error:', np.min(test_error_summary))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_data_column_cnt: 4,output_data_column_cnt: 1,seq_length: 1,rnn_cell_hidden_dim: 12,forget_bias: 1,num_stacked_layers: 4,keep_prob: 1.0,epoch_num: 2000,learning_rate: 0.01,train_error: 0.05276897,test_error: 0.07368013,min_test_error: 0.06856402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfFDfVFOxus",
        "colab_type": "code",
        "outputId": "dda549c2-5bf7-4967-f2f6-9f85e6f87360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "# 결과 그래프 출력\n",
        "plt.figure(1)\n",
        "plt.plot(train_error_summary, 'gold')\n",
        "plt.plot(test_error_summary, 'b')\n",
        "plt.xlabel('Epoch(x100)')\n",
        "plt.ylabel('Root Mean Square Error')\n",
        " \n",
        "plt.figure(2)\n",
        "plt.plot(testY, 'r')\n",
        "plt.plot(test_predict, 'b')\n",
        "plt.xlabel('Time Period')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFvdOetEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-yCUwDrRt5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBf8ry2lRug4",
        "colab_type": "code",
        "outputId": "153cf30e-5171-4f1e-ff17-75180155bcc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "error1 = mean_absolute_percentage_error(testY, test_predict)\n",
        "print(\"MAPE :\",error1,\"%\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE : 17.425428379605385 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8yGnXcAOxuy",
        "colab_type": "code",
        "outputId": "a6d9c1a5-c57e-4d44-f18d-a59c2a2e3f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
        "recent_data = np.array([x[len(x)-seq_length : ]])\n",
        "print(\"recent_data.shape:\", recent_data.shape)\n",
        "print(\"recent_data:\", recent_data)\n",
        " \n",
        "# 내일 방문자를 예측\n",
        "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        " \n",
        "print(\"test_predict\", test_predict[0])\n",
        "test_predict = reverse_min_max_scaling(visitor, test_predict) # 금액데이터 역정규화한다\n",
        "print(\"ATS\", test_predict[0]) # 예측한 visitor를 출력한다"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recent_data.shape: (1, 1, 4)\n",
            "recent_data: [[[0.14285714 0.         0.14285714 0.32052578]]]\n",
            "test_predict [0.30027232]\n",
            "ATS [2423.7852]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VOurLFfvGy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def test_network(model_dir, batch_size, test_x, test_y):\n",
        "#     inputs_, labels_, keep_prob_ = model_inputs()\n",
        "#     embed = build_embedding_layer(inputs_, vocab_size, embed_size)\n",
        "#     initial_state, lstm_outputs, lstm_cell, final_state = build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size)\n",
        "#     predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n",
        "#     accuracy = build_accuracy(predictions, labels_)\n",
        "\n",
        "#     saver = tf.train.Saver()\n",
        "\n",
        "#     test_acc = []\n",
        "#     with tf.Session() as sess:\n",
        "#         saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
        "#         test_state = sess.run(lstm_cell.zero_state(batch_size, tf.float32))\n",
        "#         for ii, (x, y) in enumerate(utl.get_batches(test_x, test_y, batch_size), 1):\n",
        "#             feed = {inputs_: x,\n",
        "#  labels_: y[:, None],\n",
        "#  keep_prob_: 1,\n",
        "#  initial_state: test_state}\n",
        "#             batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "#             test_acc.append(batch_acc)\n",
        "#         print(\"Test Accuracy: {:.3f}\".format(np.mean(test_acc)))\n",
        "\n",
        "\n",
        "# with tf.Graph().as_default():\n",
        "#     test_network('checkpoints', \n",
        "#                  batch_size, test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6niyYkPMKkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}